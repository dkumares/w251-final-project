{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "behavioral-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../fl-ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hired-parts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-dancing",
   "metadata": {},
   "source": [
    "# Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "canadian-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of the raw data and processed files name\n",
    "# CONFIG NEEDED: Uncomment only the specific files to be processed on your node\n",
    "\n",
    "csv_files = [\n",
    " '02-14-2018.csv',\n",
    " '02-15-2018.csv',\n",
    " '02-16-2018.csv',\n",
    " '02-21-2018.csv',\n",
    " '02-22-2018.csv',\n",
    " '02-23-2018.csv',\n",
    " '02-28-2018.csv',\n",
    " '03-01-2018.csv',\n",
    " '03-02-2018.csv',\n",
    " '02-20-2018.csv'    \n",
    "]\n",
    "\n",
    "label_maps = {'Benign': 0, 'FTP-BruteForce': 1, 'SSH-Bruteforce': 1, 'DoS attacks-GoldenEye': 1, 'DoS attacks-Slowloris': 1,\n",
    "         'DoS attacks-SlowHTTPTest': 1, 'DoS attacks-Hulk': 1, 'Brute Force -Web': 1, 'Brute Force -XSS': 1,\n",
    "         'SQL Injection': 1, 'Infilteration': 1, 'Bot': 1, 'DDOS attack-HOIC': 1, 'DDoS attacks-LOIC-HTTP': 1, \n",
    "         'DDOS attack-LOIC-UDP': 1}\n",
    " \n",
    "# CONFIG NEEDED: Change Binary and Multi-class output file names if needed\n",
    "multi_class_file = 'DATA-IDS-2018-multiclass'\n",
    "binary_class_file = 'DATA-IDS-2018-binaryclass'\n",
    "\n",
    "# CONFIG NEEDED: Change Train and Test output file names if needed. Adjust the split size.\n",
    "test_prefix = 'TEST-'\n",
    "train_prefix = 'TRAIN-'\n",
    "\n",
    "test_size = 0.10\n",
    "num_trainers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "regulation-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder name for raw data and processed files under the project directory\n",
    "# CONFIG NEEDED: Change the './data' and 'processed' to what you named your directories\n",
    "# Raw Data Files Location: final_project/data\n",
    "# Processed Data Files Location: final_project/data/processed\n",
    "\n",
    "rawdata_path = '../data/CSE-CIC-IDS2018'\n",
    "processed_path = os.path.join(rawdata_path, 'processed')\n",
    "\n",
    "# CONFIG NEEDED: Change to true as needed for multi-class or binary class files. \n",
    "# Note atleast one of these has to be true for the combined data file to be created. \n",
    "multi_class = True\n",
    "binary_class = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tribal-wells",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading: ../data/CSE-CIC-IDS2018/02-14-2018.csv\n",
      "appending: ../data/CSE-CIC-IDS2018/02-15-2018.csv\n",
      "appending: ../data/CSE-CIC-IDS2018/02-16-2018.csv\n",
      "appending: ../data/CSE-CIC-IDS2018/02-21-2018.csv\n",
      "appending: ../data/CSE-CIC-IDS2018/02-22-2018.csv\n",
      "appending: ../data/CSE-CIC-IDS2018/02-23-2018.csv\n",
      "appending: ../data/CSE-CIC-IDS2018/02-28-2018.csv\n",
      "appending: ../data/CSE-CIC-IDS2018/03-01-2018.csv\n",
      "appending: ../data/CSE-CIC-IDS2018/03-02-2018.csv\n",
      "appending: ../data/CSE-CIC-IDS2018/02-20-2018.csv\n",
      "Combined Raw Datafile Shape\n",
      "(16233002, 80)\n",
      "Original Number of Records:  16233002\n"
     ]
    }
   ],
   "source": [
    "# Read the first file from the list to be processed\n",
    "fname = os.path.join(rawdata_path, csv_files[0])\n",
    "print('reading:', fname)\n",
    "df = pd.read_csv(fname, low_memory=False).drop(columns=['Flow ID', 'Src IP', 'Dst IP', 'Src Port'], errors='ignore')\n",
    "\n",
    "# Read the remaining files in the list\n",
    "for name in csv_files[1:]:\n",
    "    fname = os.path.join(rawdata_path, name)\n",
    "    print('appending:', fname)\n",
    "    df1 = pd.read_csv(fname, low_memory=False).drop(columns=['Flow ID', 'Src IP', 'Dst IP', 'Src Port'], errors='ignore')    \n",
    "    df = df.append(df1, ignore_index=True)\n",
    "\n",
    "# print final shape\n",
    "print('Combined Raw Datafile Shape')\n",
    "print(df.shape)\n",
    "\n",
    "num_of_raw_records = df.shape[0]\n",
    "print('Original Number of Records: ', num_of_raw_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "continental-carbon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Value Counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Benign                      13484708\n",
       "DDOS attack-HOIC              686012\n",
       "DDoS attacks-LOIC-HTTP        576191\n",
       "DoS attacks-Hulk              461912\n",
       "Bot                           286191\n",
       "FTP-BruteForce                193360\n",
       "SSH-Bruteforce                187589\n",
       "Infilteration                 161934\n",
       "DoS attacks-SlowHTTPTest      139890\n",
       "DoS attacks-GoldenEye          41508\n",
       "DoS attacks-Slowloris          10990\n",
       "DDOS attack-LOIC-UDP            1730\n",
       "Brute Force -Web                 611\n",
       "Brute Force -XSS                 230\n",
       "SQL Injection                     87\n",
       "Label                             59\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Original Dataset Value Counts')\n",
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-cathedral",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "opposite-controversy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Infinity or NaN Values\n",
      "179219\n",
      "Number of NaN/Inf Records Dropped:  92547\n",
      "Remaining Infinity or NaN Values\n",
      "0\n",
      "Combined Raw Datafile Shape\n",
      "(16140455, 80)\n"
     ]
    }
   ],
   "source": [
    "# Remove infinity and NaN values\n",
    "print('Number of Infinity or NaN Values')\n",
    "print(df.isin([np.nan, np.inf, -np.inf]).sum().sum())\n",
    "\n",
    "# Replace infinity to NaN and drop NaN values\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "dropped_NaN_records = num_of_raw_records - df.shape[0]\n",
    "print('Number of NaN/Inf Records Dropped: ', dropped_NaN_records)\n",
    "\n",
    "# Check infinity and NaN values\n",
    "print('Remaining Infinity or NaN Values')\n",
    "print(df.isin([np.nan, np.inf, -np.inf]).sum().sum())\n",
    "\n",
    "print('Combined Raw Datafile Shape')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stone-backup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts',\n",
       "       'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max',\n",
       "       'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std',\n",
       "       'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean',\n",
       "       'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean',\n",
       "       'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot',\n",
       "       'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min',\n",
       "       'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max',\n",
       "       'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags',\n",
       "       'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s',\n",
       "       'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean',\n",
       "       'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt',\n",
       "       'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt',\n",
       "       'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg',\n",
       "       'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg',\n",
       "       'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg',\n",
       "       'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts',\n",
       "       'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts',\n",
       "       'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts',\n",
       "       'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max',\n",
       "       'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "finnish-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "armed-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate headers\n",
    "df = df[~df['Dst Port'].str.contains('Dst Port', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "convinced-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean (spaces, special characters, etc.) column headers and lower case \n",
    "column_name_regex = re.compile(r\"\\W\", re.IGNORECASE)\n",
    "df.columns = [column_name_regex.sub('_', c.lower()) for c in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "metropolitan-morrison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Value Counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Benign                      13393005\n",
       "DDOS attack-HOIC              686012\n",
       "DDoS attacks-LOIC-HTTP        576191\n",
       "DoS attacks-Hulk              461912\n",
       "Bot                           286191\n",
       "FTP-BruteForce                193354\n",
       "SSH-Bruteforce                187589\n",
       "Infilteration                 161096\n",
       "DoS attacks-SlowHTTPTest      139890\n",
       "DoS attacks-GoldenEye          41508\n",
       "DoS attacks-Slowloris          10990\n",
       "DDOS attack-LOIC-UDP            1730\n",
       "Brute Force -Web                 611\n",
       "Brute Force -XSS                 230\n",
       "SQL Injection                     87\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Original Dataset Value Counts')\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "reduced-november",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating combined dataset after cleaning and preprocessing\n",
      "writing: ../data/CSE-CIC-IDS2018/processed/CSE-CIC-IDS2018-CombinedDataset.csv\n",
      "Finished writing:  ../data/CSE-CIC-IDS2018/processed/CSE-CIC-IDS2018-CombinedDataset.csv\n"
     ]
    }
   ],
   "source": [
    "print('Creating combined dataset after cleaning and preprocessing')\n",
    "dataset_file_name = os.path.join(processed_path, 'CSE-CIC-IDS2018-CombinedDataset.csv')\n",
    "print('writing:', dataset_file_name)\n",
    "df.to_csv(dataset_file_name, index=False)\n",
    "print('Finished writing: ', dataset_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "hydraulic-reconstruction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Infinity or NaN Values\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print('Number of Infinity or NaN Values')\n",
    "print(df.isin([np.nan, np.inf, -np.inf]).sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-delta",
   "metadata": {},
   "source": [
    "#  Loading combined dataset from CSV file (auto inference of data types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "distinct-mainstream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading: ../data/CSE-CIC-IDS2018/processed/CSE-CIC-IDS2018-CombinedDataset.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_file_name = os.path.join(processed_path, 'CSE-CIC-IDS2018-CombinedDataset.csv')\n",
    "print('reading:', dataset_file_name)\n",
    "combined_dataset_df = pd.read_csv(dataset_file_name, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "closing-marble",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Dataset Shape\n",
      "(16140396, 79)\n"
     ]
    }
   ],
   "source": [
    "# print final shape\n",
    "print('Combined Dataset Shape')\n",
    "print(combined_dataset_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "considered-efficiency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Dataset Value Counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Benign                      13393005\n",
       "DDOS attack-HOIC              686012\n",
       "DDoS attacks-LOIC-HTTP        576191\n",
       "DoS attacks-Hulk              461912\n",
       "Bot                           286191\n",
       "FTP-BruteForce                193354\n",
       "SSH-Bruteforce                187589\n",
       "Infilteration                 161096\n",
       "DoS attacks-SlowHTTPTest      139890\n",
       "DoS attacks-GoldenEye          41508\n",
       "DoS attacks-Slowloris          10990\n",
       "DDOS attack-LOIC-UDP            1730\n",
       "Brute Force -Web                 611\n",
       "Brute Force -XSS                 230\n",
       "SQL Injection                     87\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Combined Dataset Value Counts')\n",
    "combined_dataset_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "willing-savannah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Infinity or NaN Values\n",
      "6426\n"
     ]
    }
   ],
   "source": [
    "print('Number of Infinity or NaN Values')\n",
    "print(combined_dataset_df.isin([np.nan, np.inf, -np.inf]).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "emerging-richards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Number of Records in combined dataset :  16140396\n"
     ]
    }
   ],
   "source": [
    "num_of_raw_records_combined = combined_dataset_df.shape[0]\n",
    "print('Original Number of Records in combined dataset : ', num_of_raw_records_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "proprietary-sunrise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN/Inf Records Dropped in combined dataset:  3213\n",
      "Remaining Infinity or NaN Values\n",
      "0\n",
      "Combined Dataset Shape\n",
      "(16137183, 79)\n"
     ]
    }
   ],
   "source": [
    "# Replace infinity to NaN and drop NaN values\n",
    "combined_dataset_df = combined_dataset_df.replace([np.inf, -np.inf], np.nan)\n",
    "combined_dataset_df = combined_dataset_df.dropna()\n",
    "combined_dataset_df = combined_dataset_df.reset_index(drop=True)\n",
    "\n",
    "dropped_NaN_records_combined = num_of_raw_records_combined - combined_dataset_df.shape[0]\n",
    "print('Number of NaN/Inf Records Dropped in combined dataset: ', dropped_NaN_records_combined)\n",
    "\n",
    "# Check infinity and NaN values\n",
    "print('Remaining Infinity or NaN Values')\n",
    "print(combined_dataset_df.isin([np.nan, np.inf, -np.inf]).sum().sum())\n",
    "\n",
    "print('Combined Dataset Shape')\n",
    "print(combined_dataset_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "filled-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop attack types that have less than 20K rows.\n",
    "reduced_df = combined_dataset_df.groupby('label').filter(lambda x : len(x) > 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "interested-athens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Value Counts After Dropping Minimal Attacks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Benign                      13390249\n",
       "DDOS attack-HOIC              686012\n",
       "DDoS attacks-LOIC-HTTP        576191\n",
       "DoS attacks-Hulk              461912\n",
       "Bot                           286191\n",
       "FTP-BruteForce                193354\n",
       "SSH-Bruteforce                187589\n",
       "Infilteration                 160639\n",
       "DoS attacks-SlowHTTPTest      139890\n",
       "DoS attacks-GoldenEye          41508\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Dataset Value Counts After Dropping Minimal Attacks')\n",
    "reduced_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-attention",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "numerical-marshall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14511181, 78) (1612354, 78) (14511181,) (1612354,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into test and train data\n",
    "y = reduced_df.pop('label')\n",
    "X = reduced_df\n",
    "\n",
    "test_size = 0.10\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, shuffle=True, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "dftrain = X_train.join(y_train)\n",
    "dftest = X_test.join(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "duplicate-flower",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14511181, 79)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "assumed-mambo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1612354, 79)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "powered-pakistan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign                      1339025\n",
       "DDOS attack-HOIC              68601\n",
       "DDoS attacks-LOIC-HTTP        57619\n",
       "DoS attacks-Hulk              46191\n",
       "Bot                           28619\n",
       "FTP-BruteForce                19336\n",
       "SSH-Bruteforce                18759\n",
       "Infilteration                 16064\n",
       "DoS attacks-SlowHTTPTest      13989\n",
       "DoS attacks-GoldenEye          4151\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "considerable-globe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign                      12051224\n",
       "DDOS attack-HOIC              617411\n",
       "DDoS attacks-LOIC-HTTP        518572\n",
       "DoS attacks-Hulk              415721\n",
       "Bot                           257572\n",
       "FTP-BruteForce                174018\n",
       "SSH-Bruteforce                168830\n",
       "Infilteration                 144575\n",
       "DoS attacks-SlowHTTPTest      125901\n",
       "DoS attacks-GoldenEye          37357\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "contrary-episode",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Finding the null values.\n",
    "print(dftrain.isin([np.nan, np.inf, -np.inf]).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "incredible-underwear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dst_port - int64\n",
      "protocol - int64\n",
      "flow_duration - int64\n",
      "tot_fwd_pkts - int64\n",
      "tot_bwd_pkts - int64\n",
      "totlen_fwd_pkts - float64\n",
      "totlen_bwd_pkts - float64\n",
      "fwd_pkt_len_max - float64\n",
      "fwd_pkt_len_min - float64\n",
      "fwd_pkt_len_mean - float64\n",
      "fwd_pkt_len_std - float64\n",
      "bwd_pkt_len_max - float64\n",
      "bwd_pkt_len_min - float64\n",
      "bwd_pkt_len_mean - float64\n",
      "bwd_pkt_len_std - float64\n",
      "flow_byts_s - float64\n",
      "flow_pkts_s - float64\n",
      "flow_iat_mean - float64\n",
      "flow_iat_std - float64\n",
      "flow_iat_max - float64\n",
      "flow_iat_min - float64\n",
      "fwd_iat_tot - float64\n",
      "fwd_iat_mean - float64\n",
      "fwd_iat_std - float64\n",
      "fwd_iat_max - float64\n",
      "fwd_iat_min - float64\n",
      "bwd_iat_tot - float64\n",
      "bwd_iat_mean - float64\n",
      "bwd_iat_std - float64\n",
      "bwd_iat_max - float64\n",
      "bwd_iat_min - float64\n",
      "fwd_psh_flags - int64\n",
      "bwd_psh_flags - int64\n",
      "fwd_urg_flags - int64\n",
      "bwd_urg_flags - int64\n",
      "fwd_header_len - int64\n",
      "bwd_header_len - int64\n",
      "fwd_pkts_s - float64\n",
      "bwd_pkts_s - float64\n",
      "pkt_len_min - float64\n",
      "pkt_len_max - float64\n",
      "pkt_len_mean - float64\n",
      "pkt_len_std - float64\n",
      "pkt_len_var - float64\n",
      "fin_flag_cnt - int64\n",
      "syn_flag_cnt - int64\n",
      "rst_flag_cnt - int64\n",
      "psh_flag_cnt - int64\n",
      "ack_flag_cnt - int64\n",
      "urg_flag_cnt - int64\n",
      "cwe_flag_count - int64\n",
      "ece_flag_cnt - int64\n",
      "down_up_ratio - float64\n",
      "pkt_size_avg - float64\n",
      "fwd_seg_size_avg - float64\n",
      "bwd_seg_size_avg - float64\n",
      "fwd_byts_b_avg - int64\n",
      "fwd_pkts_b_avg - int64\n",
      "fwd_blk_rate_avg - int64\n",
      "bwd_byts_b_avg - int64\n",
      "bwd_pkts_b_avg - int64\n",
      "bwd_blk_rate_avg - int64\n",
      "subflow_fwd_pkts - int64\n",
      "subflow_fwd_byts - int64\n",
      "subflow_bwd_pkts - int64\n",
      "subflow_bwd_byts - int64\n",
      "init_fwd_win_byts - int64\n",
      "init_bwd_win_byts - int64\n",
      "fwd_act_data_pkts - int64\n",
      "fwd_seg_size_min - int64\n",
      "active_mean - float64\n",
      "active_std - float64\n",
      "active_max - float64\n",
      "active_min - float64\n",
      "idle_mean - float64\n",
      "idle_std - float64\n",
      "idle_max - float64\n",
      "idle_min - float64\n",
      "label - object\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dftrain.columns)):\n",
    "      print(dftrain.columns[i], '-', dftrain.dtypes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-blast",
   "metadata": {},
   "source": [
    "# Bootstrapping data using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bearing-mexican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=Benign, n=12051224 (83.048%)\n",
      "label=DoS attacks-Hulk, n=415721 (2.865%)\n",
      "label=DDOS attack-HOIC, n=617411 (4.255%)\n",
      "label=DDoS attacks-LOIC-HTTP, n=518572 (3.574%)\n",
      "label=Bot, n=257572 (1.775%)\n",
      "label=DoS attacks-SlowHTTPTest, n=125901 (0.868%)\n",
      "label=FTP-BruteForce, n=174018 (1.199%)\n",
      "label=Infilteration, n=144575 (0.996%)\n",
      "label=SSH-Bruteforce, n=168830 (1.163%)\n",
      "label=DoS attacks-GoldenEye, n=37357 (0.257%)\n"
     ]
    }
   ],
   "source": [
    "# summarize distribution before resampling and augmentation of data\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(y_train)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train) * 100\n",
    "    print('label=%s, n=%d (%.3f%%)' % (k, v, per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "systematic-mountain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Benign'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_label = dftrain['label'].value_counts().idxmax()\n",
    "most_frequent_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "automated-league",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12051224"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_label_count = dftrain[dftrain['label'] == most_frequent_label].shape[0]\n",
    "most_frequent_label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "macro-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_strategy_dict = {\n",
    "    \"DDOS attack-HOIC\" : round(0.2*most_frequent_label_count),\n",
    "    \"DDoS attacks-LOIC-HTTP\" : round(0.2*most_frequent_label_count),\n",
    "    \"DoS attacks-Hulk\" : round(0.2*most_frequent_label_count),\n",
    "    \"Bot\" : round(0.1*most_frequent_label_count),\n",
    "    \"FTP-BruteForce\" : round(0.1*most_frequent_label_count),\n",
    "    \"SSH-Bruteforce\" : round(0.1*most_frequent_label_count),\n",
    "    \"Infilteration\" : round(0.1*most_frequent_label_count),\n",
    "    \"DoS attacks-SlowHTTPTest\" : round(0.1*most_frequent_label_count),\n",
    "    \"DoS attacks-GoldenEye\" : round(0.1*most_frequent_label_count)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "completed-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample the minority class and randomly downsample the majority class.\n",
    "over = SMOTE(sampling_strategy=sampling_strategy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ongoing-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to generate the data.\n",
    "oversampled_trainX, oversampled_trainY = over.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dynamic-information",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=Benign, n=12051224 (45.455%)\n",
      "label=DoS attacks-Hulk, n=2410245 (9.091%)\n",
      "label=DDOS attack-HOIC, n=2410245 (9.091%)\n",
      "label=DDoS attacks-LOIC-HTTP, n=2410245 (9.091%)\n",
      "label=Bot, n=1205122 (4.545%)\n",
      "label=DoS attacks-SlowHTTPTest, n=1205122 (4.545%)\n",
      "label=FTP-BruteForce, n=1205122 (4.545%)\n",
      "label=Infilteration, n=1205122 (4.545%)\n",
      "label=SSH-Bruteforce, n=1205122 (4.545%)\n",
      "label=DoS attacks-GoldenEye, n=1205122 (4.545%)\n"
     ]
    }
   ],
   "source": [
    "#oversampled_trainY.value_counts()\n",
    "# summarize distribution\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(oversampled_trainY)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(oversampled_trainY) * 100\n",
    "    print('label=%s, n=%d (%.3f%%)' % (k, v, per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "known-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_strategy_dict_under = {\n",
    "    \"Benign\": round(0.7*most_frequent_label_count)    \n",
    "}\n",
    "under = RandomUnderSampler(sampling_strategy=sampling_strategy_dict_under)\n",
    "#steps = [('o', over), ('u', under)]\n",
    "#pipeline = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "concrete-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to generate the data.\n",
    "sampled_trainX, sampled_trainY = under.fit_resample(oversampled_trainX, oversampled_trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "conscious-prophet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=Benign, n=8435857 (36.842%)\n",
      "label=Bot, n=1205122 (5.263%)\n",
      "label=DDOS attack-HOIC, n=2410245 (10.526%)\n",
      "label=DDoS attacks-LOIC-HTTP, n=2410245 (10.526%)\n",
      "label=DoS attacks-GoldenEye, n=1205122 (5.263%)\n",
      "label=DoS attacks-Hulk, n=2410245 (10.526%)\n",
      "label=DoS attacks-SlowHTTPTest, n=1205122 (5.263%)\n",
      "label=FTP-BruteForce, n=1205122 (5.263%)\n",
      "label=Infilteration, n=1205122 (5.263%)\n",
      "label=SSH-Bruteforce, n=1205122 (5.263%)\n"
     ]
    }
   ],
   "source": [
    "#oversampled_trainY.value_counts()\n",
    "# summarize distribution\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(sampled_trainY)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(sampled_trainY) * 100\n",
    "    print('label=%s, n=%d (%.3f%%)' % (k, v, per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "suffering-detail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22897324, 79)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_train = pd.concat([pd.DataFrame(sampled_trainX), pd.DataFrame(sampled_trainY)], axis=1)\n",
    "sampled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "personalized-manhattan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dst_port', 'protocol', 'flow_duration', 'tot_fwd_pkts', 'tot_bwd_pkts',\n",
       "       'totlen_fwd_pkts', 'totlen_bwd_pkts', 'fwd_pkt_len_max',\n",
       "       'fwd_pkt_len_min', 'fwd_pkt_len_mean', 'fwd_pkt_len_std',\n",
       "       'bwd_pkt_len_max', 'bwd_pkt_len_min', 'bwd_pkt_len_mean',\n",
       "       'bwd_pkt_len_std', 'flow_byts_s', 'flow_pkts_s', 'flow_iat_mean',\n",
       "       'flow_iat_std', 'flow_iat_max', 'flow_iat_min', 'fwd_iat_tot',\n",
       "       'fwd_iat_mean', 'fwd_iat_std', 'fwd_iat_max', 'fwd_iat_min',\n",
       "       'bwd_iat_tot', 'bwd_iat_mean', 'bwd_iat_std', 'bwd_iat_max',\n",
       "       'bwd_iat_min', 'fwd_psh_flags', 'bwd_psh_flags', 'fwd_urg_flags',\n",
       "       'bwd_urg_flags', 'fwd_header_len', 'bwd_header_len', 'fwd_pkts_s',\n",
       "       'bwd_pkts_s', 'pkt_len_min', 'pkt_len_max', 'pkt_len_mean',\n",
       "       'pkt_len_std', 'pkt_len_var', 'fin_flag_cnt', 'syn_flag_cnt',\n",
       "       'rst_flag_cnt', 'psh_flag_cnt', 'ack_flag_cnt', 'urg_flag_cnt',\n",
       "       'cwe_flag_count', 'ece_flag_cnt', 'down_up_ratio', 'pkt_size_avg',\n",
       "       'fwd_seg_size_avg', 'bwd_seg_size_avg', 'fwd_byts_b_avg',\n",
       "       'fwd_pkts_b_avg', 'fwd_blk_rate_avg', 'bwd_byts_b_avg',\n",
       "       'bwd_pkts_b_avg', 'bwd_blk_rate_avg', 'subflow_fwd_pkts',\n",
       "       'subflow_fwd_byts', 'subflow_bwd_pkts', 'subflow_bwd_byts',\n",
       "       'init_fwd_win_byts', 'init_bwd_win_byts', 'fwd_act_data_pkts',\n",
       "       'fwd_seg_size_min', 'active_mean', 'active_std', 'active_max',\n",
       "       'active_min', 'idle_mean', 'idle_std', 'idle_max', 'idle_min', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "decent-lebanon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sampled dataset after oversampling minority classes and undersampling majority classes\n",
      "writing: ../data/CSE-CIC-IDS2018/processed/CSE-CIC-IDS2018-SampledDataset.csv\n",
      "Finished writing:  ../data/CSE-CIC-IDS2018/processed/CSE-CIC-IDS2018-SampledDataset.csv\n"
     ]
    }
   ],
   "source": [
    "print('Creating sampled dataset after oversampling minority classes and undersampling majority classes')\n",
    "sampled_dataset_file_name = os.path.join(processed_path, 'CSE-CIC-IDS2018-SampledDataset.csv')\n",
    "print('writing:', sampled_dataset_file_name)\n",
    "sampled_train.to_csv(sampled_dataset_file_name, index=False)\n",
    "print('Finished writing: ', sampled_dataset_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "smaller-series",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Multi-Class Test File\n",
      "Finished writing:  ../data/CSE-CIC-IDS2018/processed/TEST--DATA-IDS-2018-multiclass.csv\n"
     ]
    }
   ],
   "source": [
    "print('Creating Multi-Class Test File')\n",
    "test_file_name = os.path.join(processed_path, test_prefix + '-' + multi_class_file + '.csv')\n",
    "dftest.to_csv(test_file_name, index=False)\n",
    "print('Finished writing: ', test_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-refrigerator",
   "metadata": {},
   "source": [
    "# Splitting Trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "equivalent-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 1: \n",
    "#     DDOS attack-HOIC + DoS attacks-GoldenEye + Brute Force -Web + SQL Injection: 617411 + 37357 + 550 + 78 = 655,396\n",
    "# Trainer 2: \n",
    "#     DDoS attacks-LOIC-HTTP + Infilteration + Brute Force -XSS: 518572 + 144665 + 207 = 663,444\n",
    "# Trainer 3:\n",
    "#     DoS attacks-Hulk + FTP-BruteForce + DDOS attack-LOIC-UDP: 415721 + 174019 + 1557 = 591,297\n",
    "# Trainer 4: \n",
    "#     Bot + DoS attacks-SlowHTTPTest + SSH-Bruteforce  + DoS attacks-Slowlori: 257572 + 168830 + 125901 + 9891 = 562,194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "smooth-delaware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign                      8435857\n",
       "DoS attacks-Hulk            2410245\n",
       "DDOS attack-HOIC            2410245\n",
       "DDoS attacks-LOIC-HTTP      2410245\n",
       "FTP-BruteForce              1205122\n",
       "Bot                         1205122\n",
       "DoS attacks-SlowHTTPTest    1205122\n",
       "Infilteration               1205122\n",
       "SSH-Bruteforce              1205122\n",
       "DoS attacks-GoldenEye       1205122\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDS_df = pd.read_csv(\"../data/CSE-CIC-IDS2018/processed/CSE-CIC-IDS2018-SampledDataset.csv\", low_memory=False)\n",
    "IDS_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sonic-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1_labels = ['DDOS attack-HOIC', 'DoS attacks-GoldenEye']\n",
    "train_2_labels = ['DDoS attacks-LOIC-HTTP', 'Infilteration' ]\n",
    "train_3_labels = ['DoS attacks-Hulk', 'FTP-BruteForce' ]\n",
    "train_4_labels = ['Bot', 'DoS attacks-SlowHTTPTest', 'SSH-Bruteforce']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "electric-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_1 = IDS_df[IDS_df.label.isin(train_1_labels)]\n",
    "df_train_2 = IDS_df[IDS_df.label.isin(train_2_labels)]\n",
    "df_train_3 = IDS_df[IDS_df.label.isin(train_3_labels)]\n",
    "df_train_4 = IDS_df[IDS_df.label.isin(train_4_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alone-request",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set 1 shape (without benigns): (3615367, 79)\n",
      "Training set 2 shape (without benigns): (3615367, 79)\n",
      "Training set 3 shape (without benigns): (3615367, 79)\n",
      "Training set 4 shape (without benigns): (3615366, 79)\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set 1 shape (without benigns): {df_train_1.shape}')\n",
    "print(f'Training set 2 shape (without benigns): {df_train_2.shape}')\n",
    "print(f'Training set 3 shape (without benigns): {df_train_3.shape}')\n",
    "print(f'Training set 4 shape (without benigns): {df_train_4.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-packet",
   "metadata": {},
   "source": [
    "## Splitting Benign Data Across Trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "occasional-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benign = IDS_df[IDS_df['label'] == 'Benign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dying-hawaiian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8435857, 79)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benign.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "seasonal-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benign = df_benign.sample(frac=1) # Shuffle data\n",
    "df_benign_1, df_benign_2, df_benign_3, df_benign_4 = np.array_split(df_benign, 4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "clean-prototype",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign set 1 shape: (2108965, 79)\n",
      "Benign set 2 shape: (2108964, 79)\n",
      "Benign set 3 shape: (2108964, 79)\n",
      "Benign set 4 shape: (2108964, 79)\n"
     ]
    }
   ],
   "source": [
    "print(f'Benign set 1 shape: {df_benign_1.shape}')\n",
    "print(f'Benign set 2 shape: {df_benign_2.shape}')\n",
    "print(f'Benign set 3 shape: {df_benign_3.shape}')\n",
    "print(f'Benign set 4 shape: {df_benign_4.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-campbell",
   "metadata": {},
   "source": [
    "## Concatenating Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "unique-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_full_1 = pd.concat([df_train_1, df_benign_1])\n",
    "df_train_full_2 = pd.concat([df_train_2, df_benign_2])\n",
    "df_train_full_3 = pd.concat([df_train_3, df_benign_3])\n",
    "df_train_full_4 = pd.concat([df_train_4, df_benign_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mature-hearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset 1 shape: (5724332, 79)\n",
      "Full dataset 2 shape: (5724331, 79)\n",
      "Full dataset 3 shape: (5724331, 79)\n",
      "Full dataset 4 shape: (5724330, 79)\n"
     ]
    }
   ],
   "source": [
    "print(f'Full dataset 1 shape: {df_train_full_1.shape}')\n",
    "print(f'Full dataset 2 shape: {df_train_full_2.shape}')\n",
    "print(f'Full dataset 3 shape: {df_train_full_3.shape}')\n",
    "print(f'Full dataset 4 shape: {df_train_full_4.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-bunny",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-champagne",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-argument",
   "metadata": {},
   "source": [
    "# Writing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "accessory-british",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Multi-Class Test File\n",
      "Finished writing:  ../data/processed/TEST--DATA-IDS-2018-multiclass.csv\n"
     ]
    }
   ],
   "source": [
    "print('Creating Multi-Class Test File')\n",
    "test_file_name = os.path.join(processed_path, test_prefix + '-' + multi_class_file + '.csv')\n",
    "# dftest = dftest.drop('timestamp', axis=1) # Drop timestamp column\n",
    "dftest.drop('timestamp', axis=1).to_csv(test_file_name, index=False)\n",
    "print('Finished writing: ', test_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "indirect-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dict = {\n",
    "    '1': df_train_full_1,\n",
    "    '2': df_train_full_2,\n",
    "    '3': df_train_full_3,\n",
    "    '4': df_train_full_4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "final-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_processed_path = f'{processed_path}_bootstrap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cubic-witness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Multi-Class Oversampled File for Trainer 1\n",
      "Finished writing:  ../data/CSE-CIC-IDS2018/processed_bootstrap/TRAIN-1-DATA-IDS-2018-multiclass-bootstrap.csv\n",
      "Creating Multi-Class Oversampled File for Trainer 2\n",
      "Finished writing:  ../data/CSE-CIC-IDS2018/processed_bootstrap/TRAIN-2-DATA-IDS-2018-multiclass-bootstrap.csv\n",
      "Creating Multi-Class Oversampled File for Trainer 3\n",
      "Finished writing:  ../data/CSE-CIC-IDS2018/processed_bootstrap/TRAIN-3-DATA-IDS-2018-multiclass-bootstrap.csv\n",
      "Creating Multi-Class Oversampled File for Trainer 4\n",
      "Finished writing:  ../data/CSE-CIC-IDS2018/processed_bootstrap/TRAIN-4-DATA-IDS-2018-multiclass-bootstrap.csv\n"
     ]
    }
   ],
   "source": [
    "for i in df_train_dict.keys():\n",
    "    print(f'Creating Multi-Class Oversampled File for Trainer {i}')\n",
    "    train_file_name = os.path.join(bootstrap_processed_path, f'{train_prefix}{i}-{multi_class_file}-bootstrap.csv')\n",
    "    df_train_dict[i].to_csv(train_file_name, index=False)\n",
    "    print('Finished writing: ', train_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
