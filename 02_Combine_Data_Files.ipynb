{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d512e080",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:51:14.473891Z",
     "start_time": "2021-04-04T02:51:14.421978Z"
    }
   },
   "outputs": [],
   "source": [
    "#############################################################################################\n",
    "# Notebook to be used for combining, downsampling, creating binary and/or multiclass files, #\n",
    "# and creating csv and/or pickle files.                                                     #\n",
    "#############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10b26a07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:51:14.513753Z",
     "start_time": "2021-04-04T02:51:14.488605Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c150cee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:51:14.543932Z",
     "start_time": "2021-04-04T02:51:14.526102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of the cleaned data files\n",
    "# CONFIG NEEDED: Uncomment only the specific files to be processed on your node\n",
    "\n",
    "cleaned_csv_files = [\n",
    " '02-14-2018-bruteforce-ftp-ssh.csv',\n",
    " '02-15-2018-dos-goldeneye-slowloris.csv',\n",
    " '02-16-2018-dos-slowhttp-hulk.csv',\n",
    "# '02-20-2018-ddos-loic-tcp.csv'   # WARNING: 4GB FILE.\n",
    " '02-21-2018-ddos-loic-udp.csv',\n",
    " '02-22-2018-bruteforce-webxss.csv',\n",
    " '02-23-2018-bruteforce-webxss-sql.csv',\n",
    " '02-28-2018-infiltration.csv',\n",
    " '03-01-2018-botnet.csv',\n",
    " '03-02-2018-infiltration.csv'\n",
    "]\n",
    "\n",
    "# CONFIG NEEDED: Change Binary and Multi-class output file names if needed\n",
    "multi_class_file = 'IDS-2018-multiclass'\n",
    "binary_class_file = 'IDS-2018-binaryclass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f463d628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:51:14.570109Z",
     "start_time": "2021-04-04T02:51:14.551690Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the folder name for raw data and processed files under the project directory\n",
    "# CONFIG NEEDED: Change the './data' and 'processed' to what you named your directories\n",
    "# Raw Data Files Location: final_project/data\n",
    "# Processed Data Files Location: final_project/data/processed\n",
    "\n",
    "rawdata_path = './data'\n",
    "processed_path = os.path.join(rawdata_path, 'processed')\n",
    "\n",
    "# CONFIG NEEDED: Change to true if you want to downsample data and update the sample size as needed\n",
    "down_sample = True\n",
    "sample_size = 10000\n",
    "\n",
    "# CONFIG NEEDED: Change to true as needed for multi-class or binary class files. \n",
    "# Note atleast one of these has to be true for the combined data file to be created. \n",
    "multi_class = True\n",
    "binary_class = True\n",
    "\n",
    "# CONFIG NEEDED: Change to true if you want to create a pickle file.\n",
    "create_pickle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73b85b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:51:14.591075Z",
     "start_time": "2021-04-04T02:51:14.576290Z"
    }
   },
   "outputs": [],
   "source": [
    "# Return the selected sample based on global setting\n",
    "def get_samples(x):\n",
    "    global sample_size\n",
    "    if sample_size > x.shape[0]:\n",
    "        return x\n",
    "    else:\n",
    "        return x.sample(sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fbd56f23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:53:01.452979Z",
     "start_time": "2021-04-04T02:51:14.598311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading: ./data/processed/02-14-2018-bruteforce-ftp-ssh.csv\n",
      "downsampled: ./data/processed/02-14-2018-bruteforce-ftp-ssh.csv\n",
      "(30000, 80)\n",
      "appending: ./data/processed/02-15-2018-dos-goldeneye-slowloris.csv\n",
      "downsampled: ./data/processed/02-15-2018-dos-goldeneye-slowloris.csv\n",
      "updated datafile shape\n",
      "(60000, 80)\n",
      "appending: ./data/processed/02-16-2018-dos-slowhttp-hulk.csv\n",
      "downsampled: ./data/processed/02-16-2018-dos-slowhttp-hulk.csv\n",
      "updated datafile shape\n",
      "(90000, 80)\n",
      "appending: ./data/processed/02-21-2018-ddos-loic-udp.csv\n",
      "downsampled: ./data/processed/02-21-2018-ddos-loic-udp.csv\n",
      "updated datafile shape\n",
      "(111730, 80)\n",
      "appending: ./data/processed/02-22-2018-bruteforce-webxss.csv\n",
      "downsampled: ./data/processed/02-22-2018-bruteforce-webxss.csv\n",
      "updated datafile shape\n",
      "(122092, 80)\n",
      "appending: ./data/processed/02-23-2018-bruteforce-webxss-sql.csv\n",
      "downsampled: ./data/processed/02-23-2018-bruteforce-webxss-sql.csv\n",
      "updated datafile shape\n",
      "(132658, 80)\n",
      "appending: ./data/processed/02-28-2018-infiltration.csv\n",
      "downsampled: ./data/processed/02-28-2018-infiltration.csv\n",
      "updated datafile shape\n",
      "(152658, 80)\n",
      "appending: ./data/processed/03-01-2018-botnet.csv\n",
      "downsampled: ./data/processed/03-01-2018-botnet.csv\n",
      "updated datafile shape\n",
      "(172658, 80)\n",
      "appending: ./data/processed/03-02-2018-infiltration.csv\n",
      "downsampled: ./data/processed/03-02-2018-infiltration.csv\n",
      "updated datafile shape\n",
      "(192658, 80)\n",
      "final datafile\n",
      "(192658, 80)\n"
     ]
    }
   ],
   "source": [
    "# Read the first file from the list to be processed\n",
    "fname = os.path.join(processed_path, cleaned_csv_files[0])\n",
    "print('reading:', fname)\n",
    "df = pd.read_csv(fname)\n",
    "\n",
    "# If downsampling required, select sample as appropriate\n",
    "if down_sample:\n",
    "    df=df.groupby('label', as_index=False, group_keys=False).apply(get_samples)\n",
    "    # Print name if downsampled\n",
    "    print('downsampled:', fname)\n",
    "\n",
    "# Check if created/downsampled correctly\n",
    "print(df.shape)\n",
    "\n",
    "# Read the remaining files in the list and downsample as needed\n",
    "for name in cleaned_csv_files[1:]:\n",
    "    fname = os.path.join(processed_path, name)\n",
    "    print('appending:', fname)\n",
    "    df1 = pd.read_csv(fname)\n",
    "\n",
    "    if down_sample:\n",
    "        df1=df1.groupby('label', as_index=False, group_keys=False).apply(get_samples)\n",
    "        # Print name if downsampled\n",
    "        print('downsampled:', fname)\n",
    "    \n",
    "    df = df.append(df1, ignore_index=True)\n",
    "\n",
    "    # Check if created/downsampled correctly\n",
    "    print('updated datafile shape')\n",
    "    print(df.shape)  \n",
    "\n",
    "# Shuffle the data records and print final shape\n",
    "df = shuffle(df)\n",
    "print('final datafile')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d75ba848",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:53:22.531979Z",
     "start_time": "2021-04-04T02:53:01.460398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating multi-class file\n"
     ]
    }
   ],
   "source": [
    "# Create a multi-class label file\n",
    "if multi_class:\n",
    "    print('creating multi-class file')\n",
    "    outFile = os.path.join(processed_path, multi_class_file)\n",
    "    df.to_csv(outFile + '.csv', index=False)\n",
    "    if create_pickle: # if pickle file is requested\n",
    "        df.to_pickle(outFile + '.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df766d5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:53:22.640101Z",
     "start_time": "2021-04-04T02:53:22.540437Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print multi-class label counts to verify\n",
    "if multi_class:\n",
    "    df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e7795b2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T03:47:46.489482Z",
     "start_time": "2021-04-04T03:47:26.514701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating binary-class file\n"
     ]
    }
   ],
   "source": [
    "# Create a binary-class label file\n",
    "if binary_class:\n",
    "    print('creating binary-class file')\n",
    "    \n",
    "    # Map benign rows to 0, all others as 1\n",
    "    df['label'] = df['label'].map(\n",
    "        {'Benign': 0, 'FTP-BruteForce': 1, 'SSH-Bruteforce': 1, 'DoS attacks-GoldenEye': 1, 'DoS attacks-Slowloris': 1,\n",
    "         'DoS attacks-SlowHTTPTest': 1, 'DoS attacks-Hulk': 1, 'Brute Force -Web': 1, 'Brute Force -XSS': 1,\n",
    "         'SQL Injection': 1, 'Infilteration': 1, 'Bot': 1})\n",
    "    \n",
    "    outFile = os.path.join(processed_path, binary_class_file)\n",
    "    df.to_csv(outFile + '.csv', index=False)\n",
    "    df.to_pickle(outFile + '.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1828148a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:53:43.259661Z",
     "start_time": "2021-04-04T02:53:43.236301Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print binary-class label counts to verify\n",
    "if binary_class:\n",
    "    df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "709a7d53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:53:43.279853Z",
     "start_time": "2021-04-04T02:53:43.266018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all done...\n"
     ]
    }
   ],
   "source": [
    "print('all done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3942413",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:53:43.295118Z",
     "start_time": "2021-04-04T02:53:43.287531Z"
    }
   },
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# Cells below this are only needed if you want to test if the files were created correctly #\n",
    "# Comment/Uncomment as needed\n",
    "############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6aa1897c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:53:45.880501Z",
     "start_time": "2021-04-04T02:53:43.303141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign                      90000\n",
       "Infilteration               20000\n",
       "Bot                         10000\n",
       "DoS attacks-Hulk            10000\n",
       "DoS attacks-Slowloris       10000\n",
       "FTP-BruteForce              10000\n",
       "DoS attacks-GoldenEye       10000\n",
       "DDOS attack-HOIC            10000\n",
       "DoS attacks-SlowHTTPTest    10000\n",
       "SSH-Bruteforce              10000\n",
       "DDOS attack-LOIC-UDP         1730\n",
       "Brute Force -Web              611\n",
       "Brute Force -XSS              230\n",
       "SQL Injection                  87\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a sample file and check label counts\n",
    "# CONFIG NEEDED: Change file name to the file you want to check\n",
    "df = pd.read_csv(\"./data/processed/IDS-2018-multiclass.csv\")\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7faeb283",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:53:48.371467Z",
     "start_time": "2021-04-04T02:53:45.887001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    90928\n",
       "0.0    90000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a sample file and check label counts\n",
    "# CONFIG NEEDED: Change file name to the file you want to check\n",
    "df1 = pd.read_csv(\"./data/processed/IDS-2018-binaryclass.csv\")\n",
    "df1['label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
