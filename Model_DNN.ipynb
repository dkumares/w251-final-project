{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:38</td>\n",
       "      <td>141385</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>553</td>\n",
       "      <td>3773.0</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49684</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:38</td>\n",
       "      <td>281</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:40</td>\n",
       "      <td>279824</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>1086</td>\n",
       "      <td>10527.0</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:40</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:41</td>\n",
       "      <td>274016</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>1285</td>\n",
       "      <td>6141.0</td>\n",
       "      <td>517</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dst Port  Protocol            Timestamp  Flow Duration  Tot Fwd Pkts  \\\n",
       "0       443         6  02/03/2018 08:47:38         141385             9   \n",
       "1     49684         6  02/03/2018 08:47:38            281             2   \n",
       "2       443         6  02/03/2018 08:47:40         279824            11   \n",
       "3       443         6  02/03/2018 08:47:40            132             2   \n",
       "4       443         6  02/03/2018 08:47:41         274016             9   \n",
       "\n",
       "   Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  \\\n",
       "0             7              553           3773.0              202   \n",
       "1             1               38              0.0               38   \n",
       "2            15             1086          10527.0              385   \n",
       "3             0                0              0.0                0   \n",
       "4            13             1285           6141.0              517   \n",
       "\n",
       "   Fwd Pkt Len Min  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
       "0                0  ...                20          0.0         0.0   \n",
       "1                0  ...                20          0.0         0.0   \n",
       "2                0  ...                20          0.0         0.0   \n",
       "3                0  ...                20          0.0         0.0   \n",
       "4                0  ...                20          0.0         0.0   \n",
       "\n",
       "   Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min   Label  \n",
       "0         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
       "1         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
       "2         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
       "3         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
       "4         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDS_df = pd.read_csv(\"./Data/CSE-CIC-IDS2018/03-02-2018.csv\")\n",
    "\n",
    "# To display the top 5 rows\n",
    "IDS_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048575, 80)\n"
     ]
    }
   ],
   "source": [
    "# print shape before dropping NaN rows\n",
    "print(IDS_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8100\n"
     ]
    }
   ],
   "source": [
    "# Finding the null values.\n",
    "print(IDS_df.isin([np.nan, np.inf, -np.inf]).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  first replace infs to NaN:\n",
    "IDS_df = IDS_df.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044525, 80)\n"
     ]
    }
   ],
   "source": [
    "# print shape after dropping NaN rows\n",
    "IDS_df = IDS_df.dropna()\n",
    "print(IDS_df.shape)\n",
    "IDS_df = IDS_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Finding the null values.\n",
    "print(IDS_df.isin([np.nan, np.inf, -np.inf]).sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the proportion of types of traffic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Benign', 758334), ('Bot', 286191)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = IDS_df[\"Label\"].values\n",
    "from collections import Counter\n",
    "\n",
    "Counter(y).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all non-normal observations into a single class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_anomalous(text):\n",
    "    \"\"\"Binarize target labels into normal or anomalous.\"\"\"\n",
    "    if text == \"Benign\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "IDS_df[\"Label\"] = IDS_df[\"Label\"].apply(label_anomalous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 758334), (1, 286191)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = IDS_df[\"Label\"].values\n",
    "Counter(y).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all categorical features into numerical form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encodings_dictionary = dict()\n",
    "for c in IDS_df.columns:\n",
    "    if IDS_df[c].dtype == \"object\":\n",
    "        encodings_dictionary[c] = LabelEncoder()\n",
    "        IDS_df[c] = encodings_dictionary[c].fit_transform(IDS_df[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into normal and abnormal observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDS_df_normal = IDS_df[IDS_df[\"Label\"] == 0]\n",
    "IDS_df_abnormal = IDS_df[IDS_df[\"Label\"] == 1]\n",
    "y_normal = IDS_df_normal.pop(\"Label\").values\n",
    "X_normal = IDS_df_normal.values\n",
    "y_anomaly = IDS_df_abnormal.pop(\"Label\").values\n",
    "X_anomaly = IDS_df_abnormal.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test split the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_normal_train, X_normal_test, y_normal_train, y_normal_test = train_test_split(\n",
    "    X_normal, y_normal, test_size=0.3, random_state=11\n",
    ")\n",
    "X_anomaly_train, X_anomaly_test, y_anomaly_train, y_anomaly_test = train_test_split(\n",
    "    X_anomaly, y_anomaly, test_size=0.3, random_state=11\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.concatenate((X_normal_train, X_anomaly_train))\n",
    "y_train = np.concatenate((y_normal_train, y_anomaly_train))\n",
    "X_test = np.concatenate((X_normal_test, X_anomaly_test))\n",
    "y_test = np.concatenate((y_normal_test, y_anomaly_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed loading data\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "# Pytorch\n",
    "X_train  = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train)\n",
    "\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "valid = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "print('Completed loading data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.tensors[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=79, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "        \n",
    "# Defining the DNN model\n",
    "input_size = train_loader.dataset.tensors[0].shape[1]\n",
    "hidden_layers = [128,64]\n",
    "output_size = 2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size, hidden_layers[0]),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_layers[0], hidden_layers[1]),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_layers[1], output_size),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "print(model)\n",
    "model.to(device)\n",
    "\n",
    " # Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss().to(device)\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.001\n",
    "# TODO: Try SGD\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Iteration: 0  Loss: 0.316585510969162  Accuracy: 72.60075378417969 %\n",
      "Iteration: 100  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 200  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 300  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 400  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 500  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 600  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 700  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 800  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 900  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1000  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1100  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1200  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1300  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1400  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1500  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1600  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1700  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1800  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1900  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 2000  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 2100  Loss: 1.313262701034546  Accuracy: 72.60075378417969 %\n",
      "Iteration: 2200  Loss: 1.313262701034546  Accuracy: 72.60075378417969 %\n",
      "Iteration: 2300  Loss: 1.313262701034546  Accuracy: 72.60075378417969 %\n",
      "Iteration: 2400  Loss: 1.313262701034546  Accuracy: 72.60075378417969 %\n",
      "Iteration: 2500  Loss: 1.313262701034546  Accuracy: 72.60075378417969 %\n",
      "Iteration: 2600  Loss: 1.313262701034546  Accuracy: 72.60075378417969 %\n",
      "Iteration: 2700  Loss: 1.313262701034546  Accuracy: 72.60075378417969 %\n",
      "Iteration: 2800  Loss: 1.313262701034546  Accuracy: 72.60075378417969 %\n",
      "Iteration: 0  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 100  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 200  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 300  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 400  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 500  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 600  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 700  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 800  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 900  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1000  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1100  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1200  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1300  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1400  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1500  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1600  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1700  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1800  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 1900  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 2000  Loss: 0.31326231360435486  Accuracy: 72.60075378417969 %\n",
      "Iteration: 2100  Loss: 1.313262701034546  Accuracy: 72.60075378417969 %\n",
      "Iteration: 2200  Loss: 1.313262701034546  Accuracy: 72.60075378417969 %\n",
      "Iteration: 2300  Loss: 1.313262701034546  Accuracy: 72.60075378417969 %\n"
     ]
    }
   ],
   "source": [
    "print('Start training...')\n",
    "start_time = time.time()\n",
    "    \n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    count = 0\n",
    "    loss_list = []\n",
    "    iteration_list = []\n",
    "    accuracy_list = []\n",
    "   \n",
    "    for i, (data, labels) in enumerate(train_loader):\n",
    "        train = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for data, labels in valid_loader:\n",
    "                valid = data.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward propagation\n",
    "                outputs = model(valid)\n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "\n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / float(total)\n",
    "\n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "        if count % 100 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data, accuracy))\n",
    "\n",
    "        count += 1\n",
    "\n",
    "end_time = time.time()\n",
    "print('Epochs completed. Time taken (seconds): ', str(end_time - start_time))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
