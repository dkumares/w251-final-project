{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = '../data/CSE-CIC-IDS2018/processed'\n",
    "cleaned_csv_files = [\n",
    "  '02-14-2018-bruteforce-ftp-ssh.csv',\n",
    "  '02-15-2018-dos-goldeneye-slowloris.csv',\n",
    "  '02-16-2018-dos-slowhttp-hulk.csv',\n",
    "  '02-21-2018-ddos-loic-udp.csv',\n",
    "  '02-22-2018-bruteforce-webxss.csv',\n",
    "  '02-23-2018-bruteforce-webxss-sql.csv',\n",
    "  '02-28-2018-infiltration.csv',\n",
    "  '03-01-2018-botnet.csv',\n",
    "  '03-02-2018-infiltration.csv'\n",
    "  #'02-20-2018-ddos-loic-tcp.csv'   # WARNING: 4GB FILE.\n",
    "]\n",
    "\n",
    "list_of_dataframes = []\n",
    "for filename in cleaned_csv_files:\n",
    "    fname = os.path.join(processed_path, filename)\n",
    "    list_of_dataframes.append(pd.read_csv(fname))\n",
    "\n",
    "IDS_df = pd.concat(list_of_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dst_port', 'protocol', 'timestamp', 'flow_duration', 'tot_fwd_pkts',\n",
       "       'tot_bwd_pkts', 'totlen_fwd_pkts', 'totlen_bwd_pkts', 'fwd_pkt_len_max',\n",
       "       'fwd_pkt_len_min', 'fwd_pkt_len_mean', 'fwd_pkt_len_std',\n",
       "       'bwd_pkt_len_max', 'bwd_pkt_len_min', 'bwd_pkt_len_mean',\n",
       "       'bwd_pkt_len_std', 'flow_byts_s', 'flow_pkts_s', 'flow_iat_mean',\n",
       "       'flow_iat_std', 'flow_iat_max', 'flow_iat_min', 'fwd_iat_tot',\n",
       "       'fwd_iat_mean', 'fwd_iat_std', 'fwd_iat_max', 'fwd_iat_min',\n",
       "       'bwd_iat_tot', 'bwd_iat_mean', 'bwd_iat_std', 'bwd_iat_max',\n",
       "       'bwd_iat_min', 'fwd_psh_flags', 'bwd_psh_flags', 'fwd_urg_flags',\n",
       "       'bwd_urg_flags', 'fwd_header_len', 'bwd_header_len', 'fwd_pkts_s',\n",
       "       'bwd_pkts_s', 'pkt_len_min', 'pkt_len_max', 'pkt_len_mean',\n",
       "       'pkt_len_std', 'pkt_len_var', 'fin_flag_cnt', 'syn_flag_cnt',\n",
       "       'rst_flag_cnt', 'psh_flag_cnt', 'ack_flag_cnt', 'urg_flag_cnt',\n",
       "       'cwe_flag_count', 'ece_flag_cnt', 'down_up_ratio', 'pkt_size_avg',\n",
       "       'fwd_seg_size_avg', 'bwd_seg_size_avg', 'fwd_byts_b_avg',\n",
       "       'fwd_pkts_b_avg', 'fwd_blk_rate_avg', 'bwd_byts_b_avg',\n",
       "       'bwd_pkts_b_avg', 'bwd_blk_rate_avg', 'subflow_fwd_pkts',\n",
       "       'subflow_fwd_byts', 'subflow_bwd_pkts', 'subflow_bwd_byts',\n",
       "       'init_fwd_win_byts', 'init_bwd_win_byts', 'fwd_act_data_pkts',\n",
       "       'fwd_seg_size_min', 'active_mean', 'active_std', 'active_max',\n",
       "       'active_min', 'idle_mean', 'idle_std', 'idle_max', 'idle_min', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IDS_df = pd.read_csv(\"../data/CSE-CIC-IDS2018/TRAINER-03-IDS-2018-multiclass.csv\")\n",
    "\n",
    "# To display the top 5 rows/\n",
    "# IDS_df.head(5)\n",
    "IDS_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDS_df = IDS_df.drop('timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dst_port - int64\n",
      "protocol - int64\n",
      "flow_duration - int64\n",
      "tot_fwd_pkts - int64\n",
      "tot_bwd_pkts - int64\n",
      "totlen_fwd_pkts - int64\n",
      "totlen_bwd_pkts - float64\n",
      "fwd_pkt_len_max - int64\n",
      "fwd_pkt_len_min - int64\n",
      "fwd_pkt_len_mean - float64\n",
      "fwd_pkt_len_std - float64\n",
      "bwd_pkt_len_max - int64\n",
      "bwd_pkt_len_min - int64\n",
      "bwd_pkt_len_mean - float64\n",
      "bwd_pkt_len_std - float64\n",
      "flow_byts_s - float64\n",
      "flow_pkts_s - float64\n",
      "flow_iat_mean - float64\n",
      "flow_iat_std - float64\n",
      "flow_iat_max - float64\n",
      "flow_iat_min - float64\n",
      "fwd_iat_tot - float64\n",
      "fwd_iat_mean - float64\n",
      "fwd_iat_std - float64\n",
      "fwd_iat_max - float64\n",
      "fwd_iat_min - float64\n",
      "bwd_iat_tot - float64\n",
      "bwd_iat_mean - float64\n",
      "bwd_iat_std - float64\n",
      "bwd_iat_max - float64\n",
      "bwd_iat_min - float64\n",
      "fwd_psh_flags - int64\n",
      "bwd_psh_flags - int64\n",
      "fwd_urg_flags - int64\n",
      "bwd_urg_flags - int64\n",
      "fwd_header_len - int64\n",
      "bwd_header_len - int64\n",
      "fwd_pkts_s - float64\n",
      "bwd_pkts_s - float64\n",
      "pkt_len_min - int64\n",
      "pkt_len_max - int64\n",
      "pkt_len_mean - float64\n",
      "pkt_len_std - float64\n",
      "pkt_len_var - float64\n",
      "fin_flag_cnt - int64\n",
      "syn_flag_cnt - int64\n",
      "rst_flag_cnt - int64\n",
      "psh_flag_cnt - int64\n",
      "ack_flag_cnt - int64\n",
      "urg_flag_cnt - int64\n",
      "cwe_flag_count - int64\n",
      "ece_flag_cnt - int64\n",
      "down_up_ratio - int64\n",
      "pkt_size_avg - float64\n",
      "fwd_seg_size_avg - float64\n",
      "bwd_seg_size_avg - float64\n",
      "fwd_byts_b_avg - int64\n",
      "fwd_pkts_b_avg - int64\n",
      "fwd_blk_rate_avg - int64\n",
      "bwd_byts_b_avg - int64\n",
      "bwd_pkts_b_avg - int64\n",
      "bwd_blk_rate_avg - int64\n",
      "subflow_fwd_pkts - int64\n",
      "subflow_fwd_byts - int64\n",
      "subflow_bwd_pkts - int64\n",
      "subflow_bwd_byts - int64\n",
      "init_fwd_win_byts - int64\n",
      "init_bwd_win_byts - int64\n",
      "fwd_act_data_pkts - int64\n",
      "fwd_seg_size_min - int64\n",
      "active_mean - float64\n",
      "active_std - float64\n",
      "active_max - float64\n",
      "active_min - float64\n",
      "idle_mean - float64\n",
      "idle_std - float64\n",
      "idle_max - float64\n",
      "idle_min - float64\n",
      "label - object\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(IDS_df.columns)):\n",
    "     print(IDS_df.columns[i], '-', IDS_df.dtypes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8270842, 79)\n"
     ]
    }
   ],
   "source": [
    "# print shape before dropping NaN rows\n",
    "print(IDS_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45908\n"
     ]
    }
   ],
   "source": [
    "# Finding the null values.\n",
    "print(IDS_df.isin([np.nan, np.inf, -np.inf]).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  first replace infs to NaN:\n",
    "IDS_df = IDS_df.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8247888, 79)\n"
     ]
    }
   ],
   "source": [
    "# print shape after dropping NaN rows\n",
    "IDS_df = IDS_df.dropna()\n",
    "print(IDS_df.shape)\n",
    "IDS_df = IDS_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Finding the null values.\n",
    "print(IDS_df.isin([np.nan, np.inf, -np.inf]).sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the proportion of types of traffic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign                      6077145\n",
       "DDOS attack-HOIC             686012\n",
       "DoS attacks-Hulk             461912\n",
       "Bot                          286191\n",
       "FTP-BruteForce               193354\n",
       "SSH-Bruteforce               187589\n",
       "Infilteration                160639\n",
       "DoS attacks-SlowHTTPTest     139890\n",
       "DoS attacks-GoldenEye         41508\n",
       "DoS attacks-Slowloris         10990\n",
       "DDOS attack-LOIC-UDP           1730\n",
       "Brute Force -Web                611\n",
       "Brute Force -XSS                230\n",
       "SQL Injection                    87\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDS_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all non-normal observations into a single class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(text):    \n",
    "    if text == \"Benign\":\n",
    "        return 0\n",
    "    elif text == 'Infilteration':\n",
    "        return 1\n",
    "    elif text == 'DoS attacks-Slowloris':\n",
    "        return 2\n",
    "    elif text == 'SSH-Bruteforce':\n",
    "        return 3\n",
    "    elif text == 'DDOS attack-HOIC':\n",
    "        return 4\n",
    "    elif text == 'FTP-BruteForce':\n",
    "        return 5\n",
    "    elif text == 'DoS attacks-SlowHTTPTest':\n",
    "        return 6\n",
    "    elif text == 'Bot':\n",
    "        return 7\n",
    "    elif text == 'DoS attacks-Hulk':\n",
    "        return 8\n",
    "    elif text == 'DoS attacks-GoldenEye':\n",
    "        return 9\n",
    "    elif text == 'DDoS attacks-LOIC-HTTP':\n",
    "        return 10\n",
    "    elif text == 'DDOS attack-LOIC-UDP':\n",
    "        return 11\n",
    "    elif text == 'Brute Force -Web':\n",
    "        return 12\n",
    "    elif text == 'Brute Force -XSS':\n",
    "        return 13\n",
    "    elif text == 'SQL Injection':\n",
    "        return 14\n",
    "\n",
    "IDS_df[\"label\"] = IDS_df[\"label\"].apply(get_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     6077145\n",
      "4      686012\n",
      "8      461912\n",
      "7      286191\n",
      "5      193354\n",
      "3      187589\n",
      "1      160639\n",
      "6      139890\n",
      "9       41508\n",
      "2       10990\n",
      "11       1730\n",
      "12        611\n",
      "13        230\n",
      "14         87\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#y = IDS_df[\"Label\"].values\n",
    "print(IDS_df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all categorical features into numerical form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encodings_dictionary = dict()\n",
    "for c in IDS_df.columns:\n",
    "    if IDS_df[c].dtype == \"object\":\n",
    "        encodings_dictionary[c] = LabelEncoder()\n",
    "        IDS_df[c] = encodings_dictionary[c].fit_transform(IDS_df[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Stratified K Fold to split the data into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state = seed)\n",
    "target = IDS_df.loc[:,'label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test split the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPyTorchDataLoaders(x_train, x_test, y_train, y_test, batch_size = 1000):\n",
    "    # Pytorch\n",
    "    X_train  = torch.from_numpy(x_train).float()\n",
    "    Y_train = torch.from_numpy(y_train)\n",
    "\n",
    "    X_test = torch.from_numpy(x_test).float()\n",
    "    Y_test = torch.from_numpy(y_test)\n",
    "\n",
    "    # Pytorch train and test sets\n",
    "    train = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "    valid = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "\n",
    "    # data loader\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    print('Completed loading data and returning pytorch train and validation data loaders')\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (layer1): Linear(in_features=78, out_features=256, bias=True)\n",
      "  (activ1): ReLU()\n",
      "  (layer2): Linear(in_features=256, out_features=15, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "        \n",
    "# Defining the DNN model\n",
    "#input_size = train_loader.dataset.tensors[0].shape[1]\n",
    "input_size = 78\n",
    "hidden_layers = [256]\n",
    "output_size = 15\n",
    "\n",
    "# model definition\n",
    "class MLP(nn.Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_inputs, hidden_layers[0])\n",
    "        self.activ1 = nn.ReLU()\n",
    "        \n",
    "        #self.layer2 = nn.Linear(hidden_layers[0], hidden_layers[1])\n",
    "        #self.activ2 = nn.ReLU()\n",
    "\n",
    "        #self.layer3 = nn.Linear(hidden_layers[1], hidden_layers[2])\n",
    "        #self.activ3 = nn.ReLU()\n",
    "        \n",
    "        self.layer2 = nn.Linear(hidden_layers[0], output_size)\n",
    "        \n",
    "    # forward propagate input\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.activ1(x)\n",
    "        \n",
    "        #x = self.layer2(x)\n",
    "        #x = self.activ2(x)\n",
    "        \n",
    "        #x = self.layer3(x)\n",
    "        #x = self.activ3(x)\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "model = MLP(input_size)\n",
    "print(model)\n",
    "model.to(device)\n",
    "\n",
    " # Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss().to(device)\n",
    "# Adam Optimizer\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train, test, fold_no):\n",
    "    print('Start training...')\n",
    "    start_time = time.time()\n",
    "\n",
    "    epochs = 1\n",
    "\n",
    "    count = 0\n",
    "    loss_list = []\n",
    "    iteration_list = []\n",
    "    accuracy_list = []\n",
    "    accuracy_scores = []\n",
    "    \n",
    "    # Separate into training data and labels, testing data and labels\n",
    "    Y_train = train.pop(\"label\").values\n",
    "    X_train = train.values\n",
    "    \n",
    "    Y_test = test.pop(\"label\").values\n",
    "    X_test = test.values\n",
    "    \n",
    "    # Get PyTorch training and validation data loaders\n",
    "    train_loader, valid_loader = GetPyTorchDataLoaders(X_train, X_test, Y_train, Y_test, batch_size = 1000)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        correct_epoch = 0\n",
    "        total_epoch = 0\n",
    "        for i, (data, labels) in enumerate(train_loader):\n",
    "            train = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = model(train)\n",
    "\n",
    "            # Calculate softmax and cross entropy loss\n",
    "            loss = error(outputs, labels)\n",
    "\n",
    "            # Calculating gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            if count % 100 == 0:\n",
    "                # Calculate Accuracy         \n",
    "                correct = 0\n",
    "                total = 0\n",
    "\n",
    "                # Iterate through test dataset\n",
    "                for data, labels in valid_loader:\n",
    "                    valid = data.to(device)                               \n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # Forward propagation\n",
    "                    outputs = model(valid)\n",
    "\n",
    "                    # Get predictions from the maximum value\n",
    "                    predicted = torch.max(outputs.data, 1)[1]\n",
    "\n",
    "                    #print('Predicted: ', predicted)\n",
    "\n",
    "                    # Total number of labels\n",
    "                    total += len(labels)\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "                accuracy = 100 * correct / float(total)\n",
    "\n",
    "                # store loss and iteration\n",
    "                loss_list.append(loss.data)\n",
    "                iteration_list.append(count)\n",
    "                accuracy_list.append(accuracy)\n",
    "                \n",
    "            if count % 100 == 0:\n",
    "                # Print Loss\n",
    "                print('Epoch: {} Iteration: {}  Loss: {}  Accuracy: {} %'.format(e + 1, count, loss.data, accuracy))\n",
    "\n",
    "            count += 1\n",
    "        \n",
    "        \n",
    "        # calculate accuracy on the validation set\n",
    "        # Iterate through test dataset\n",
    "        for data, labels in valid_loader:\n",
    "            valid = data.to(device)                               \n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = model(valid)\n",
    "\n",
    "            # Get predictions from the maximum value\n",
    "            predicted = torch.max(outputs.data, 1)[1]\n",
    "            \n",
    "            total_epoch += len(labels)\n",
    "            correct_epoch += (predicted == labels).sum()\n",
    "\n",
    "        accuracy_epoch = (100 * correct_epoch / float(total_epoch)).item()\n",
    "\n",
    "        print('Fold',str(fold_no), 'Epoch No. :', e, 'Accuracy for Epoch :', accuracy_epoch)\n",
    "\n",
    "    end_time = time.time()\n",
    "    accuracy_scores.append(accuracy_epoch)\n",
    "    mean_accuracy_score = np.mean(accuracy_scores)\n",
    "    print('Epochs completed. Time taken (seconds): ', str(end_time - start_time))\n",
    "    print('Average accuracy over all epochs', mean_accuracy_score)\n",
    "    return mean_accuracy_score\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Completed loading data and returning pytorch train and validation data loaders\n",
      "Epoch: 1 Iteration: 0  Loss: 3099.1455078125  Accuracy: 84.47628021240234 %\n",
      "Epoch: 1 Iteration: 100  Loss: 5265.826171875  Accuracy: 87.5980453491211 %\n",
      "Epoch: 1 Iteration: 200  Loss: 6888.2958984375  Accuracy: 85.92149353027344 %\n",
      "Epoch: 1 Iteration: 300  Loss: 8548.7060546875  Accuracy: 88.19576263427734 %\n",
      "Epoch: 1 Iteration: 400  Loss: 3928.36572265625  Accuracy: 89.48458862304688 %\n",
      "Epoch: 1 Iteration: 500  Loss: 15927.6259765625  Accuracy: 90.6816177368164 %\n",
      "Epoch: 1 Iteration: 600  Loss: 8574.859375  Accuracy: 80.83631134033203 %\n",
      "Epoch: 1 Iteration: 700  Loss: 2583.40771484375  Accuracy: 84.34617614746094 %\n",
      "Epoch: 1 Iteration: 800  Loss: 1045.3656005859375  Accuracy: 88.74609375 %\n",
      "Epoch: 1 Iteration: 900  Loss: 8936.9521484375  Accuracy: 88.21868133544922 %\n",
      "Epoch: 1 Iteration: 1000  Loss: 7732.67431640625  Accuracy: 90.44943237304688 %\n",
      "Epoch: 1 Iteration: 1100  Loss: 413.5671691894531  Accuracy: 89.26185607910156 %\n",
      "Epoch: 1 Iteration: 1200  Loss: 2023.541748046875  Accuracy: 88.45947265625 %\n",
      "Epoch: 1 Iteration: 1300  Loss: 5990.80908203125  Accuracy: 90.61444854736328 %\n",
      "Epoch: 1 Iteration: 1400  Loss: 2896.251953125  Accuracy: 90.38481140136719 %\n",
      "Epoch: 1 Iteration: 1500  Loss: 3152.70654296875  Accuracy: 91.67387390136719 %\n",
      "Epoch: 1 Iteration: 1600  Loss: 6052.86328125  Accuracy: 91.55553436279297 %\n",
      "Epoch: 1 Iteration: 1700  Loss: 698.533935546875  Accuracy: 90.84941864013672 %\n",
      "Epoch: 1 Iteration: 1800  Loss: 2506.744140625  Accuracy: 89.09102630615234 %\n",
      "Epoch: 1 Iteration: 1900  Loss: 1596.085693359375  Accuracy: 89.35012817382812 %\n",
      "Epoch: 1 Iteration: 2000  Loss: 3399.6357421875  Accuracy: 82.10511779785156 %\n",
      "Epoch: 1 Iteration: 2100  Loss: 8439.892578125  Accuracy: 91.39706420898438 %\n",
      "Epoch: 1 Iteration: 2200  Loss: 2240.0498046875  Accuracy: 91.09954833984375 %\n",
      "Epoch: 1 Iteration: 2300  Loss: 21314.76953125  Accuracy: 90.40603637695312 %\n",
      "Epoch: 1 Iteration: 2400  Loss: 1333.9847412109375  Accuracy: 81.23556518554688 %\n",
      "Epoch: 1 Iteration: 2500  Loss: 1521.8892822265625  Accuracy: 89.18741607666016 %\n",
      "Epoch: 1 Iteration: 2600  Loss: 7104.30615234375  Accuracy: 90.73799133300781 %\n",
      "Epoch: 1 Iteration: 2700  Loss: 2461.231689453125  Accuracy: 87.39313507080078 %\n",
      "Epoch: 1 Iteration: 2800  Loss: 2508.33203125  Accuracy: 90.47186279296875 %\n",
      "Epoch: 1 Iteration: 2900  Loss: 3662.647705078125  Accuracy: 90.1949462890625 %\n",
      "Epoch: 1 Iteration: 3000  Loss: 584.7879638671875  Accuracy: 87.25067901611328 %\n",
      "Epoch: 1 Iteration: 3100  Loss: 2286.69140625  Accuracy: 91.47588348388672 %\n",
      "Epoch: 1 Iteration: 3200  Loss: 715.1434936523438  Accuracy: 91.06195068359375 %\n",
      "Epoch: 1 Iteration: 3300  Loss: 4176.9482421875  Accuracy: 90.73399353027344 %\n",
      "Epoch: 1 Iteration: 3400  Loss: 306.4750061035156  Accuracy: 92.2486801147461 %\n",
      "Epoch: 1 Iteration: 3500  Loss: 5006.46630859375  Accuracy: 89.20572662353516 %\n",
      "Epoch: 1 Iteration: 3600  Loss: 302.0050354003906  Accuracy: 86.80256652832031 %\n",
      "Epoch: 1 Iteration: 3700  Loss: 2400.799072265625  Accuracy: 94.82559204101562 %\n",
      "Epoch: 1 Iteration: 3800  Loss: 131.23101806640625  Accuracy: 89.1038818359375 %\n",
      "Epoch: 1 Iteration: 3900  Loss: 1300.122314453125  Accuracy: 94.25101470947266 %\n",
      "Epoch: 1 Iteration: 4000  Loss: 181.09742736816406  Accuracy: 78.68133544921875 %\n",
      "Epoch: 1 Iteration: 4100  Loss: 8958.775390625  Accuracy: 92.36398315429688 %\n",
      "Epoch: 1 Iteration: 4200  Loss: 737.2545776367188  Accuracy: 94.3676528930664 %\n",
      "Epoch: 1 Iteration: 4300  Loss: 1189.9615478515625  Accuracy: 89.54883575439453 %\n",
      "Epoch: 1 Iteration: 4400  Loss: 2682.788818359375  Accuracy: 89.68414306640625 %\n",
      "Epoch: 1 Iteration: 4500  Loss: 1895.8135986328125  Accuracy: 91.90568542480469 %\n",
      "Epoch: 1 Iteration: 4600  Loss: 1251.2454833984375  Accuracy: 89.60121154785156 %\n",
      "Epoch: 1 Iteration: 4700  Loss: 764.8191528320312  Accuracy: 91.19192504882812 %\n",
      "Epoch: 1 Iteration: 4800  Loss: 780.3118896484375  Accuracy: 91.823486328125 %\n",
      "Epoch: 1 Iteration: 4900  Loss: 2382.449462890625  Accuracy: 92.47758483886719 %\n",
      "Epoch: 1 Iteration: 5000  Loss: 488.85003662109375  Accuracy: 88.99172973632812 %\n",
      "Epoch: 1 Iteration: 5100  Loss: 1038.3953857421875  Accuracy: 92.89248657226562 %\n",
      "Epoch: 1 Iteration: 5200  Loss: 1018.5332641601562  Accuracy: 90.82360076904297 %\n",
      "Epoch: 1 Iteration: 5300  Loss: 539.3482055664062  Accuracy: 82.72358703613281 %\n",
      "Epoch: 1 Iteration: 5400  Loss: 1049.337646484375  Accuracy: 92.65291595458984 %\n",
      "Epoch: 1 Iteration: 5500  Loss: 2426.475830078125  Accuracy: 91.36566925048828 %\n",
      "Epoch: 1 Iteration: 5600  Loss: 305.7644958496094  Accuracy: 90.4642333984375 %\n",
      "Epoch: 1 Iteration: 5700  Loss: 1821.6717529296875  Accuracy: 91.40325927734375 %\n",
      "Epoch: 1 Iteration: 5800  Loss: 1338.2808837890625  Accuracy: 91.95806121826172 %\n",
      "Epoch: 1 Iteration: 5900  Loss: 818.0411376953125  Accuracy: 88.20329284667969 %\n",
      "Epoch: 1 Iteration: 6000  Loss: 82.87019348144531  Accuracy: 82.52862548828125 %\n",
      "Epoch: 1 Iteration: 6100  Loss: 66.66160583496094  Accuracy: 92.24456787109375 %\n",
      "Epoch: 1 Iteration: 6200  Loss: 409.3979797363281  Accuracy: 92.72359466552734 %\n",
      "Epoch: 1 Iteration: 6300  Loss: 87.0468978881836  Accuracy: 91.84797668457031 %\n",
      "Epoch: 1 Iteration: 6400  Loss: 378.9364929199219  Accuracy: 92.92146301269531 %\n",
      "Epoch: 1 Iteration: 6500  Loss: 2825.1962890625  Accuracy: 92.43006134033203 %\n",
      "Epoch: 1 Iteration: 6600  Loss: 82.63459777832031  Accuracy: 88.69408416748047 %\n",
      "Epoch: 1 Iteration: 6700  Loss: 481.28680419921875  Accuracy: 90.24793243408203 %\n",
      "Epoch: 1 Iteration: 6800  Loss: 208.59579467773438  Accuracy: 90.63772583007812 %\n",
      "Epoch: 1 Iteration: 6900  Loss: 101.87356567382812  Accuracy: 90.892822265625 %\n",
      "Epoch: 1 Iteration: 7000  Loss: 232.75526428222656  Accuracy: 92.80858612060547 %\n",
      "Epoch: 1 Iteration: 7100  Loss: 304.7956237792969  Accuracy: 90.09371185302734 %\n",
      "Epoch: 1 Iteration: 7200  Loss: 121.25945281982422  Accuracy: 93.67122650146484 %\n",
      "Epoch: 1 Iteration: 7300  Loss: 159.35308837890625  Accuracy: 91.93745422363281 %\n",
      "Epoch: 1 Iteration: 7400  Loss: 729.7673950195312  Accuracy: 90.93585968017578 %\n",
      "Fold 1 Epoch No. : 0 Accuracy for Epoch : 93.99301147460938\n",
      "Epochs completed. Time taken (seconds):  1553.557309627533\n",
      "Average accuracy over all epochs 93.99301147460938\n",
      "Start training...\n",
      "Completed loading data and returning pytorch train and validation data loaders\n",
      "Epoch: 1 Iteration: 0  Loss: 357.22662353515625  Accuracy: 93.83987426757812 %\n",
      "Epoch: 1 Iteration: 100  Loss: 83.40158081054688  Accuracy: 95.26837158203125 %\n",
      "Epoch: 1 Iteration: 200  Loss: 322.8299255371094  Accuracy: 94.30824279785156 %\n",
      "Epoch: 1 Iteration: 300  Loss: 280.7847900390625  Accuracy: 94.5937728881836 %\n",
      "Epoch: 1 Iteration: 400  Loss: 105.39350891113281  Accuracy: 80.99781036376953 %\n",
      "Epoch: 1 Iteration: 500  Loss: 177.67364501953125  Accuracy: 91.8374252319336 %\n",
      "Epoch: 1 Iteration: 600  Loss: 536.8857421875  Accuracy: 74.57943725585938 %\n",
      "Epoch: 1 Iteration: 700  Loss: 262.68292236328125  Accuracy: 90.3777847290039 %\n",
      "Epoch: 1 Iteration: 800  Loss: 108.00373077392578  Accuracy: 89.68269348144531 %\n",
      "Epoch: 1 Iteration: 900  Loss: 151.4782257080078  Accuracy: 90.32831573486328 %\n",
      "Epoch: 1 Iteration: 1000  Loss: 415.0089416503906  Accuracy: 90.553466796875 %\n",
      "Epoch: 1 Iteration: 1100  Loss: 70.50943756103516  Accuracy: 92.22673797607422 %\n",
      "Epoch: 1 Iteration: 1200  Loss: 96.02324676513672  Accuracy: 92.29439544677734 %\n",
      "Epoch: 1 Iteration: 1300  Loss: 321.2037353515625  Accuracy: 89.4212875366211 %\n",
      "Epoch: 1 Iteration: 1400  Loss: 68.71649169921875  Accuracy: 93.46595764160156 %\n",
      "Epoch: 1 Iteration: 1500  Loss: 50.41328811645508  Accuracy: 92.21983337402344 %\n",
      "Epoch: 1 Iteration: 1600  Loss: 136.5951385498047  Accuracy: 89.83631134033203 %\n",
      "Epoch: 1 Iteration: 1700  Loss: 163.57933044433594  Accuracy: 93.7169418334961 %\n",
      "Epoch: 1 Iteration: 1800  Loss: 142.77264404296875  Accuracy: 90.2522964477539 %\n",
      "Epoch: 1 Iteration: 1900  Loss: 1360.4718017578125  Accuracy: 89.97247314453125 %\n",
      "Epoch: 1 Iteration: 2000  Loss: 37.64694595336914  Accuracy: 88.00662231445312 %\n",
      "Epoch: 1 Iteration: 2100  Loss: 64.05235290527344  Accuracy: 89.40576934814453 %\n",
      "Epoch: 1 Iteration: 2200  Loss: 200.94691467285156  Accuracy: 91.23860931396484 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 2300  Loss: 48.23068618774414  Accuracy: 88.14545440673828 %\n",
      "Epoch: 1 Iteration: 2400  Loss: 239.0350799560547  Accuracy: 77.86100769042969 %\n",
      "Epoch: 1 Iteration: 2500  Loss: 57.788543701171875  Accuracy: 91.75437927246094 %\n",
      "Epoch: 1 Iteration: 2600  Loss: 82.55542755126953  Accuracy: 92.63799285888672 %\n",
      "Epoch: 1 Iteration: 2700  Loss: 241.8072509765625  Accuracy: 89.44214630126953 %\n",
      "Epoch: 1 Iteration: 2800  Loss: 146.3297119140625  Accuracy: 88.85871887207031 %\n",
      "Epoch: 1 Iteration: 2900  Loss: 65.2767333984375  Accuracy: 84.23573303222656 %\n",
      "Epoch: 1 Iteration: 3000  Loss: 226.13539123535156  Accuracy: 88.81932067871094 %\n",
      "Epoch: 1 Iteration: 3100  Loss: 425.31732177734375  Accuracy: 89.09114837646484 %\n",
      "Epoch: 1 Iteration: 3200  Loss: 148.29986572265625  Accuracy: 88.2982177734375 %\n",
      "Epoch: 1 Iteration: 3300  Loss: 44.997886657714844  Accuracy: 85.72216796875 %\n",
      "Epoch: 1 Iteration: 3400  Loss: 77.02788543701172  Accuracy: 87.55365753173828 %\n",
      "Epoch: 1 Iteration: 3500  Loss: 41.95169448852539  Accuracy: 88.12654113769531 %\n",
      "Epoch: 1 Iteration: 3600  Loss: 54.168296813964844  Accuracy: 87.87762451171875 %\n",
      "Epoch: 1 Iteration: 3700  Loss: 19.517614364624023  Accuracy: 86.85858154296875 %\n",
      "Epoch: 1 Iteration: 3800  Loss: 111.39115905761719  Accuracy: 88.46214294433594 %\n",
      "Epoch: 1 Iteration: 3900  Loss: 7.64547872543335  Accuracy: 86.79953002929688 %\n",
      "Epoch: 1 Iteration: 4000  Loss: 441.48114013671875  Accuracy: 84.59739685058594 %\n",
      "Epoch: 1 Iteration: 4100  Loss: 30.898441314697266  Accuracy: 86.58759307861328 %\n",
      "Epoch: 1 Iteration: 4200  Loss: 35.088932037353516  Accuracy: 94.0197982788086 %\n",
      "Epoch: 1 Iteration: 4300  Loss: 98.48501586914062  Accuracy: 93.65595245361328 %\n",
      "Epoch: 1 Iteration: 4400  Loss: 29.8730411529541  Accuracy: 91.47345733642578 %\n",
      "Epoch: 1 Iteration: 4500  Loss: 14.552779197692871  Accuracy: 87.2936019897461 %\n",
      "Epoch: 1 Iteration: 4600  Loss: 23.458351135253906  Accuracy: 91.05686950683594 %\n",
      "Epoch: 1 Iteration: 4700  Loss: 29.07070541381836  Accuracy: 89.29895782470703 %\n",
      "Epoch: 1 Iteration: 4800  Loss: 35.87872314453125  Accuracy: 92.06342315673828 %\n",
      "Epoch: 1 Iteration: 4900  Loss: 17.314096450805664  Accuracy: 91.98365020751953 %\n",
      "Epoch: 1 Iteration: 5000  Loss: 71.28041076660156  Accuracy: 92.65811920166016 %\n",
      "Epoch: 1 Iteration: 5100  Loss: 8.137191772460938  Accuracy: 91.7203140258789 %\n",
      "Epoch: 1 Iteration: 5200  Loss: 2.4180798530578613  Accuracy: 91.96060943603516 %\n",
      "Epoch: 1 Iteration: 5300  Loss: 147.2576904296875  Accuracy: 94.45082092285156 %\n",
      "Epoch: 1 Iteration: 5400  Loss: 2.216128349304199  Accuracy: 94.74896240234375 %\n",
      "Epoch: 1 Iteration: 5500  Loss: 4.224344253540039  Accuracy: 93.50318908691406 %\n",
      "Epoch: 1 Iteration: 5600  Loss: 8.079442024230957  Accuracy: 94.23234558105469 %\n",
      "Epoch: 1 Iteration: 5700  Loss: 2.054830551147461  Accuracy: 93.12599182128906 %\n",
      "Epoch: 1 Iteration: 5800  Loss: 14.668867111206055  Accuracy: 94.10261535644531 %\n",
      "Epoch: 1 Iteration: 5900  Loss: 6.4593377113342285  Accuracy: 92.76323699951172 %\n",
      "Epoch: 1 Iteration: 6000  Loss: 3.4868218898773193  Accuracy: 93.64927673339844 %\n",
      "Epoch: 1 Iteration: 6100  Loss: 11.204360961914062  Accuracy: 83.59799194335938 %\n",
      "Epoch: 1 Iteration: 6200  Loss: 6.3127217292785645  Accuracy: 92.77790832519531 %\n",
      "Epoch: 1 Iteration: 6300  Loss: 11.9321870803833  Accuracy: 90.54097747802734 %\n",
      "Epoch: 1 Iteration: 6400  Loss: 1.8585759401321411  Accuracy: 91.88397979736328 %\n",
      "Epoch: 1 Iteration: 6500  Loss: 0.6490359306335449  Accuracy: 94.31745910644531 %\n",
      "Epoch: 1 Iteration: 6600  Loss: 1.148954153060913  Accuracy: 92.43151092529297 %\n",
      "Epoch: 1 Iteration: 6700  Loss: 5.112867832183838  Accuracy: 92.12950134277344 %\n",
      "Epoch: 1 Iteration: 6800  Loss: 19.32903480529785  Accuracy: 87.02783203125 %\n",
      "Epoch: 1 Iteration: 6900  Loss: 8.996540069580078  Accuracy: 88.3666000366211 %\n",
      "Epoch: 1 Iteration: 7000  Loss: 188.6140899658203  Accuracy: 85.60589599609375 %\n",
      "Epoch: 1 Iteration: 7100  Loss: 17.295612335205078  Accuracy: 87.725341796875 %\n",
      "Epoch: 1 Iteration: 7200  Loss: 8.11934757232666  Accuracy: 88.06858825683594 %\n",
      "Epoch: 1 Iteration: 7300  Loss: 1.9879474639892578  Accuracy: 88.7851333618164 %\n",
      "Epoch: 1 Iteration: 7400  Loss: 1.7437920570373535  Accuracy: 87.12458801269531 %\n",
      "Fold 2 Epoch No. : 0 Accuracy for Epoch : 87.62568664550781\n",
      "Epochs completed. Time taken (seconds):  1598.3720874786377\n",
      "Average accuracy over all epochs 87.62568664550781\n",
      "Start training...\n",
      "Completed loading data and returning pytorch train and validation data loaders\n",
      "Epoch: 1 Iteration: 0  Loss: 2.151280164718628  Accuracy: 85.13655853271484 %\n",
      "Epoch: 1 Iteration: 100  Loss: 17.798913955688477  Accuracy: 88.31143951416016 %\n",
      "Epoch: 1 Iteration: 200  Loss: 2.3475780487060547  Accuracy: 87.85810852050781 %\n",
      "Epoch: 1 Iteration: 300  Loss: 1.306716799736023  Accuracy: 88.550048828125 %\n",
      "Epoch: 1 Iteration: 400  Loss: 0.7515200972557068  Accuracy: 87.79190826416016 %\n",
      "Epoch: 1 Iteration: 500  Loss: 0.6004294753074646  Accuracy: 88.567138671875 %\n",
      "Epoch: 1 Iteration: 600  Loss: 1.9248028993606567  Accuracy: 88.41593933105469 %\n",
      "Epoch: 1 Iteration: 700  Loss: 1.9374727010726929  Accuracy: 88.72644805908203 %\n",
      "Epoch: 1 Iteration: 800  Loss: 1.7019758224487305  Accuracy: 87.05450439453125 %\n",
      "Epoch: 1 Iteration: 900  Loss: 1.3989317417144775  Accuracy: 88.55441284179688 %\n",
      "Epoch: 1 Iteration: 1000  Loss: 1.1530671119689941  Accuracy: 88.12023162841797 %\n",
      "Epoch: 1 Iteration: 1100  Loss: 1.2961281538009644  Accuracy: 88.11260223388672 %\n",
      "Epoch: 1 Iteration: 1200  Loss: 1.3041188716888428  Accuracy: 88.08773803710938 %\n",
      "Epoch: 1 Iteration: 1300  Loss: 2.270021438598633  Accuracy: 89.09078979492188 %\n",
      "Epoch: 1 Iteration: 1400  Loss: 7.997073650360107  Accuracy: 87.1500473022461 %\n",
      "Epoch: 1 Iteration: 1500  Loss: 3.0422072410583496  Accuracy: 85.023681640625 %\n",
      "Epoch: 1 Iteration: 1600  Loss: 3.4001898765563965  Accuracy: 85.60213470458984 %\n",
      "Epoch: 1 Iteration: 1700  Loss: 0.9992063045501709  Accuracy: 85.58515930175781 %\n",
      "Epoch: 1 Iteration: 1800  Loss: 0.9778737425804138  Accuracy: 85.42354583740234 %\n",
      "Epoch: 1 Iteration: 1900  Loss: 3.37172269821167  Accuracy: 85.65972900390625 %\n",
      "Epoch: 1 Iteration: 2000  Loss: 3.441734552383423  Accuracy: 82.66878509521484 %\n",
      "Epoch: 1 Iteration: 2100  Loss: 1.0665169954299927  Accuracy: 84.3768539428711 %\n",
      "Epoch: 1 Iteration: 2200  Loss: 1.1875983476638794  Accuracy: 85.41651153564453 %\n",
      "Epoch: 1 Iteration: 2300  Loss: 0.70986407995224  Accuracy: 85.69113159179688 %\n",
      "Epoch: 1 Iteration: 2400  Loss: 1.2417620420455933  Accuracy: 85.59207153320312 %\n",
      "Epoch: 1 Iteration: 2500  Loss: 0.9747403860092163  Accuracy: 85.16397094726562 %\n",
      "Epoch: 1 Iteration: 2600  Loss: 0.8692241907119751  Accuracy: 85.63353729248047 %\n",
      "Epoch: 1 Iteration: 2700  Loss: 1.2663061618804932  Accuracy: 85.78242492675781 %\n",
      "Epoch: 1 Iteration: 2800  Loss: 1.6386955976486206  Accuracy: 85.59061431884766 %\n",
      "Epoch: 1 Iteration: 2900  Loss: 0.7311574816703796  Accuracy: 87.78815460205078 %\n",
      "Epoch: 1 Iteration: 3000  Loss: 1.1275562047958374  Accuracy: 85.7410888671875 %\n",
      "Epoch: 1 Iteration: 3100  Loss: 2.0092344284057617  Accuracy: 85.74168395996094 %\n",
      "Epoch: 1 Iteration: 3200  Loss: 1.1162775754928589  Accuracy: 85.59619140625 %\n",
      "Epoch: 1 Iteration: 3300  Loss: 0.741500198841095  Accuracy: 85.63656616210938 %\n",
      "Epoch: 1 Iteration: 3400  Loss: 1.9219417572021484  Accuracy: 85.59850311279297 %\n",
      "Epoch: 1 Iteration: 3500  Loss: 1.827747106552124  Accuracy: 85.67694091796875 %\n",
      "Epoch: 1 Iteration: 3600  Loss: 1.3425731658935547  Accuracy: 85.72289276123047 %\n",
      "Epoch: 1 Iteration: 3700  Loss: 0.9806500673294067  Accuracy: 84.7734375 %\n",
      "Epoch: 1 Iteration: 3800  Loss: 1.2455635070800781  Accuracy: 85.67306518554688 %\n",
      "Epoch: 1 Iteration: 3900  Loss: 0.9781486988067627  Accuracy: 85.08503723144531 %\n",
      "Epoch: 1 Iteration: 4000  Loss: 0.7535290122032166  Accuracy: 85.58067321777344 %\n",
      "Epoch: 1 Iteration: 4100  Loss: 1.4595606327056885  Accuracy: 85.74241638183594 %\n",
      "Epoch: 1 Iteration: 4200  Loss: 0.7884020209312439  Accuracy: 85.74617004394531 %\n",
      "Epoch: 1 Iteration: 4300  Loss: 0.8448716402053833  Accuracy: 85.05023193359375 %\n",
      "Epoch: 1 Iteration: 4400  Loss: 1.3003723621368408  Accuracy: 85.72676849365234 %\n",
      "Epoch: 1 Iteration: 4500  Loss: 0.8932788372039795  Accuracy: 85.73065185546875 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 4600  Loss: 0.8243563175201416  Accuracy: 85.42730712890625 %\n",
      "Epoch: 1 Iteration: 4700  Loss: 1.0387481451034546  Accuracy: 85.76205444335938 %\n",
      "Epoch: 1 Iteration: 4800  Loss: 0.9244939684867859  Accuracy: 85.51666259765625 %\n",
      "Epoch: 1 Iteration: 4900  Loss: 0.7424236536026001  Accuracy: 85.62905883789062 %\n",
      "Epoch: 1 Iteration: 5000  Loss: 0.8620346784591675  Accuracy: 85.49957275390625 %\n",
      "Epoch: 1 Iteration: 5100  Loss: 1.2680596113204956  Accuracy: 85.6833724975586 %\n",
      "Epoch: 1 Iteration: 5200  Loss: 0.7059283256530762  Accuracy: 85.54794311523438 %\n",
      "Epoch: 1 Iteration: 5300  Loss: 0.994006335735321  Accuracy: 85.51725769042969 %\n",
      "Epoch: 1 Iteration: 5400  Loss: 1.8881635665893555  Accuracy: 85.5766830444336 %\n",
      "Epoch: 1 Iteration: 5500  Loss: 1.1548585891723633  Accuracy: 85.3680191040039 %\n",
      "Epoch: 1 Iteration: 5600  Loss: 1.0313204526901245  Accuracy: 86.90185546875 %\n",
      "Epoch: 1 Iteration: 5700  Loss: 0.7402180433273315  Accuracy: 85.64323425292969 %\n",
      "Epoch: 1 Iteration: 5800  Loss: 0.7123405337333679  Accuracy: 85.44209289550781 %\n",
      "Epoch: 1 Iteration: 5900  Loss: 0.8266686797142029  Accuracy: 85.59388732910156 %\n",
      "Epoch: 1 Iteration: 6000  Loss: 0.8077878355979919  Accuracy: 85.44633483886719 %\n",
      "Epoch: 1 Iteration: 6100  Loss: 1.6601370573043823  Accuracy: 85.24095153808594 %\n",
      "Epoch: 1 Iteration: 6200  Loss: 1.753392219543457  Accuracy: 85.28932189941406 %\n",
      "Epoch: 1 Iteration: 6300  Loss: 0.8701576590538025  Accuracy: 85.40184020996094 %\n",
      "Epoch: 1 Iteration: 6400  Loss: 0.7089908719062805  Accuracy: 85.560791015625 %\n",
      "Epoch: 1 Iteration: 6500  Loss: 0.7452287673950195  Accuracy: 85.48719024658203 %\n",
      "Epoch: 1 Iteration: 6600  Loss: 2.8783037662506104  Accuracy: 85.46173858642578 %\n",
      "Epoch: 1 Iteration: 6700  Loss: 1.3575271368026733  Accuracy: 85.45433807373047 %\n",
      "Epoch: 1 Iteration: 6800  Loss: 1.7706401348114014  Accuracy: 85.55545806884766 %\n",
      "Epoch: 1 Iteration: 6900  Loss: 1.2604786157608032  Accuracy: 85.46755981445312 %\n",
      "Epoch: 1 Iteration: 7000  Loss: 0.8128010034561157  Accuracy: 85.56600952148438 %\n",
      "Epoch: 1 Iteration: 7100  Loss: 0.6846977472305298  Accuracy: 85.39190673828125 %\n",
      "Epoch: 1 Iteration: 7200  Loss: 0.7132560014724731  Accuracy: 85.4151840209961 %\n",
      "Epoch: 1 Iteration: 7300  Loss: 1.0833642482757568  Accuracy: 84.62442779541016 %\n",
      "Epoch: 1 Iteration: 7400  Loss: 0.6189019680023193  Accuracy: 85.58503723144531 %\n",
      "Fold 3 Epoch No. : 0 Accuracy for Epoch : 85.52769470214844\n",
      "Epochs completed. Time taken (seconds):  1842.2156546115875\n",
      "Average accuracy over all epochs 85.52769470214844\n",
      "Start training...\n",
      "Completed loading data and returning pytorch train and validation data loaders\n",
      "Epoch: 1 Iteration: 0  Loss: 0.6679802536964417  Accuracy: 85.31636810302734 %\n",
      "Epoch: 1 Iteration: 100  Loss: 1.7192851305007935  Accuracy: 84.75465393066406 %\n",
      "Epoch: 1 Iteration: 200  Loss: 1.1138821840286255  Accuracy: 85.26387023925781 %\n",
      "Epoch: 1 Iteration: 300  Loss: 0.7574484348297119  Accuracy: 85.00004577636719 %\n",
      "Epoch: 1 Iteration: 400  Loss: 0.7102693319320679  Accuracy: 85.47991943359375 %\n",
      "Epoch: 1 Iteration: 500  Loss: 0.6571761965751648  Accuracy: 85.58612823486328 %\n",
      "Epoch: 1 Iteration: 600  Loss: 0.720082700252533  Accuracy: 85.5212631225586 %\n",
      "Epoch: 1 Iteration: 700  Loss: 0.847176194190979  Accuracy: 85.48841094970703 %\n",
      "Epoch: 1 Iteration: 800  Loss: 0.6797254085540771  Accuracy: 85.37904357910156 %\n",
      "Epoch: 1 Iteration: 900  Loss: 0.6534574031829834  Accuracy: 85.37153625488281 %\n",
      "Epoch: 1 Iteration: 1000  Loss: 0.8253620266914368  Accuracy: 85.5105972290039 %\n",
      "Epoch: 1 Iteration: 1100  Loss: 1.158748984336853  Accuracy: 85.35504913330078 %\n",
      "Epoch: 1 Iteration: 1200  Loss: 0.8270042538642883  Accuracy: 85.49750518798828 %\n",
      "Epoch: 1 Iteration: 1300  Loss: 0.6536670923233032  Accuracy: 85.44197082519531 %\n",
      "Epoch: 1 Iteration: 1400  Loss: 3.316728353500366  Accuracy: 83.85066223144531 %\n",
      "Epoch: 1 Iteration: 1500  Loss: 0.9324852824211121  Accuracy: 83.8755111694336 %\n",
      "Epoch: 1 Iteration: 1600  Loss: 0.7541061043739319  Accuracy: 83.89237213134766 %\n",
      "Epoch: 1 Iteration: 1700  Loss: 0.721488356590271  Accuracy: 83.4708023071289 %\n",
      "Epoch: 1 Iteration: 1800  Loss: 0.7069298624992371  Accuracy: 83.7210464477539 %\n",
      "Epoch: 1 Iteration: 1900  Loss: 0.7799261808395386  Accuracy: 83.78191375732422 %\n",
      "Epoch: 1 Iteration: 2000  Loss: 5.468503475189209  Accuracy: 83.81526184082031 %\n",
      "Epoch: 1 Iteration: 2100  Loss: 0.7159265279769897  Accuracy: 83.90860748291016 %\n",
      "Epoch: 1 Iteration: 2200  Loss: 1.7680509090423584  Accuracy: 83.53797149658203 %\n",
      "Epoch: 1 Iteration: 2300  Loss: 1.330451488494873  Accuracy: 83.32009887695312 %\n",
      "Epoch: 1 Iteration: 2400  Loss: 0.8811265230178833  Accuracy: 83.86993408203125 %\n",
      "Epoch: 1 Iteration: 2500  Loss: 2.109757900238037  Accuracy: 83.84484100341797 %\n",
      "Epoch: 1 Iteration: 2600  Loss: 0.775176465511322  Accuracy: 83.90727996826172 %\n",
      "Epoch: 1 Iteration: 2700  Loss: 0.7867148518562317  Accuracy: 83.91952514648438 %\n",
      "Epoch: 1 Iteration: 2800  Loss: 2.1237473487854004  Accuracy: 83.91322326660156 %\n",
      "Epoch: 1 Iteration: 2900  Loss: 24.56269073486328  Accuracy: 83.90618133544922 %\n",
      "Epoch: 1 Iteration: 3000  Loss: 0.7757925987243652  Accuracy: 83.88812255859375 %\n",
      "Epoch: 1 Iteration: 3100  Loss: 0.9032174944877625  Accuracy: 83.92752075195312 %\n",
      "Epoch: 1 Iteration: 3200  Loss: 1.072587251663208  Accuracy: 83.52051544189453 %\n",
      "Epoch: 1 Iteration: 3300  Loss: 0.7601367831230164  Accuracy: 83.43855285644531 %\n",
      "Epoch: 1 Iteration: 3400  Loss: 0.8239781260490417  Accuracy: 83.59896087646484 %\n",
      "Epoch: 1 Iteration: 3500  Loss: 0.7078517079353333  Accuracy: 83.90218353271484 %\n",
      "Epoch: 1 Iteration: 3600  Loss: 0.7769995331764221  Accuracy: 83.9116439819336 %\n",
      "Epoch: 1 Iteration: 3700  Loss: 2.589540958404541  Accuracy: 83.74542236328125 %\n",
      "Epoch: 1 Iteration: 3800  Loss: 0.7288601398468018  Accuracy: 83.8037338256836 %\n",
      "Epoch: 1 Iteration: 3900  Loss: 0.8078535199165344  Accuracy: 83.84507751464844 %\n",
      "Epoch: 1 Iteration: 4000  Loss: 0.9986107349395752  Accuracy: 83.83525848388672 %\n",
      "Epoch: 1 Iteration: 4100  Loss: 0.7793786525726318  Accuracy: 83.88872528076172 %\n",
      "Epoch: 1 Iteration: 4200  Loss: 0.8655116558074951  Accuracy: 83.9000015258789 %\n",
      "Epoch: 1 Iteration: 4300  Loss: 0.7035949230194092  Accuracy: 83.84701538085938 %\n",
      "Epoch: 1 Iteration: 4400  Loss: 0.8269376158714294  Accuracy: 83.91636657714844 %\n",
      "Epoch: 1 Iteration: 4500  Loss: 0.7873165011405945  Accuracy: 83.83320617675781 %\n",
      "Epoch: 1 Iteration: 4600  Loss: 1.2703440189361572  Accuracy: 83.65666961669922 %\n",
      "Epoch: 1 Iteration: 4700  Loss: 0.7608446478843689  Accuracy: 83.82228088378906 %\n",
      "Epoch: 1 Iteration: 4800  Loss: 0.7383236289024353  Accuracy: 83.85272216796875 %\n",
      "Epoch: 1 Iteration: 4900  Loss: 0.9344538450241089  Accuracy: 83.68055725097656 %\n",
      "Epoch: 1 Iteration: 5000  Loss: 0.7679616808891296  Accuracy: 83.89273071289062 %\n",
      "Epoch: 1 Iteration: 5100  Loss: 0.8011513948440552  Accuracy: 83.85853576660156 %\n",
      "Epoch: 1 Iteration: 5200  Loss: 0.795320451259613  Accuracy: 83.87696838378906 %\n",
      "Epoch: 1 Iteration: 5300  Loss: 0.7289416790008545  Accuracy: 83.9122543334961 %\n",
      "Epoch: 1 Iteration: 5400  Loss: 0.7043049931526184  Accuracy: 83.914306640625 %\n",
      "Epoch: 1 Iteration: 5500  Loss: 0.6653643846511841  Accuracy: 83.34871673583984 %\n",
      "Epoch: 1 Iteration: 5600  Loss: 0.7803664207458496  Accuracy: 83.89017486572266 %\n",
      "Epoch: 1 Iteration: 5700  Loss: 0.7263189554214478  Accuracy: 83.88957977294922 %\n",
      "Epoch: 1 Iteration: 5800  Loss: 0.7921586036682129  Accuracy: 83.88072967529297 %\n",
      "Epoch: 1 Iteration: 5900  Loss: 0.6901028156280518  Accuracy: 83.89273071289062 %\n",
      "Epoch: 1 Iteration: 6000  Loss: 0.8018293976783752  Accuracy: 83.89334106445312 %\n",
      "Epoch: 1 Iteration: 6100  Loss: 0.8364552855491638  Accuracy: 83.75621032714844 %\n",
      "Epoch: 1 Iteration: 6200  Loss: 0.7326983213424683  Accuracy: 83.68782806396484 %\n",
      "Epoch: 1 Iteration: 6300  Loss: 0.7733010053634644  Accuracy: 83.58307647705078 %\n",
      "Epoch: 1 Iteration: 6400  Loss: 0.6847630739212036  Accuracy: 83.84762573242188 %\n",
      "Epoch: 1 Iteration: 6500  Loss: 0.7657196521759033  Accuracy: 83.68758392333984 %\n",
      "Epoch: 1 Iteration: 6600  Loss: 0.7992461323738098  Accuracy: 83.86375427246094 %\n",
      "Epoch: 1 Iteration: 6700  Loss: 0.8222598433494568  Accuracy: 83.83779907226562 %\n",
      "Epoch: 1 Iteration: 6800  Loss: 0.7162801623344421  Accuracy: 83.8427734375 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 6900  Loss: 0.8206849694252014  Accuracy: 83.83271789550781 %\n",
      "Epoch: 1 Iteration: 7000  Loss: 0.7813779711723328  Accuracy: 83.82046508789062 %\n",
      "Epoch: 1 Iteration: 7100  Loss: 0.7686989307403564  Accuracy: 83.7747573852539 %\n",
      "Epoch: 1 Iteration: 7200  Loss: 0.8110915422439575  Accuracy: 83.77633666992188 %\n",
      "Epoch: 1 Iteration: 7300  Loss: 0.778888463973999  Accuracy: 83.73802185058594 %\n",
      "Epoch: 1 Iteration: 7400  Loss: 0.7635128498077393  Accuracy: 83.46353149414062 %\n",
      "Fold 4 Epoch No. : 0 Accuracy for Epoch : 83.58780670166016\n",
      "Epochs completed. Time taken (seconds):  2119.765521287918\n",
      "Average accuracy over all epochs 83.58780670166016\n",
      "Start training...\n",
      "Completed loading data and returning pytorch train and validation data loaders\n",
      "Epoch: 1 Iteration: 0  Loss: 0.9112256765365601  Accuracy: 83.09906768798828 %\n",
      "Epoch: 1 Iteration: 100  Loss: 0.7761479020118713  Accuracy: 83.8464126586914 %\n",
      "Epoch: 1 Iteration: 200  Loss: 0.8017571568489075  Accuracy: 83.85816955566406 %\n",
      "Epoch: 1 Iteration: 300  Loss: 0.7084037661552429  Accuracy: 83.8118667602539 %\n",
      "Epoch: 1 Iteration: 400  Loss: 0.7959520816802979  Accuracy: 83.67134094238281 %\n",
      "Epoch: 1 Iteration: 500  Loss: 0.8555719256401062  Accuracy: 83.63666534423828 %\n",
      "Epoch: 1 Iteration: 600  Loss: 0.8226092457771301  Accuracy: 83.67121887207031 %\n",
      "Epoch: 1 Iteration: 700  Loss: 0.7796130180358887  Accuracy: 83.64854431152344 %\n",
      "Epoch: 1 Iteration: 800  Loss: 0.7756990790367126  Accuracy: 83.47637939453125 %\n",
      "Epoch: 1 Iteration: 900  Loss: 0.8090206980705261  Accuracy: 83.6609115600586 %\n",
      "Epoch: 1 Iteration: 1000  Loss: 0.9412338137626648  Accuracy: 83.21631622314453 %\n",
      "Epoch: 1 Iteration: 1100  Loss: 0.7925066351890564  Accuracy: 83.52632904052734 %\n",
      "Epoch: 1 Iteration: 1200  Loss: 0.7603262662887573  Accuracy: 83.60381317138672 %\n",
      "Epoch: 1 Iteration: 1300  Loss: 0.7956997156143188  Accuracy: 83.6138687133789 %\n",
      "Epoch: 1 Iteration: 1400  Loss: 0.7564907670021057  Accuracy: 83.67872619628906 %\n",
      "Epoch: 1 Iteration: 1500  Loss: 0.7770966291427612  Accuracy: 83.17047882080078 %\n",
      "Epoch: 1 Iteration: 1600  Loss: 0.8170308470726013  Accuracy: 83.6486587524414 %\n",
      "Epoch: 1 Iteration: 1700  Loss: 0.8078197836875916  Accuracy: 83.64672088623047 %\n",
      "Epoch: 1 Iteration: 1800  Loss: 0.7432088255882263  Accuracy: 83.65690612792969 %\n",
      "Epoch: 1 Iteration: 1900  Loss: 0.8401737809181213  Accuracy: 83.06742858886719 %\n",
      "Epoch: 1 Iteration: 2000  Loss: 0.7941091656684875  Accuracy: 83.41490173339844 %\n",
      "Epoch: 1 Iteration: 2100  Loss: 0.729966402053833  Accuracy: 83.63860321044922 %\n",
      "Epoch: 1 Iteration: 2200  Loss: 0.8058398962020874  Accuracy: 83.64551544189453 %\n",
      "Epoch: 1 Iteration: 2300  Loss: 0.7240611910820007  Accuracy: 83.67376708984375 %\n",
      "Epoch: 1 Iteration: 2400  Loss: 0.7860659956932068  Accuracy: 83.67182159423828 %\n",
      "Epoch: 1 Iteration: 2500  Loss: 0.7895564436912537  Accuracy: 83.65522003173828 %\n",
      "Epoch: 1 Iteration: 2600  Loss: 0.7663958072662354  Accuracy: 83.61823272705078 %\n",
      "Epoch: 1 Iteration: 2700  Loss: 1.4398666620254517  Accuracy: 81.94265747070312 %\n",
      "Epoch: 1 Iteration: 2800  Loss: 0.8564786314964294  Accuracy: 81.93938446044922 %\n",
      "Epoch: 1 Iteration: 2900  Loss: 0.8741683959960938  Accuracy: 81.9100341796875 %\n",
      "Epoch: 1 Iteration: 3000  Loss: 0.8550230264663696  Accuracy: 81.9431381225586 %\n",
      "Epoch: 1 Iteration: 3100  Loss: 0.9235402941703796  Accuracy: 81.87366485595703 %\n",
      "Epoch: 1 Iteration: 3200  Loss: 0.7566298842430115  Accuracy: 81.91100311279297 %\n",
      "Epoch: 1 Iteration: 3300  Loss: 1.171462059020996  Accuracy: 81.93938446044922 %\n",
      "Epoch: 1 Iteration: 3400  Loss: 0.8104894757270813  Accuracy: 81.94277954101562 %\n",
      "Epoch: 1 Iteration: 3500  Loss: 0.8433206677436829  Accuracy: 81.90980529785156 %\n",
      "Epoch: 1 Iteration: 3600  Loss: 0.7914148569107056  Accuracy: 81.93489837646484 %\n",
      "Epoch: 1 Iteration: 3700  Loss: 0.8448418974876404  Accuracy: 81.94023132324219 %\n",
      "Epoch: 1 Iteration: 3800  Loss: 0.8301854133605957  Accuracy: 81.94860076904297 %\n",
      "Epoch: 1 Iteration: 3900  Loss: 0.8822270631790161  Accuracy: 81.94532012939453 %\n",
      "Epoch: 1 Iteration: 4000  Loss: 0.8296849131584167  Accuracy: 81.96629333496094 %\n",
      "Epoch: 1 Iteration: 4100  Loss: 0.8125322461128235  Accuracy: 81.94241333007812 %\n",
      "Epoch: 1 Iteration: 4200  Loss: 1.0557160377502441  Accuracy: 81.93683624267578 %\n",
      "Epoch: 1 Iteration: 4300  Loss: 0.845641553401947  Accuracy: 81.89027404785156 %\n",
      "Epoch: 1 Iteration: 4400  Loss: 0.9396999478340149  Accuracy: 81.95162963867188 %\n",
      "Epoch: 1 Iteration: 4500  Loss: 0.7637771964073181  Accuracy: 81.60475158691406 %\n",
      "Epoch: 1 Iteration: 4600  Loss: 0.827126145362854  Accuracy: 81.93841552734375 %\n",
      "Epoch: 1 Iteration: 4700  Loss: 0.7781470417976379  Accuracy: 81.9476318359375 %\n",
      "Epoch: 1 Iteration: 4800  Loss: 0.8042412996292114  Accuracy: 81.91016387939453 %\n",
      "Epoch: 1 Iteration: 4900  Loss: 0.8296739459037781  Accuracy: 81.94241333007812 %\n",
      "Epoch: 1 Iteration: 5000  Loss: 0.8262459635734558  Accuracy: 81.94956970214844 %\n",
      "Epoch: 1 Iteration: 5100  Loss: 0.8544911742210388  Accuracy: 81.71544647216797 %\n",
      "Epoch: 1 Iteration: 5200  Loss: 0.776524543762207  Accuracy: 81.92167663574219 %\n",
      "Epoch: 1 Iteration: 5300  Loss: 0.8248999714851379  Accuracy: 81.93344116210938 %\n",
      "Epoch: 1 Iteration: 5400  Loss: 0.866202175617218  Accuracy: 81.9496841430664 %\n",
      "Epoch: 1 Iteration: 5500  Loss: 0.8579218983650208  Accuracy: 81.94495391845703 %\n",
      "Epoch: 1 Iteration: 5600  Loss: 0.8234950304031372  Accuracy: 81.93841552734375 %\n",
      "Epoch: 1 Iteration: 5700  Loss: 0.8417268991470337  Accuracy: 81.55904388427734 %\n",
      "Epoch: 1 Iteration: 5800  Loss: 0.8962481617927551  Accuracy: 81.5329818725586 %\n",
      "Epoch: 1 Iteration: 5900  Loss: 0.8399978280067444  Accuracy: 81.55152130126953 %\n",
      "Epoch: 1 Iteration: 6000  Loss: 0.906602144241333  Accuracy: 81.57080841064453 %\n",
      "Epoch: 1 Iteration: 6100  Loss: 0.8691095113754272  Accuracy: 81.56388854980469 %\n",
      "Epoch: 1 Iteration: 6200  Loss: 0.7829607129096985  Accuracy: 81.54570770263672 %\n",
      "Epoch: 1 Iteration: 6300  Loss: 0.7655966877937317  Accuracy: 81.56098175048828 %\n",
      "Epoch: 1 Iteration: 6400  Loss: 0.7957044839859009  Accuracy: 81.57310485839844 %\n",
      "Epoch: 1 Iteration: 6500  Loss: 0.8614177107810974  Accuracy: 81.58401489257812 %\n",
      "Epoch: 1 Iteration: 6600  Loss: 2.4476704597473145  Accuracy: 39.882442474365234 %\n",
      "Epoch: 1 Iteration: 6700  Loss: 0.8167340755462646  Accuracy: 81.61468505859375 %\n",
      "Epoch: 1 Iteration: 6800  Loss: 0.8102609515190125  Accuracy: 81.57711029052734 %\n",
      "Epoch: 1 Iteration: 6900  Loss: 1.1532701253890991  Accuracy: 81.59214782714844 %\n",
      "Epoch: 1 Iteration: 7000  Loss: 0.8369342088699341  Accuracy: 81.6031723022461 %\n",
      "Epoch: 1 Iteration: 7100  Loss: 0.8751384019851685  Accuracy: 81.60863494873047 %\n",
      "Epoch: 1 Iteration: 7200  Loss: 0.9073799848556519  Accuracy: 81.62754821777344 %\n",
      "Epoch: 1 Iteration: 7300  Loss: 1.0718317031860352  Accuracy: 81.63736724853516 %\n",
      "Epoch: 1 Iteration: 7400  Loss: 0.768170177936554  Accuracy: 81.63821411132812 %\n",
      "Fold 5 Epoch No. : 0 Accuracy for Epoch : 81.63130187988281\n",
      "Epochs completed. Time taken (seconds):  2182.0284247398376\n",
      "Average accuracy over all epochs 81.63130187988281\n",
      "Start training...\n",
      "Completed loading data and returning pytorch train and validation data loaders\n",
      "Epoch: 1 Iteration: 0  Loss: 1.104424238204956  Accuracy: 81.63408660888672 %\n",
      "Epoch: 1 Iteration: 100  Loss: 0.7912219166755676  Accuracy: 81.642333984375 %\n",
      "Epoch: 1 Iteration: 200  Loss: 0.9078007936477661  Accuracy: 81.641845703125 %\n",
      "Epoch: 1 Iteration: 300  Loss: 0.830919086933136  Accuracy: 81.64378356933594 %\n",
      "Epoch: 1 Iteration: 400  Loss: 0.8118857145309448  Accuracy: 81.63057708740234 %\n",
      "Epoch: 1 Iteration: 500  Loss: 5.3913350105285645  Accuracy: 81.5381851196289 %\n",
      "Epoch: 1 Iteration: 600  Loss: 11.954937934875488  Accuracy: 81.56413269042969 %\n",
      "Epoch: 1 Iteration: 700  Loss: 0.8850741386413574  Accuracy: 81.55406188964844 %\n",
      "Epoch: 1 Iteration: 800  Loss: 0.882441520690918  Accuracy: 81.63482666015625 %\n",
      "Epoch: 1 Iteration: 900  Loss: 0.7324746251106262  Accuracy: 81.6460952758789 %\n",
      "Epoch: 1 Iteration: 1000  Loss: 0.8788158893585205  Accuracy: 81.65445709228516 %\n",
      "Epoch: 1 Iteration: 1100  Loss: 0.9352796077728271  Accuracy: 81.63348388671875 %\n",
      "Epoch: 1 Iteration: 1200  Loss: 0.9495511651039124  Accuracy: 81.63482666015625 %\n",
      "Epoch: 1 Iteration: 1300  Loss: 0.8419989347457886  Accuracy: 81.6102066040039 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 1400  Loss: 0.8165351152420044  Accuracy: 81.63348388671875 %\n",
      "Epoch: 1 Iteration: 1500  Loss: 0.8563674092292786  Accuracy: 81.61190032958984 %\n",
      "Epoch: 1 Iteration: 1600  Loss: 0.8337306976318359  Accuracy: 81.61759948730469 %\n",
      "Epoch: 1 Iteration: 1700  Loss: 0.7716463208198547  Accuracy: 81.39936065673828 %\n",
      "Epoch: 1 Iteration: 1800  Loss: 0.9267963767051697  Accuracy: 81.64512634277344 %\n",
      "Epoch: 1 Iteration: 1900  Loss: 0.799351692199707  Accuracy: 81.64500427246094 %\n",
      "Epoch: 1 Iteration: 2000  Loss: 0.9273772835731506  Accuracy: 81.64900207519531 %\n",
      "Epoch: 1 Iteration: 2100  Loss: 0.8523193001747131  Accuracy: 81.62014770507812 %\n",
      "Epoch: 1 Iteration: 2200  Loss: 0.8001448512077332  Accuracy: 81.64463806152344 %\n",
      "Epoch: 1 Iteration: 2300  Loss: 0.8811419606208801  Accuracy: 81.61711120605469 %\n",
      "Epoch: 1 Iteration: 2400  Loss: 0.9060463905334473  Accuracy: 81.64366912841797 %\n",
      "Epoch: 1 Iteration: 2500  Loss: 0.7689059972763062  Accuracy: 81.6217269897461 %\n",
      "Epoch: 1 Iteration: 2600  Loss: 0.7856929302215576  Accuracy: 81.64027404785156 %\n",
      "Epoch: 1 Iteration: 2700  Loss: 0.8989136815071106  Accuracy: 81.63275909423828 %\n",
      "Epoch: 1 Iteration: 2800  Loss: 0.8851042985916138  Accuracy: 79.3375015258789 %\n",
      "Epoch: 1 Iteration: 2900  Loss: 1.1260485649108887  Accuracy: 79.5096664428711 %\n",
      "Epoch: 1 Iteration: 3000  Loss: 0.9085014462471008  Accuracy: 79.51730346679688 %\n",
      "Epoch: 1 Iteration: 3100  Loss: 0.9593079090118408  Accuracy: 79.68753051757812 %\n",
      "Epoch: 1 Iteration: 3200  Loss: 0.914060115814209  Accuracy: 80.39717102050781 %\n",
      "Epoch: 1 Iteration: 3300  Loss: 0.9083157181739807  Accuracy: 80.48191833496094 %\n",
      "Epoch: 1 Iteration: 3400  Loss: 0.789878785610199  Accuracy: 80.64608001708984 %\n",
      "Epoch: 1 Iteration: 3500  Loss: 0.8098533153533936  Accuracy: 80.64813995361328 %\n",
      "Epoch: 1 Iteration: 3600  Loss: 0.8855000734329224  Accuracy: 80.72367858886719 %\n",
      "Epoch: 1 Iteration: 3700  Loss: 0.8982043266296387  Accuracy: 80.87462615966797 %\n",
      "Epoch: 1 Iteration: 3800  Loss: 0.7672290802001953  Accuracy: 81.58401489257812 %\n",
      "Epoch: 1 Iteration: 3900  Loss: 0.9102513194084167  Accuracy: 81.57989501953125 %\n",
      "Epoch: 1 Iteration: 4000  Loss: 0.7803754210472107  Accuracy: 81.57359313964844 %\n",
      "Epoch: 1 Iteration: 4100  Loss: 0.9563601613044739  Accuracy: 81.58364868164062 %\n",
      "Epoch: 1 Iteration: 4200  Loss: 0.8862455487251282  Accuracy: 81.59893798828125 %\n",
      "Epoch: 1 Iteration: 4300  Loss: 0.8714127540588379  Accuracy: 81.60608673095703 %\n",
      "Epoch: 1 Iteration: 4400  Loss: 0.8465123772621155  Accuracy: 81.60038757324219 %\n",
      "Epoch: 1 Iteration: 4500  Loss: 0.8643603920936584  Accuracy: 81.59990692138672 %\n",
      "Epoch: 1 Iteration: 4600  Loss: 0.8648163676261902  Accuracy: 81.60147857666016 %\n",
      "Epoch: 1 Iteration: 4700  Loss: 0.8289608359336853  Accuracy: 81.58716583251953 %\n",
      "Epoch: 1 Iteration: 4800  Loss: 0.8257336020469666  Accuracy: 81.59941864013672 %\n",
      "Epoch: 1 Iteration: 4900  Loss: 0.864255428314209  Accuracy: 81.59722900390625 %\n",
      "Epoch: 1 Iteration: 5000  Loss: 0.8437424302101135  Accuracy: 81.60195922851562 %\n",
      "Epoch: 1 Iteration: 5100  Loss: 0.9184532761573792  Accuracy: 81.58826446533203 %\n",
      "Epoch: 1 Iteration: 5200  Loss: 0.7427477836608887  Accuracy: 81.55891418457031 %\n",
      "Epoch: 1 Iteration: 5300  Loss: 0.9124379754066467  Accuracy: 81.59613800048828 %\n",
      "Epoch: 1 Iteration: 5400  Loss: 0.868205726146698  Accuracy: 81.60449981689453 %\n",
      "Epoch: 1 Iteration: 5500  Loss: 0.8650797009468079  Accuracy: 81.57298278808594 %\n",
      "Epoch: 1 Iteration: 5600  Loss: 0.9299244284629822  Accuracy: 81.64148712158203 %\n",
      "Epoch: 1 Iteration: 5700  Loss: 0.8351439833641052  Accuracy: 81.78843688964844 %\n",
      "Epoch: 1 Iteration: 5800  Loss: 0.7641294598579407  Accuracy: 81.94834899902344 %\n",
      "Epoch: 1 Iteration: 5900  Loss: 0.8569983839988708  Accuracy: 81.94617462158203 %\n",
      "Epoch: 1 Iteration: 6000  Loss: 0.860297679901123  Accuracy: 81.947021484375 %\n",
      "Epoch: 1 Iteration: 6100  Loss: 0.8700428605079651  Accuracy: 81.95222473144531 %\n",
      "Epoch: 1 Iteration: 6200  Loss: 0.8497127890586853  Accuracy: 81.96981048583984 %\n",
      "Epoch: 1 Iteration: 6300  Loss: 0.7756841778755188  Accuracy: 81.95404815673828 %\n",
      "Epoch: 1 Iteration: 6400  Loss: 0.8464341163635254  Accuracy: 81.97733306884766 %\n",
      "Epoch: 1 Iteration: 6500  Loss: 1.0242246389389038  Accuracy: 81.95623016357422 %\n",
      "Epoch: 1 Iteration: 6600  Loss: 0.8128905892372131  Accuracy: 81.97405242919922 %\n",
      "Epoch: 1 Iteration: 6700  Loss: 0.8405814170837402  Accuracy: 81.96024322509766 %\n",
      "Epoch: 1 Iteration: 6800  Loss: 0.8064361810684204  Accuracy: 81.90967559814453 %\n",
      "Epoch: 1 Iteration: 6900  Loss: 0.845438539981842  Accuracy: 81.96205139160156 %\n",
      "Epoch: 1 Iteration: 7000  Loss: 0.8484400510787964  Accuracy: 81.98048400878906 %\n",
      "Epoch: 1 Iteration: 7100  Loss: 0.7847420573234558  Accuracy: 81.98206329345703 %\n",
      "Epoch: 1 Iteration: 7200  Loss: 0.8153802752494812  Accuracy: 81.93379974365234 %\n",
      "Epoch: 1 Iteration: 7300  Loss: 0.814131498336792  Accuracy: 81.97999572753906 %\n",
      "Epoch: 1 Iteration: 7400  Loss: 0.820032000541687  Accuracy: 81.94860076904297 %\n",
      "Fold 6 Epoch No. : 0 Accuracy for Epoch : 81.97721099853516\n",
      "Epochs completed. Time taken (seconds):  2319.1017322540283\n",
      "Average accuracy over all epochs 81.97721099853516\n",
      "Start training...\n",
      "Completed loading data and returning pytorch train and validation data loaders\n",
      "Epoch: 1 Iteration: 0  Loss: 0.8909711837768555  Accuracy: 81.97781372070312 %\n",
      "Epoch: 1 Iteration: 100  Loss: 0.799384355545044  Accuracy: 81.98374938964844 %\n",
      "Epoch: 1 Iteration: 200  Loss: 0.8171697854995728  Accuracy: 81.9796371459961 %\n",
      "Epoch: 1 Iteration: 300  Loss: 0.8341065049171448  Accuracy: 81.95975494384766 %\n",
      "Epoch: 1 Iteration: 400  Loss: 0.7944797873497009  Accuracy: 81.98255157470703 %\n",
      "Epoch: 1 Iteration: 500  Loss: 0.8393069505691528  Accuracy: 81.92700958251953 %\n",
      "Epoch: 1 Iteration: 600  Loss: 0.8393383026123047  Accuracy: 81.98339080810547 %\n",
      "Epoch: 1 Iteration: 700  Loss: 0.8974586129188538  Accuracy: 81.96289825439453 %\n",
      "Epoch: 1 Iteration: 800  Loss: 0.8809110522270203  Accuracy: 81.98314666748047 %\n",
      "Epoch: 1 Iteration: 900  Loss: 0.8019841909408569  Accuracy: 81.98339080810547 %\n",
      "Epoch: 1 Iteration: 1000  Loss: 0.8736937046051025  Accuracy: 81.96593475341797 %\n",
      "Epoch: 1 Iteration: 1100  Loss: 1.180260181427002  Accuracy: 81.97999572753906 %\n",
      "Epoch: 1 Iteration: 1200  Loss: 0.7986520528793335  Accuracy: 81.97721099853516 %\n",
      "Epoch: 1 Iteration: 1300  Loss: 0.8308839797973633  Accuracy: 81.97211456298828 %\n",
      "Epoch: 1 Iteration: 1400  Loss: 0.842721164226532  Accuracy: 81.97369384765625 %\n",
      "Epoch: 1 Iteration: 1500  Loss: 0.7953994870185852  Accuracy: 81.97769927978516 %\n",
      "Epoch: 1 Iteration: 1600  Loss: 0.8500550389289856  Accuracy: 81.98035430908203 %\n",
      "Epoch: 1 Iteration: 1700  Loss: 0.9023217558860779  Accuracy: 81.28575897216797 %\n",
      "Epoch: 1 Iteration: 1800  Loss: 0.9007198214530945  Accuracy: 81.89645385742188 %\n",
      "Epoch: 1 Iteration: 1900  Loss: 0.8431652784347534  Accuracy: 81.91210174560547 %\n",
      "Epoch: 1 Iteration: 2000  Loss: 0.8727923631668091  Accuracy: 81.84832763671875 %\n",
      "Epoch: 1 Iteration: 2100  Loss: 0.890245795249939  Accuracy: 81.94507598876953 %\n",
      "Epoch: 1 Iteration: 2200  Loss: 0.7689716815948486  Accuracy: 81.96035766601562 %\n",
      "Epoch: 1 Iteration: 2300  Loss: 0.8339025378227234  Accuracy: 81.97430419921875 %\n",
      "Epoch: 1 Iteration: 2400  Loss: 0.7939819097518921  Accuracy: 81.97854614257812 %\n",
      "Epoch: 1 Iteration: 2500  Loss: 0.8885201215744019  Accuracy: 81.9436264038086 %\n",
      "Epoch: 1 Iteration: 2600  Loss: 0.8837885856628418  Accuracy: 81.98497009277344 %\n",
      "Epoch: 1 Iteration: 2700  Loss: 0.8191892504692078  Accuracy: 81.35838317871094 %\n",
      "Epoch: 1 Iteration: 2800  Loss: 0.8479366302490234  Accuracy: 81.94956970214844 %\n",
      "Epoch: 1 Iteration: 2900  Loss: 0.8043579459190369  Accuracy: 81.9510269165039 %\n",
      "Epoch: 1 Iteration: 3000  Loss: 0.8771665692329407  Accuracy: 81.96920013427734 %\n",
      "Epoch: 1 Iteration: 3100  Loss: 0.7492882013320923  Accuracy: 81.98278045654297 %\n",
      "Epoch: 1 Iteration: 3200  Loss: 0.8382091522216797  Accuracy: 81.97744750976562 %\n",
      "Epoch: 1 Iteration: 3300  Loss: 0.8139679431915283  Accuracy: 81.93901824951172 %\n",
      "Epoch: 1 Iteration: 3400  Loss: 0.877199113368988  Accuracy: 81.97479248046875 %\n",
      "Epoch: 1 Iteration: 3500  Loss: 0.774600088596344  Accuracy: 81.97259521484375 %\n",
      "Epoch: 1 Iteration: 3600  Loss: 0.7793604135513306  Accuracy: 81.97587585449219 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 3700  Loss: 0.7534970641136169  Accuracy: 81.98035430908203 %\n",
      "Epoch: 1 Iteration: 3800  Loss: 0.7926412224769592  Accuracy: 81.965087890625 %\n",
      "Epoch: 1 Iteration: 3900  Loss: 0.9135222434997559  Accuracy: 81.982421875 %\n",
      "Epoch: 1 Iteration: 4000  Loss: 0.8118467926979065  Accuracy: 81.97624206542969 %\n",
      "Epoch: 1 Iteration: 4100  Loss: 0.8209523558616638  Accuracy: 81.94410705566406 %\n",
      "Epoch: 1 Iteration: 4200  Loss: 0.8127445578575134  Accuracy: 81.97211456298828 %\n",
      "Epoch: 1 Iteration: 4300  Loss: 0.838043212890625  Accuracy: 81.9795150756836 %\n",
      "Epoch: 1 Iteration: 4400  Loss: 0.7965112328529358  Accuracy: 81.9779281616211 %\n",
      "Epoch: 1 Iteration: 4500  Loss: 0.8579010963439941  Accuracy: 81.98193359375 %\n",
      "Epoch: 1 Iteration: 4600  Loss: 0.8257718086242676  Accuracy: 81.97999572753906 %\n",
      "Epoch: 1 Iteration: 4700  Loss: 0.8365787267684937  Accuracy: 81.97673034667969 %\n",
      "Epoch: 1 Iteration: 4800  Loss: 0.8746343851089478  Accuracy: 81.98096466064453 %\n",
      "Epoch: 1 Iteration: 4900  Loss: 0.798916220664978  Accuracy: 81.94738006591797 %\n",
      "Epoch: 1 Iteration: 5000  Loss: 0.8342554569244385  Accuracy: 81.9499282836914 %\n",
      "Epoch: 1 Iteration: 5100  Loss: 0.7955591082572937  Accuracy: 81.94750213623047 %\n",
      "Epoch: 1 Iteration: 5200  Loss: 0.7863926291465759  Accuracy: 81.96823120117188 %\n",
      "Epoch: 1 Iteration: 5300  Loss: 0.7815952301025391  Accuracy: 81.97090911865234 %\n",
      "Epoch: 1 Iteration: 5400  Loss: 0.849933385848999  Accuracy: 81.97042083740234 %\n",
      "Epoch: 1 Iteration: 5500  Loss: 0.8367628455162048  Accuracy: 81.9795150756836 %\n",
      "Epoch: 1 Iteration: 5600  Loss: 0.8508093357086182  Accuracy: 81.97708892822266 %\n",
      "Epoch: 1 Iteration: 5700  Loss: 0.7640194892883301  Accuracy: 81.97248077392578 %\n",
      "Epoch: 1 Iteration: 5800  Loss: 0.8284033536911011  Accuracy: 81.97769927978516 %\n",
      "Epoch: 1 Iteration: 5900  Loss: 0.8040757179260254  Accuracy: 81.9454345703125 %\n",
      "Epoch: 1 Iteration: 6000  Loss: 0.8668491244316101  Accuracy: 81.8716049194336 %\n",
      "Epoch: 1 Iteration: 6100  Loss: 0.8577170372009277  Accuracy: 81.97016906738281 %\n",
      "Epoch: 1 Iteration: 6200  Loss: 0.8026447892189026  Accuracy: 81.92047119140625 %\n",
      "Epoch: 1 Iteration: 6300  Loss: 0.8429452180862427  Accuracy: 81.96908569335938 %\n",
      "Epoch: 1 Iteration: 6400  Loss: 0.8252707123756409  Accuracy: 81.97999572753906 %\n",
      "Epoch: 1 Iteration: 6500  Loss: 0.8104573488235474  Accuracy: 81.9789047241211 %\n",
      "Epoch: 1 Iteration: 6600  Loss: 0.852806031703949  Accuracy: 81.92955780029297 %\n",
      "Epoch: 1 Iteration: 6700  Loss: 0.8324472308158875  Accuracy: 81.96957397460938 %\n",
      "Epoch: 1 Iteration: 6800  Loss: 0.7751129865646362  Accuracy: 81.95793151855469 %\n",
      "Epoch: 1 Iteration: 6900  Loss: 0.7891353368759155  Accuracy: 81.8758544921875 %\n",
      "Epoch: 1 Iteration: 7000  Loss: 0.7711821794509888  Accuracy: 81.91258239746094 %\n",
      "Epoch: 1 Iteration: 7100  Loss: 0.786117434501648  Accuracy: 81.51805877685547 %\n",
      "Epoch: 1 Iteration: 7200  Loss: 0.8418142199516296  Accuracy: 81.5145492553711 %\n",
      "Epoch: 1 Iteration: 7300  Loss: 0.8271871209144592  Accuracy: 81.57286071777344 %\n",
      "Epoch: 1 Iteration: 7400  Loss: 0.7469986081123352  Accuracy: 81.54704284667969 %\n",
      "Fold 7 Epoch No. : 0 Accuracy for Epoch : 81.5740737915039\n",
      "Epochs completed. Time taken (seconds):  2262.543430328369\n",
      "Average accuracy over all epochs 81.5740737915039\n",
      "Start training...\n",
      "Completed loading data and returning pytorch train and validation data loaders\n",
      "Epoch: 1 Iteration: 0  Loss: 0.7717611789703369  Accuracy: 81.58558654785156 %\n",
      "Epoch: 1 Iteration: 100  Loss: 0.8458143472671509  Accuracy: 81.58038330078125 %\n",
      "Epoch: 1 Iteration: 200  Loss: 0.9124101996421814  Accuracy: 81.57879638671875 %\n",
      "Epoch: 1 Iteration: 300  Loss: 0.7797573804855347  Accuracy: 81.57323455810547 %\n",
      "Epoch: 1 Iteration: 400  Loss: 0.863404393196106  Accuracy: 81.59237670898438 %\n",
      "Epoch: 1 Iteration: 500  Loss: 0.8026166558265686  Accuracy: 81.58025360107422 %\n",
      "Epoch: 1 Iteration: 600  Loss: 0.8260746002197266  Accuracy: 81.54461669921875 %\n",
      "Epoch: 1 Iteration: 700  Loss: 0.811091959476471  Accuracy: 81.5851058959961 %\n",
      "Epoch: 1 Iteration: 800  Loss: 0.8979726433753967  Accuracy: 81.57103729248047 %\n",
      "Epoch: 1 Iteration: 900  Loss: 0.8272490501403809  Accuracy: 81.57892608642578 %\n",
      "Epoch: 1 Iteration: 1000  Loss: 0.9313109517097473  Accuracy: 81.58219146728516 %\n",
      "Epoch: 1 Iteration: 1100  Loss: 0.8398828506469727  Accuracy: 81.59104919433594 %\n",
      "Epoch: 1 Iteration: 1200  Loss: 0.8957061171531677  Accuracy: 81.57164764404297 %\n",
      "Epoch: 1 Iteration: 1300  Loss: 0.8695498704910278  Accuracy: 81.54074096679688 %\n",
      "Epoch: 1 Iteration: 1400  Loss: 0.8434641361236572  Accuracy: 81.5863265991211 %\n",
      "Epoch: 1 Iteration: 1500  Loss: 0.8691988587379456  Accuracy: 81.58038330078125 %\n",
      "Epoch: 1 Iteration: 1600  Loss: 0.847321629524231  Accuracy: 81.58826446533203 %\n",
      "Epoch: 1 Iteration: 1700  Loss: 0.7965711355209351  Accuracy: 81.57674407958984 %\n",
      "Epoch: 1 Iteration: 1800  Loss: 0.9000847339630127  Accuracy: 81.5033950805664 %\n",
      "Epoch: 1 Iteration: 1900  Loss: 0.8759469389915466  Accuracy: 81.50775909423828 %\n",
      "Epoch: 1 Iteration: 2000  Loss: 0.8501570820808411  Accuracy: 81.5392837524414 %\n",
      "Epoch: 1 Iteration: 2100  Loss: 0.8145244717597961  Accuracy: 81.58898162841797 %\n",
      "Epoch: 1 Iteration: 2200  Loss: 0.89352947473526  Accuracy: 81.589111328125 %\n",
      "Epoch: 1 Iteration: 2300  Loss: 0.8577934503555298  Accuracy: 81.5888671875 %\n",
      "Epoch: 1 Iteration: 2400  Loss: 0.8231540322303772  Accuracy: 81.5880126953125 %\n",
      "Epoch: 1 Iteration: 2500  Loss: 0.8890947699546814  Accuracy: 81.59323120117188 %\n",
      "Epoch: 1 Iteration: 2600  Loss: 0.8638690710067749  Accuracy: 81.5566177368164 %\n",
      "Epoch: 1 Iteration: 2700  Loss: 0.8902401924133301  Accuracy: 81.60269165039062 %\n",
      "Epoch: 1 Iteration: 2800  Loss: 0.9413080811500549  Accuracy: 81.60789489746094 %\n",
      "Epoch: 1 Iteration: 2900  Loss: 0.8452454805374146  Accuracy: 81.48411560058594 %\n",
      "Epoch: 1 Iteration: 3000  Loss: 0.8458417654037476  Accuracy: 81.5533447265625 %\n",
      "Epoch: 1 Iteration: 3100  Loss: 80.83458709716797  Accuracy: 81.48920440673828 %\n",
      "Epoch: 1 Iteration: 3200  Loss: 15.922893524169922  Accuracy: 81.46023559570312 %\n",
      "Epoch: 1 Iteration: 3300  Loss: 226.23123168945312  Accuracy: 80.56836700439453 %\n",
      "Epoch: 1 Iteration: 3400  Loss: 13.316030502319336  Accuracy: 81.57759857177734 %\n",
      "Epoch: 1 Iteration: 3500  Loss: 0.8065945506095886  Accuracy: 81.56170654296875 %\n",
      "Epoch: 1 Iteration: 3600  Loss: 0.8794535994529724  Accuracy: 81.56813049316406 %\n",
      "Epoch: 1 Iteration: 3700  Loss: 1.8759963512420654  Accuracy: 81.57286071777344 %\n",
      "Epoch: 1 Iteration: 3800  Loss: 0.8533024191856384  Accuracy: 81.5380630493164 %\n",
      "Epoch: 1 Iteration: 3900  Loss: 1.0368385314941406  Accuracy: 81.48362731933594 %\n",
      "Epoch: 1 Iteration: 4000  Loss: 2.9349863529205322  Accuracy: 81.54267883300781 %\n",
      "Epoch: 1 Iteration: 4100  Loss: 0.742400586605072  Accuracy: 81.58074188232422 %\n",
      "Epoch: 1 Iteration: 4200  Loss: 0.8130772709846497  Accuracy: 81.58256530761719 %\n",
      "Epoch: 1 Iteration: 4300  Loss: 3.9150497913360596  Accuracy: 81.60147857666016 %\n",
      "Epoch: 1 Iteration: 4400  Loss: 19.185354232788086  Accuracy: 81.58135223388672 %\n",
      "Epoch: 1 Iteration: 4500  Loss: 0.8073834776878357  Accuracy: 81.60087585449219 %\n",
      "Epoch: 1 Iteration: 4600  Loss: 0.9613358974456787  Accuracy: 81.58122253417969 %\n",
      "Epoch: 1 Iteration: 4700  Loss: 0.9440189599990845  Accuracy: 81.57795715332031 %\n",
      "Epoch: 1 Iteration: 4800  Loss: 395.10174560546875  Accuracy: 81.5740737915039 %\n",
      "Epoch: 1 Iteration: 4900  Loss: 0.7934662103652954  Accuracy: 81.49284362792969 %\n",
      "Epoch: 1 Iteration: 5000  Loss: 0.8205258250236511  Accuracy: 81.59699249267578 %\n",
      "Epoch: 1 Iteration: 5100  Loss: 9.49992561340332  Accuracy: 81.57795715332031 %\n",
      "Epoch: 1 Iteration: 5200  Loss: 0.8412898778915405  Accuracy: 81.57601165771484 %\n",
      "Epoch: 1 Iteration: 5300  Loss: 0.7903246283531189  Accuracy: 81.57565307617188 %\n",
      "Epoch: 1 Iteration: 5400  Loss: 0.8551835417747498  Accuracy: 81.60026550292969 %\n",
      "Epoch: 1 Iteration: 5500  Loss: 0.7878081798553467  Accuracy: 81.01514434814453 %\n",
      "Epoch: 1 Iteration: 5600  Loss: 0.8733395338058472  Accuracy: 81.59965515136719 %\n",
      "Epoch: 1 Iteration: 5700  Loss: 0.8120645880699158  Accuracy: 81.58244323730469 %\n",
      "Epoch: 1 Iteration: 5800  Loss: 0.8551668524742126  Accuracy: 81.59613800048828 %\n",
      "Epoch: 1 Iteration: 5900  Loss: 0.8860244750976562  Accuracy: 81.6110610961914 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 6000  Loss: 0.8468315005302429  Accuracy: 81.60195922851562 %\n",
      "Epoch: 1 Iteration: 6100  Loss: 0.8251774311065674  Accuracy: 81.53721618652344 %\n",
      "Epoch: 1 Iteration: 6200  Loss: 0.8156551718711853  Accuracy: 81.57820129394531 %\n",
      "Epoch: 1 Iteration: 6300  Loss: 0.8630697131156921  Accuracy: 81.45065307617188 %\n",
      "Epoch: 1 Iteration: 6400  Loss: 0.8607076406478882  Accuracy: 81.55309295654297 %\n",
      "Epoch: 1 Iteration: 6500  Loss: 0.8186013102531433  Accuracy: 81.49430084228516 %\n",
      "Epoch: 1 Iteration: 6600  Loss: 0.9250956773757935  Accuracy: 81.48969268798828 %\n",
      "Epoch: 1 Iteration: 6700  Loss: 0.8734655976295471  Accuracy: 81.50787353515625 %\n",
      "Epoch: 1 Iteration: 6800  Loss: 0.8456119894981384  Accuracy: 81.56631469726562 %\n",
      "Epoch: 1 Iteration: 6900  Loss: 0.8961796164512634  Accuracy: 81.57649993896484 %\n",
      "Epoch: 1 Iteration: 7000  Loss: 0.8174991011619568  Accuracy: 81.56170654296875 %\n",
      "Epoch: 1 Iteration: 7100  Loss: 0.8423861265182495  Accuracy: 81.58061981201172 %\n",
      "Epoch: 1 Iteration: 7200  Loss: 0.855089545249939  Accuracy: 81.5561294555664 %\n",
      "Epoch: 1 Iteration: 7300  Loss: 0.901500403881073  Accuracy: 81.54109954833984 %\n",
      "Epoch: 1 Iteration: 7400  Loss: 0.7969726324081421  Accuracy: 81.570068359375 %\n",
      "Fold 8 Epoch No. : 0 Accuracy for Epoch : 81.58183288574219\n",
      "Epochs completed. Time taken (seconds):  2240.5490243434906\n",
      "Average accuracy over all epochs 81.58183288574219\n",
      "Start training...\n",
      "Completed loading data and returning pytorch train and validation data loaders\n",
      "Epoch: 1 Iteration: 0  Loss: 0.7712758183479309  Accuracy: 81.57344818115234 %\n",
      "Epoch: 1 Iteration: 100  Loss: 0.9241784811019897  Accuracy: 81.57587432861328 %\n",
      "Epoch: 1 Iteration: 200  Loss: 0.8570497632026672  Accuracy: 80.93510437011719 %\n",
      "Epoch: 1 Iteration: 300  Loss: 0.804481565952301  Accuracy: 81.58411407470703 %\n",
      "Epoch: 1 Iteration: 400  Loss: 0.830045223236084  Accuracy: 81.54203796386719 %\n",
      "Epoch: 1 Iteration: 500  Loss: 0.9199105501174927  Accuracy: 81.57975006103516 %\n",
      "Epoch: 1 Iteration: 600  Loss: 0.7917502522468567  Accuracy: 81.56690216064453 %\n",
      "Epoch: 1 Iteration: 700  Loss: 0.9093940258026123  Accuracy: 81.5818099975586 %\n",
      "Epoch: 1 Iteration: 800  Loss: 0.9003268480300903  Accuracy: 81.5701675415039 %\n",
      "Epoch: 1 Iteration: 900  Loss: 1.061047077178955  Accuracy: 76.56197357177734 %\n",
      "Epoch: 1 Iteration: 1000  Loss: 1.0254619121551514  Accuracy: 77.31271362304688 %\n",
      "Epoch: 1 Iteration: 1100  Loss: 1.0626451969146729  Accuracy: 77.67475128173828 %\n",
      "Epoch: 1 Iteration: 1200  Loss: 1.0030544996261597  Accuracy: 77.82035827636719 %\n",
      "Epoch: 1 Iteration: 1300  Loss: 0.9236101508140564  Accuracy: 77.91650390625 %\n",
      "Epoch: 1 Iteration: 1400  Loss: 0.9417051672935486  Accuracy: 78.03690338134766 %\n",
      "Epoch: 1 Iteration: 1500  Loss: 1.02870512008667  Accuracy: 78.10868072509766 %\n",
      "Epoch: 1 Iteration: 1600  Loss: 1.0543912649154663  Accuracy: 78.26750946044922 %\n",
      "Epoch: 1 Iteration: 1700  Loss: 0.9846669435501099  Accuracy: 78.89881896972656 %\n",
      "Epoch: 1 Iteration: 1800  Loss: 0.9183481931686401  Accuracy: 78.9878158569336 %\n",
      "Epoch: 1 Iteration: 1900  Loss: 1.0245230197906494  Accuracy: 79.01679229736328 %\n",
      "Epoch: 1 Iteration: 2000  Loss: 0.9595267176628113  Accuracy: 79.03509521484375 %\n",
      "Epoch: 1 Iteration: 2100  Loss: 0.9200880527496338  Accuracy: 79.05716705322266 %\n",
      "Epoch: 1 Iteration: 2200  Loss: 0.9518975019454956  Accuracy: 79.06455993652344 %\n",
      "Epoch: 1 Iteration: 2300  Loss: 0.9615478515625  Accuracy: 79.07935333251953 %\n",
      "Epoch: 1 Iteration: 2400  Loss: 0.9854400753974915  Accuracy: 79.0768051147461 %\n",
      "Epoch: 1 Iteration: 2500  Loss: 0.9352849125862122  Accuracy: 79.1019058227539 %\n",
      "Epoch: 1 Iteration: 2600  Loss: 0.9875434041023254  Accuracy: 79.12239074707031 %\n",
      "Epoch: 1 Iteration: 2700  Loss: 0.9771907925605774  Accuracy: 79.1480941772461 %\n",
      "Epoch: 1 Iteration: 2800  Loss: 0.8909667134284973  Accuracy: 79.19004821777344 %\n",
      "Epoch: 1 Iteration: 2900  Loss: 0.8647329211235046  Accuracy: 80.8191909790039 %\n",
      "Epoch: 1 Iteration: 3000  Loss: 0.8273344039916992  Accuracy: 80.87496185302734 %\n",
      "Epoch: 1 Iteration: 3100  Loss: 0.7794392108917236  Accuracy: 80.98480987548828 %\n",
      "Epoch: 1 Iteration: 3200  Loss: 0.959335207939148  Accuracy: 81.0482177734375 %\n",
      "Epoch: 1 Iteration: 3300  Loss: 0.8490791916847229  Accuracy: 81.19953155517578 %\n",
      "Epoch: 1 Iteration: 3400  Loss: 0.8448202013969421  Accuracy: 81.50785827636719 %\n",
      "Epoch: 1 Iteration: 3500  Loss: 0.8959551453590393  Accuracy: 81.4922103881836 %\n",
      "Epoch: 1 Iteration: 3600  Loss: 0.9612284302711487  Accuracy: 81.48954772949219 %\n",
      "Epoch: 1 Iteration: 3700  Loss: 0.8979529738426208  Accuracy: 81.53889465332031 %\n",
      "Epoch: 1 Iteration: 3800  Loss: 0.9191724061965942  Accuracy: 81.54241180419922 %\n",
      "Epoch: 1 Iteration: 3900  Loss: 0.8656895160675049  Accuracy: 81.53330993652344 %\n",
      "Epoch: 1 Iteration: 4000  Loss: 0.8456642627716064  Accuracy: 77.52913665771484 %\n",
      "Epoch: 1 Iteration: 4100  Loss: 0.8973657488822937  Accuracy: 81.56544494628906 %\n",
      "Epoch: 1 Iteration: 4200  Loss: 0.8416163921356201  Accuracy: 81.57695770263672 %\n",
      "Epoch: 1 Iteration: 4300  Loss: 0.8416507840156555  Accuracy: 81.6889877319336 %\n",
      "Epoch: 1 Iteration: 4400  Loss: 0.8375520706176758  Accuracy: 81.3490219116211 %\n",
      "Epoch: 1 Iteration: 4500  Loss: 0.7987659573554993  Accuracy: 81.90650939941406 %\n",
      "Epoch: 1 Iteration: 4600  Loss: 0.952911376953125  Accuracy: 81.53004455566406 %\n",
      "Epoch: 1 Iteration: 4700  Loss: 0.8247247338294983  Accuracy: 81.73845672607422 %\n",
      "Epoch: 1 Iteration: 4800  Loss: 0.8072175979614258  Accuracy: 81.76925659179688 %\n",
      "Epoch: 1 Iteration: 4900  Loss: 169.16249084472656  Accuracy: 81.8683090209961 %\n",
      "Epoch: 1 Iteration: 5000  Loss: 0.8029254674911499  Accuracy: 81.88322448730469 %\n",
      "Epoch: 1 Iteration: 5100  Loss: 0.9115871787071228  Accuracy: 81.9044418334961 %\n",
      "Epoch: 1 Iteration: 5200  Loss: 0.84833824634552  Accuracy: 81.88782501220703 %\n",
      "Epoch: 1 Iteration: 5300  Loss: 12.61251449584961  Accuracy: 81.88019561767578 %\n",
      "Epoch: 1 Iteration: 5400  Loss: 0.7558547854423523  Accuracy: 81.93001556396484 %\n",
      "Epoch: 1 Iteration: 5500  Loss: 0.8108086585998535  Accuracy: 81.92565155029297 %\n",
      "Epoch: 1 Iteration: 5600  Loss: 0.8170078992843628  Accuracy: 81.90214538574219 %\n",
      "Epoch: 1 Iteration: 5700  Loss: 0.8469170331954956  Accuracy: 81.88043212890625 %\n",
      "Epoch: 1 Iteration: 5800  Loss: 0.7950592637062073  Accuracy: 81.89886474609375 %\n",
      "Epoch: 1 Iteration: 5900  Loss: 1.3051856756210327  Accuracy: 81.77919006347656 %\n",
      "Epoch: 1 Iteration: 6000  Loss: 0.802161693572998  Accuracy: 81.87667083740234 %\n",
      "Epoch: 1 Iteration: 6100  Loss: 0.8716477751731873  Accuracy: 81.9045639038086 %\n",
      "Epoch: 1 Iteration: 6200  Loss: 0.8363044857978821  Accuracy: 81.9229965209961 %\n",
      "Epoch: 1 Iteration: 6300  Loss: 0.8337026834487915  Accuracy: 81.92759704589844 %\n",
      "Epoch: 1 Iteration: 6400  Loss: 0.7998406291007996  Accuracy: 81.8887939453125 %\n",
      "Epoch: 1 Iteration: 6500  Loss: 0.8769134283065796  Accuracy: 81.9055404663086 %\n",
      "Epoch: 1 Iteration: 6600  Loss: 0.8311027884483337  Accuracy: 81.88043212890625 %\n",
      "Epoch: 1 Iteration: 6700  Loss: 0.8604122996330261  Accuracy: 81.91498565673828 %\n",
      "Epoch: 1 Iteration: 6800  Loss: 0.813870370388031  Accuracy: 81.92626190185547 %\n",
      "Epoch: 1 Iteration: 6900  Loss: 0.8928177952766418  Accuracy: 81.92904663085938 %\n",
      "Epoch: 1 Iteration: 7000  Loss: 0.884290337562561  Accuracy: 81.91911315917969 %\n",
      "Epoch: 1 Iteration: 7100  Loss: 0.8658969402313232  Accuracy: 81.86322021484375 %\n",
      "Epoch: 1 Iteration: 7200  Loss: 0.8360003232955933  Accuracy: 81.92117309570312 %\n",
      "Epoch: 1 Iteration: 7300  Loss: 0.9420782923698425  Accuracy: 81.93111419677734 %\n",
      "Epoch: 1 Iteration: 7400  Loss: 0.8626558780670166  Accuracy: 81.93499755859375 %\n",
      "Fold 9 Epoch No. : 0 Accuracy for Epoch : 81.93038940429688\n",
      "Epochs completed. Time taken (seconds):  2255.6139941215515\n",
      "Average accuracy over all epochs 81.93038940429688\n",
      "Start training...\n",
      "Completed loading data and returning pytorch train and validation data loaders\n",
      "Epoch: 1 Iteration: 0  Loss: 8.848067283630371  Accuracy: 81.5496826171875 %\n",
      "Epoch: 1 Iteration: 100  Loss: 0.863869309425354  Accuracy: 81.89546966552734 %\n",
      "Epoch: 1 Iteration: 200  Loss: 0.8746239542961121  Accuracy: 81.91571807861328 %\n",
      "Epoch: 1 Iteration: 300  Loss: 0.8682503700256348  Accuracy: 81.91595458984375 %\n",
      "Epoch: 1 Iteration: 400  Loss: 0.9211164116859436  Accuracy: 81.87946319580078 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 500  Loss: 0.7550186514854431  Accuracy: 81.88334655761719 %\n",
      "Epoch: 1 Iteration: 600  Loss: 0.8378651142120361  Accuracy: 81.91826629638672 %\n",
      "Epoch: 1 Iteration: 700  Loss: 0.7704294323921204  Accuracy: 81.89474487304688 %\n",
      "Epoch: 1 Iteration: 800  Loss: 0.8259454369544983  Accuracy: 81.91220092773438 %\n",
      "Epoch: 1 Iteration: 900  Loss: 0.7930015921592712  Accuracy: 81.92311096191406 %\n",
      "Epoch: 1 Iteration: 1000  Loss: 0.8787292242050171  Accuracy: 81.91802215576172 %\n",
      "Epoch: 1 Iteration: 1100  Loss: 0.8590245842933655  Accuracy: 81.90237426757812 %\n",
      "Epoch: 1 Iteration: 1200  Loss: 0.8783048987388611  Accuracy: 81.92068481445312 %\n",
      "Epoch: 1 Iteration: 1300  Loss: 0.8340209722518921  Accuracy: 81.87983703613281 %\n",
      "Epoch: 1 Iteration: 1400  Loss: 0.9004214406013489  Accuracy: 81.89729309082031 %\n",
      "Epoch: 1 Iteration: 1500  Loss: 0.8076409697532654  Accuracy: 81.88771057128906 %\n",
      "Epoch: 1 Iteration: 1600  Loss: 0.8026077151298523  Accuracy: 81.91886138916016 %\n",
      "Epoch: 1 Iteration: 1700  Loss: 0.8068568110466003  Accuracy: 81.90953063964844 %\n",
      "Epoch: 1 Iteration: 1800  Loss: 0.9433864951133728  Accuracy: 81.8747329711914 %\n",
      "Epoch: 1 Iteration: 1900  Loss: 0.8085662126541138  Accuracy: 81.89292907714844 %\n",
      "Epoch: 1 Iteration: 2000  Loss: 0.7878873944282532  Accuracy: 81.91365814208984 %\n",
      "Epoch: 1 Iteration: 2100  Loss: 0.8082162737846375  Accuracy: 81.91329956054688 %\n",
      "Epoch: 1 Iteration: 2200  Loss: 0.7553170919418335  Accuracy: 81.87230682373047 %\n",
      "Epoch: 1 Iteration: 2300  Loss: 0.8204337358474731  Accuracy: 81.8867416381836 %\n",
      "Epoch: 1 Iteration: 2400  Loss: 0.8042048215866089  Accuracy: 81.85497283935547 %\n",
      "Epoch: 1 Iteration: 2500  Loss: 0.9110828638076782  Accuracy: 81.89765167236328 %\n",
      "Epoch: 1 Iteration: 2600  Loss: 0.8333683013916016  Accuracy: 81.93075561523438 %\n",
      "Epoch: 1 Iteration: 2700  Loss: 0.9243202805519104  Accuracy: 81.9044418334961 %\n",
      "Epoch: 1 Iteration: 2800  Loss: 0.8559828400611877  Accuracy: 81.91923522949219 %\n",
      "Epoch: 1 Iteration: 2900  Loss: 0.8656154274940491  Accuracy: 81.9107437133789 %\n",
      "Epoch: 1 Iteration: 3000  Loss: 0.7361456155776978  Accuracy: 81.90311431884766 %\n",
      "Epoch: 1 Iteration: 3100  Loss: 0.7806451320648193  Accuracy: 81.90055847167969 %\n",
      "Epoch: 1 Iteration: 3200  Loss: 0.8576536774635315  Accuracy: 81.92105865478516 %\n",
      "Epoch: 1 Iteration: 3300  Loss: 0.9103876352310181  Accuracy: 81.88116455078125 %\n",
      "Epoch: 1 Iteration: 3400  Loss: 0.8393985033035278  Accuracy: 81.91826629638672 %\n",
      "Epoch: 1 Iteration: 3500  Loss: 0.8267411589622498  Accuracy: 81.91232299804688 %\n",
      "Epoch: 1 Iteration: 3600  Loss: 0.7886713743209839  Accuracy: 81.91413879394531 %\n",
      "Epoch: 1 Iteration: 3700  Loss: 5.409637928009033  Accuracy: 81.92662048339844 %\n",
      "Epoch: 1 Iteration: 3800  Loss: 0.8325120806694031  Accuracy: 81.85994720458984 %\n",
      "Epoch: 1 Iteration: 3900  Loss: 0.8521823287010193  Accuracy: 81.84867095947266 %\n",
      "Epoch: 1 Iteration: 4000  Loss: 0.9335792660713196  Accuracy: 81.34320831298828 %\n",
      "Epoch: 1 Iteration: 4100  Loss: 0.7739023566246033  Accuracy: 81.88297271728516 %\n",
      "Epoch: 1 Iteration: 4200  Loss: 0.8940390944480896  Accuracy: 81.44880676269531 %\n",
      "Epoch: 1 Iteration: 4300  Loss: 0.8020004630088806  Accuracy: 81.87692260742188 %\n",
      "Epoch: 1 Iteration: 4400  Loss: 0.833737313747406  Accuracy: 81.8900146484375 %\n",
      "Epoch: 1 Iteration: 4500  Loss: 0.8525403738021851  Accuracy: 81.8943862915039 %\n",
      "Epoch: 1 Iteration: 4600  Loss: 0.8821997046470642  Accuracy: 81.8742446899414 %\n",
      "Epoch: 1 Iteration: 4700  Loss: 0.86517333984375  Accuracy: 81.79932403564453 %\n",
      "Epoch: 1 Iteration: 4800  Loss: 0.7728037238121033  Accuracy: 81.90080261230469 %\n",
      "Epoch: 1 Iteration: 4900  Loss: 0.8150662779808044  Accuracy: 81.73518371582031 %\n",
      "Epoch: 1 Iteration: 5000  Loss: 0.8150508403778076  Accuracy: 81.8896484375 %\n",
      "Epoch: 1 Iteration: 5100  Loss: 0.7697469592094421  Accuracy: 81.77107238769531 %\n",
      "Epoch: 1 Iteration: 5200  Loss: 0.8439376950263977  Accuracy: 81.89826202392578 %\n",
      "Epoch: 1 Iteration: 5300  Loss: 0.9106346964836121  Accuracy: 81.90528106689453 %\n",
      "Epoch: 1 Iteration: 5400  Loss: 0.8472166061401367  Accuracy: 81.64485168457031 %\n",
      "Epoch: 1 Iteration: 5500  Loss: 0.9011436104774475  Accuracy: 81.90274047851562 %\n",
      "Epoch: 1 Iteration: 5600  Loss: 0.8380483984947205  Accuracy: 81.8934097290039 %\n",
      "Epoch: 1 Iteration: 5700  Loss: 0.792209267616272  Accuracy: 81.89486694335938 %\n",
      "Epoch: 1 Iteration: 5800  Loss: 0.7819423079490662  Accuracy: 81.50312805175781 %\n",
      "Epoch: 1 Iteration: 5900  Loss: 0.8425755500793457  Accuracy: 81.91826629638672 %\n",
      "Epoch: 1 Iteration: 6000  Loss: 0.827967643737793  Accuracy: 81.91911315917969 %\n",
      "Epoch: 1 Iteration: 6100  Loss: 0.8829625844955444  Accuracy: 81.92080688476562 %\n",
      "Epoch: 1 Iteration: 6200  Loss: 0.9384316205978394  Accuracy: 81.9251708984375 %\n",
      "Epoch: 1 Iteration: 6300  Loss: 0.9044643044471741  Accuracy: 81.53270721435547 %\n",
      "Epoch: 1 Iteration: 6400  Loss: 0.8465172648429871  Accuracy: 81.51815795898438 %\n",
      "Epoch: 1 Iteration: 6500  Loss: 0.8066388964653015  Accuracy: 81.57975006103516 %\n",
      "Epoch: 1 Iteration: 6600  Loss: 0.9263268113136292  Accuracy: 81.5825424194336 %\n",
      "Epoch: 1 Iteration: 6700  Loss: 0.8925580978393555  Accuracy: 81.59661102294922 %\n",
      "Epoch: 1 Iteration: 6800  Loss: 0.8164693117141724  Accuracy: 81.61478424072266 %\n",
      "Epoch: 1 Iteration: 6900  Loss: 1.1515507698059082  Accuracy: 81.8892822265625 %\n",
      "Epoch: 1 Iteration: 7000  Loss: 0.8569797873497009  Accuracy: 81.87801361083984 %\n",
      "Epoch: 1 Iteration: 7100  Loss: 2.311645984649658  Accuracy: 74.8359603881836 %\n",
      "Epoch: 1 Iteration: 7200  Loss: 0.9697674512863159  Accuracy: 81.37569427490234 %\n",
      "Epoch: 1 Iteration: 7300  Loss: 0.833251416683197  Accuracy: 81.32623291015625 %\n",
      "Epoch: 1 Iteration: 7400  Loss: 0.99549400806427  Accuracy: 81.32514190673828 %\n",
      "Fold 10 Epoch No. : 0 Accuracy for Epoch : 81.27155303955078\n",
      "Epochs completed. Time taken (seconds):  2256.188085794449\n",
      "Average accuracy over all epochs 81.27155303955078\n",
      "Mean accuracy score across all cross validation sets 84.07005615234375\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "fold_no = 1\n",
    "\n",
    "for train_index, test_index in skf.split(IDS_df, target):\n",
    "    train = IDS_df.loc[train_index,:]\n",
    "    test = IDS_df.loc[test_index,:]\n",
    "    accuracy_score = train_model(train, test, fold_no)\n",
    "    accuracy_scores.append(accuracy_score)\n",
    "    fold_no += 1\n",
    "    \n",
    "print('Mean accuracy score across all cross validation sets', np.mean(accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iteration_list,loss_list)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Number of iteration\")\n",
    "plt.show()\n",
    "\n",
    "# visualization accuracy \n",
    "plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy vs Number of iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
