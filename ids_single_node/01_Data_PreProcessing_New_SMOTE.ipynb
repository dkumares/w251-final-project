{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../fl-ids')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of the raw data and processed files name\n",
    "# CONFIG NEEDED: Uncomment only the specific files to be processed on your node\n",
    "\n",
    "csv_files = [\n",
    " '02-14-2018.csv',\n",
    " '02-15-2018.csv',\n",
    " '02-16-2018.csv',\n",
    " '02-21-2018.csv',\n",
    " '02-22-2018.csv',\n",
    " '02-23-2018.csv',\n",
    " '02-28-2018.csv',\n",
    " '03-01-2018.csv',\n",
    " '03-02-2018.csv',\n",
    " '02-20-2018.csv'    \n",
    "]\n",
    "\n",
    "label_maps = {'Benign': 0, 'FTP-BruteForce': 1, 'SSH-Bruteforce': 1, 'DoS attacks-GoldenEye': 1, 'DoS attacks-Slowloris': 1,\n",
    "         'DoS attacks-SlowHTTPTest': 1, 'DoS attacks-Hulk': 1, 'Brute Force -Web': 1, 'Brute Force -XSS': 1,\n",
    "         'SQL Injection': 1, 'Infilteration': 1, 'Bot': 1, 'DDOS attack-HOIC': 1, 'DDoS attacks-LOIC-HTTP': 1, \n",
    "         'DDOS attack-LOIC-UDP': 1}\n",
    " \n",
    "# CONFIG NEEDED: Change Binary and Multi-class output file names if needed\n",
    "multi_class_file = 'DATA-IDS-2018-multiclass'\n",
    "binary_class_file = 'DATA-IDS-2018-binaryclass'\n",
    "\n",
    "# CONFIG NEEDED: Change Train and Test output file names if needed. Adjust the split size.\n",
    "test_prefix = 'TEST-'\n",
    "train_prefix = 'TRAIN-'\n",
    "\n",
    "test_size = 0.10\n",
    "num_trainers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder name for raw data and processed files under the project directory\n",
    "# CONFIG NEEDED: Change the './data' and 'processed' to what you named your directories\n",
    "# Raw Data Files Location: final_project/data\n",
    "# Processed Data Files Location: final_project/data/processed\n",
    "\n",
    "rawdata_path = '../data/CSE-CIC-IDS2018'\n",
    "processed_path = os.path.join(rawdata_path, 'processed')\n",
    "\n",
    "# CONFIG NEEDED: Change to true as needed for multi-class or binary class files. \n",
    "# Note atleast one of these has to be true for the combined data file to be created. \n",
    "multi_class = True\n",
    "binary_class = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading: ../data/CSE-CIC-IDS2018\\02-14-2018.csv\n",
      "appending: ../data/CSE-CIC-IDS2018\\02-15-2018.csv\n",
      "appending: ../data/CSE-CIC-IDS2018\\02-16-2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitinpi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appending: ../data/CSE-CIC-IDS2018\\02-21-2018.csv\n",
      "appending: ../data/CSE-CIC-IDS2018\\02-22-2018.csv\n",
      "appending: ../data/CSE-CIC-IDS2018\\02-23-2018.csv\n",
      "appending: ../data/CSE-CIC-IDS2018\\02-28-2018.csv\n",
      "appending: ../data/CSE-CIC-IDS2018\\03-01-2018.csv\n",
      "appending: ../data/CSE-CIC-IDS2018\\03-02-2018.csv\n",
      "appending: ../data/CSE-CIC-IDS2018\\02-20-2018.csv\n",
      "Combined Raw Datafile Shape\n",
      "(16233002, 83)\n",
      "Original Number of Records:  16233002\n"
     ]
    }
   ],
   "source": [
    "# Read the first file from the list to be processed\n",
    "fname = os.path.join(rawdata_path, csv_files[0])\n",
    "print('reading:', fname)\n",
    "df = pd.read_csv(fname).drop(columns=['Timestamp'], errors='ignore')\n",
    "\n",
    "# Read the remaining files in the list\n",
    "for name in csv_files[1:]:\n",
    "    fname = os.path.join(rawdata_path, name)\n",
    "    print('appending:', fname)\n",
    "    df1 = pd.read_csv(fname).drop(columns=['Timestamp'], errors='ignore')\n",
    "    df = df.append(df1, ignore_index=True)\n",
    "\n",
    "# Shuffle the data records and print final shape\n",
    "print('Combined Raw Datafile Shape')\n",
    "print(df.shape)\n",
    "\n",
    "num_of_raw_records = df.shape[0]\n",
    "print('Original Number of Records: ', num_of_raw_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove infinity and NaN values\n",
    "print('Number of Infinity or NaN Values')\n",
    "print(df.isin([np.nan, np.inf, -np.inf]).sum().sum())\n",
    "\n",
    "# Replace infinity to NaN and drop NaN values\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "dropped_NaN_records = num_of_raw_records - df.shape[0]\n",
    "print('Number of NaN/Inf Records Dropped: ', dropped_NaN_records)\n",
    "\n",
    "# Check infinity and NaN values\n",
    "print('Remaining Infinity or NaN Values')\n",
    "print(df.isin([np.nan, np.inf, -np.inf]).sum().sum())\n",
    "\n",
    "print('Combined Raw Datafile Shape')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate headers\n",
    "df = df[~df['Dst Port'].str.contains('Dst Port', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean (spaces, special characters, etc.) column headers and lower case \n",
    "column_name_regex = re.compile(r\"\\W\", re.IGNORECASE)\n",
    "\n",
    "df.columns = [column_name_regex.sub('_', c.lower()) for c in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original Dataset Value Counts')\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop attack types that have less than 20K rows.\n",
    "df = df.groupby('label').filter(lambda x : len(x) > 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset Value Counts After Dropping Minimal Attacks')\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into test and train data\n",
    "y = df.pop('label')\n",
    "X = df\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, shuffle=True, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "dftrain = X_train.join(y_train)\n",
    "dftest = X_test.join(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14524388, 80)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1613821, 80)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign                      1339118\n",
       "DDOS attack-HOIC              68601\n",
       "DDoS attacks-LOIC-HTTP        57619\n",
       "DoS attacks-Hulk              46191\n",
       "Bot                           28619\n",
       "FTP-BruteForce                19335\n",
       "SSH-Bruteforce                18759\n",
       "Infilteration                 16074\n",
       "DoS attacks-SlowHTTPTest      13989\n",
       "DoS attacks-GoldenEye          4151\n",
       "DoS attacks-Slowloris          1099\n",
       "DDOS attack-LOIC-UDP            173\n",
       "Brute Force -Web                 61\n",
       "Brute Force -XSS                 23\n",
       "SQL Injection                     9\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign                      12052057\n",
       "DDOS attack-HOIC              617411\n",
       "DDoS attacks-LOIC-HTTP        518572\n",
       "DoS attacks-Hulk              415721\n",
       "Bot                           257572\n",
       "FTP-BruteForce                174019\n",
       "SSH-Bruteforce                168830\n",
       "Infilteration                 144665\n",
       "DoS attacks-SlowHTTPTest      125901\n",
       "DoS attacks-GoldenEye          37357\n",
       "DoS attacks-Slowloris           9891\n",
       "DDOS attack-LOIC-UDP            1557\n",
       "Brute Force -Web                 550\n",
       "Brute Force -XSS                 207\n",
       "SQL Injection                     78\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 1: \n",
    "#     DDOS attack-HOIC + DoS attacks-GoldenEye + Brute Force -Web + SQL Injection: 617411 + 37357 + 550 + 78 = 655,396\n",
    "# Trainer 2: \n",
    "#     DDoS attacks-LOIC-HTTP + Infilteration + Brute Force -XSS: 518572 + 144665 + 207 = 663,444\n",
    "# Trainer 3:\n",
    "#     DoS attacks-Hulk + FTP-BruteForce + DDOS attack-LOIC-UDP: 415721 + 174019 + 1557 = 591,297\n",
    "# Trainer 4: \n",
    "#     Bot + DoS attacks-SlowHTTPTest + SSH-Bruteforce  + DoS attacks-Slowlori: 257572 + 168830 + 125901 + 9891 = 562,194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1_labels = ['DDOS attack-HOIC', 'DoS attacks-GoldenEye', 'Brute Force -Web', 'SQL Injection']\n",
    "train_2_labels = ['DDoS attacks-LOIC-HTTP', 'Infilteration', 'Brute Force -XSS']\n",
    "train_3_labels = ['DoS attacks-Hulk', 'FTP-BruteForce', 'DDOS attack-LOIC-UDP']\n",
    "train_4_labels = ['Bot', 'DoS attacks-SlowHTTPTest', 'SSH-Bruteforce', 'DoS attacks-Slowloris']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_1 = dftrain[dftrain.label.isin(train_1_labels)]\n",
    "df_train_2 = dftrain[dftrain.label.isin(train_2_labels)]\n",
    "df_train_3 = dftrain[dftrain.label.isin(train_3_labels)]\n",
    "df_train_4 = dftrain[dftrain.label.isin(train_4_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set 1 shape (without benigns): (655396, 80)\n",
      "Training set 2 shape (without benigns): (663444, 80)\n",
      "Training set 3 shape (without benigns): (591297, 80)\n",
      "Training set 4 shape (without benigns): (562194, 80)\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set 1 shape (without benigns): {df_train_1.shape}')\n",
    "print(f'Training set 2 shape (without benigns): {df_train_2.shape}')\n",
    "print(f'Training set 3 shape (without benigns): {df_train_3.shape}')\n",
    "print(f'Training set 4 shape (without benigns): {df_train_4.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Benign Data Across Trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benign = dftrain[dftrain['label'] == 'Benign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12052057, 80)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benign.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benign = df_benign.sample(frac=1) # Shuffle data\n",
    "df_benign_1, df_benign_2, df_benign_3, df_benign_4 = np.array_split(df_benign, 4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign set 1 shape: (3013015, 80)\n",
      "Benign set 2 shape: (3013014, 80)\n",
      "Benign set 3 shape: (3013014, 80)\n",
      "Benign set 4 shape: (3013014, 80)\n"
     ]
    }
   ],
   "source": [
    "print(f'Benign set 1 shape: {df_benign_1.shape}')\n",
    "print(f'Benign set 2 shape: {df_benign_2.shape}')\n",
    "print(f'Benign set 3 shape: {df_benign_3.shape}')\n",
    "print(f'Benign set 4 shape: {df_benign_4.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_full_1 = pd.concat([df_train_1, df_benign_1])\n",
    "df_train_full_2 = pd.concat([df_train_2, df_benign_2])\n",
    "df_train_full_3 = pd.concat([df_train_3, df_benign_3])\n",
    "df_train_full_4 = pd.concat([df_train_4, df_benign_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset 1 shape: (3668411, 80)\n",
      "Full dataset 2 shape: (3676458, 80)\n",
      "Full dataset 3 shape: (3604311, 80)\n",
      "Full dataset 4 shape: (3575208, 80)\n"
     ]
    }
   ],
   "source": [
    "print(f'Full dataset 1 shape: {df_train_full_1.shape}')\n",
    "print(f'Full dataset 2 shape: {df_train_full_2.shape}')\n",
    "print(f'Full dataset 3 shape: {df_train_full_3.shape}')\n",
    "print(f'Full dataset 4 shape: {df_train_full_4.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Processing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conf import LABEL_TO_ID\n",
    "from util.data_loader import get_id_from_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_full_1['label'] = df_train_full_1['label'].apply(lambda x: get_id_from_label(x, LABEL_TO_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  9, 12, 14,  0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_full_1['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_full_2['label'] = df_train_full_2['label'].apply(lambda x: get_id_from_label(x, LABEL_TO_ID))\n",
    "df_train_full_3['label'] = df_train_full_3['label'].apply(lambda x: get_id_from_label(x, LABEL_TO_ID))\n",
    "df_train_full_4['label'] = df_train_full_4['label'].apply(lambda x: get_id_from_label(x, LABEL_TO_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  9 12 14  0]\n",
      "[ 1 10 13  0]\n",
      "[ 8  5 11  0]\n",
      "[7 6 3 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(df_train_full_1['label'].unique())\n",
    "print(df_train_full_2['label'].unique())\n",
    "print(df_train_full_3['label'].unique())\n",
    "print(df_train_full_4['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dict = {\n",
    "    '1': df_train_full_1,\n",
    "    '2': df_train_full_2,\n",
    "    '3': df_train_full_3,\n",
    "    '4': df_train_full_4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Multi-Class Test File\n",
      "Finished writing:  ../data/processed/TEST--DATA-IDS-2018-multiclass.csv\n"
     ]
    }
   ],
   "source": [
    "print('Creating Multi-Class Test File')\n",
    "test_file_name = os.path.join(processed_path, test_prefix + '-' + multi_class_file + '.csv')\n",
    "# dftest = dftest.drop('timestamp', axis=1) # Drop timestamp column\n",
    "dftest.drop('timestamp', axis=1).to_csv(test_file_name, index=False)\n",
    "print('Finished writing: ', test_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Multi-Class Test File for Trainer 1\n",
      "Finished writing:  ../data/processed/TRAIN-1-DATA-IDS-2018-multiclass.csv\n",
      "Creating Multi-Class Test File for Trainer 2\n",
      "Finished writing:  ../data/processed/TRAIN-2-DATA-IDS-2018-multiclass.csv\n",
      "Creating Multi-Class Test File for Trainer 3\n",
      "Finished writing:  ../data/processed/TRAIN-3-DATA-IDS-2018-multiclass.csv\n",
      "Creating Multi-Class Test File for Trainer 4\n",
      "Finished writing:  ../data/processed/TRAIN-4-DATA-IDS-2018-multiclass.csv\n"
     ]
    }
   ],
   "source": [
    "for i in df_train_dict.keys():\n",
    "    print(f'Creating Multi-Class Test File for Trainer {i}')\n",
    "    train_file_name = os.path.join(processed_path, f'{train_prefix}{i}-{multi_class_file}.csv')\n",
    "    df_train_dict[i].drop('timestamp', axis=1).to_csv(train_file_name, index=False)\n",
    "    print('Finished writing: ', train_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_read = pd.read_csv(test_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1613821, 79)\n"
     ]
    }
   ],
   "source": [
    "print(test_read.shape) # Should match dftest.shape = (1613821, 80) (-1 column with dropped timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_read\n",
    "del df_train_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping Minority Classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3013015\n",
       "4      617411\n",
       "9       37357\n",
       "12        550\n",
       "14         78\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_full_1['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_label_14_bootstrapped = df_train_full_1[df_train_full_1['label'] == 14].sample(10000, replace=True)\n",
    "df_1_label_12_bootstrapped = df_train_full_1[df_train_full_1['label'] == 12].sample(20000, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3013015\n",
       "4     617411\n",
       "9      37357\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_full_1[~df_train_full_1.label.isin([12, 14])].label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_bootstrapped_1 = pd.concat(\n",
    "    [\n",
    "        df_train_full_1[~df_train_full_1.label.isin([12, 14])], \n",
    "        df_1_label_14_bootstrapped, \n",
    "        df_1_label_12_bootstrapped\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3013015\n",
       "4      617411\n",
       "9       37357\n",
       "12      20000\n",
       "14      10000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_bootstrapped_1.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3013014\n",
       "10     518572\n",
       "1      144665\n",
       "13        207\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_full_2['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_label_13_bootstrapped = df_train_full_2[df_train_full_2['label'] == 13].sample(20000, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_bootstrapped_2 = pd.concat(\n",
    "    [\n",
    "        df_train_full_2[~df_train_full_2.label.isin([13])], \n",
    "        df_2_label_13_bootstrapped, \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3013014\n",
       "10     518572\n",
       "1      144665\n",
       "13      20000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_bootstrapped_2.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3013014\n",
       "8      415721\n",
       "5      174019\n",
       "11       1557\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_full_3['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3_label_11_bootstrapped = df_train_full_3[df_train_full_3['label'] == 11].sample(50000, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_bootstrapped_3 = pd.concat(\n",
    "    [\n",
    "        df_train_full_3[~df_train_full_3.label.isin([11])], \n",
    "        df_3_label_11_bootstrapped, \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3013014\n",
       "8      415721\n",
       "5      174019\n",
       "11      50000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_bootstrapped_3.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3013014\n",
       "7     257572\n",
       "3     168830\n",
       "6     125901\n",
       "2       9891\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_full_4['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4_label_2_bootstrapped = df_train_full_4[df_train_full_4['label'] == 2].sample(30000, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_bootstrapped_4 = pd.concat(\n",
    "    [\n",
    "        df_train_full_4[~df_train_full_4.label.isin([2])], \n",
    "        df_4_label_2_bootstrapped, \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3013014\n",
       "7     257572\n",
       "3     168830\n",
       "6     125901\n",
       "2      30000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_bootstrapped_4.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Bootstrap Oversampled Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dict = {\n",
    "    '1': df_train_bootstrapped_1,\n",
    "    '2': df_train_bootstrapped_2,\n",
    "    '3': df_train_bootstrapped_3,\n",
    "    '4': df_train_bootstrapped_4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_processed_path = f'{processed_path}_bootstrap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Multi-Class Oversampled File for Trainer 1\n",
      "Finished writing:  ../data/processed_bootstrap/TRAIN-1-DATA-IDS-2018-multiclass-bootstrap.csv\n",
      "Creating Multi-Class Oversampled File for Trainer 2\n",
      "Finished writing:  ../data/processed_bootstrap/TRAIN-2-DATA-IDS-2018-multiclass-bootstrap.csv\n",
      "Creating Multi-Class Oversampled File for Trainer 3\n",
      "Finished writing:  ../data/processed_bootstrap/TRAIN-3-DATA-IDS-2018-multiclass-bootstrap.csv\n",
      "Creating Multi-Class Oversampled File for Trainer 4\n",
      "Finished writing:  ../data/processed_bootstrap/TRAIN-4-DATA-IDS-2018-multiclass-bootstrap.csv\n"
     ]
    }
   ],
   "source": [
    "for i in df_train_dict.keys():\n",
    "    print(f'Creating Multi-Class Oversampled File for Trainer {i}')\n",
    "    train_file_name = os.path.join(bootstrap_processed_path, f'{train_prefix}{i}-{multi_class_file}-bootstrap.csv')\n",
    "    df_train_dict[i].drop('timestamp', axis=1).to_csv(train_file_name, index=False)\n",
    "    print('Finished writing: ', train_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a multi-class label file\n",
    "# if multi_class:\n",
    "#     print('Creating Multi-Class Test File')\n",
    "#     outTestFile = os.path.join(processed_path, test_prefix + '-' + multi_class_file + '.csv')\n",
    "#     dftest = dftest.drop('timestamp', axis=1)      # Drop timestamp column\n",
    "#     dftest.to_csv(outTestFile, index=False)\n",
    "#     print('finished writing:', outTestFile)\n",
    "    \n",
    "#     # Sort training data based of timestamp and split into four equal chunks\n",
    "#     dftrain = dftrain.sort_values(by='timestamp', ascending=True)\n",
    "#     df_train_split = np.array_split(dftrain, num_trainers)\n",
    "    \n",
    "#     for x in range(0, num_trainers):\n",
    "#         print('Creating Multi-Class Training File: ', str(x+1))\n",
    "#         outTrainFile = os.path.join(processed_path, train_prefix + str(x+1) + '-' + multi_class_file + '.csv')\n",
    "#         df_train_split[x].to_csv(outTrainFile, index=False)\n",
    "#         print('finished writing:', outTrainFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../data/processed/TRAIN-0DATA-IDS-2018-multiclass.csv\")\n",
    "# df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if binary_class:\n",
    "#     print('Creating Binary-Class Test File')\n",
    "#     df = pd.read_csv(processed_path, test_prefix + multi_class_file + '.csv')\n",
    "#     outTestFile = os.path.join(processed_path, test_prefix + binary_class_file + '.csv')\n",
    "\n",
    "#     # Map benign rows to 0, all others as 1\n",
    "#     df['label'] = df['label'].map(label_maps).astype(int)\n",
    "#     df.to_csv(outTestFile, index=False)\n",
    "#     print('finished writing:', outTestFile)\n",
    "\n",
    "#     for x in range(0, num_trainers):\n",
    "#         print('Creating Binary-Class Training File: ', str(x+1))\n",
    "#         df = pd.read_csv(processed_path, train_prefix + str(x+1) + multi_class_file + '.csv')\n",
    "\n",
    "#         # Map benign rows to 0, all others as 1\n",
    "#         df['label'] = df['label'].map(label_maps).astype(int)\n",
    "\n",
    "#         outTrainFile = os.path.join(processed_path, train_prefix + str(x+1) + binary_class_file + '.csv')\n",
    "#         df.to_csv(outTrainFile, index=False)\n",
    "#         print('finished writing:', outTrainFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../data/processed/train-02-20-2018-ddos-loic-tcp.csv\")\n",
    "# df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('all done...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
