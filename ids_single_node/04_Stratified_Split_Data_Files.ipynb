{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d512e080",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:51:14.473891Z",
     "start_time": "2021-04-04T02:51:14.421978Z"
    }
   },
   "outputs": [],
   "source": [
    "#############################################################################################\n",
    "# Notebook to be used for doing a stratified split of the cleaned datasets                  #\n",
    "# and creating csv files.                                                                   #\n",
    "#############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10b26a07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:51:14.513753Z",
     "start_time": "2021-04-04T02:51:14.488605Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c150cee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:51:14.543932Z",
     "start_time": "2021-04-04T02:51:14.526102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of the cleaned data files\n",
    "# CONFIG NEEDED: Uncomment only the specific files to be processed on your node\n",
    "\n",
    "cleaned_csv_files = [\n",
    " '02-14-2018-bruteforce-ftp-ssh.csv',\n",
    " '02-15-2018-dos-goldeneye-slowloris.csv',\n",
    " '02-16-2018-dos-slowhttp-hulk.csv',\n",
    " '02-21-2018-ddos-loic-udp.csv',\n",
    " '02-22-2018-bruteforce-webxss.csv',\n",
    " '02-23-2018-bruteforce-webxss-sql.csv',\n",
    " '02-28-2018-infiltration.csv',\n",
    " '03-01-2018-botnet.csv'\n",
    "# '03-02-2018-infiltration.csv',\n",
    "# '02-20-2018-ddos-loic-tcp.csv'   # WARNING: 4GB FILE.\n",
    "]\n",
    "\n",
    "# CONFIG NEEDED: Change Binary and Multi-class output file names if needed\n",
    "# multi_class_file = 'IDS-2018-multiclass'\n",
    "# binary_class_file = 'IDS-2018-binaryclass'\n",
    "\n",
    "test_prefix = 'test-'\n",
    "train_prefix = 'train-'\n",
    "\n",
    "test_size = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f463d628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:51:14.570109Z",
     "start_time": "2021-04-04T02:51:14.551690Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the folder name for raw data and processed files under the project directory\n",
    "# CONFIG NEEDED: Change the './data' and 'processed' to what you named your directories\n",
    "# Raw Data Files Location: final_project/data\n",
    "# Processed Data Files Location: final_project/data/processed\n",
    "\n",
    "rawdata_path = '../data'\n",
    "processed_path = os.path.join(rawdata_path, 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fbd56f23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:53:01.452979Z",
     "start_time": "2021-04-04T02:51:14.598311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading: ../data/processed/02-14-2018-bruteforce-ftp-ssh.csv\n",
      "(1047028, 79) (1047028,)\n",
      "(942325, 79) (104703, 79) (942325,) (104703,)\n",
      "finished writing: ../data/processed/train-02-14-2018-bruteforce-ftp-ssh.csv\n",
      "finished writing: ../data/processed/test-02-14-2018-bruteforce-ftp-ssh.csv\n",
      "reading: ../data/processed/02-15-2018-dos-goldeneye-slowloris.csv\n",
      "(1045469, 79) (1045469,)\n",
      "(940922, 79) (104547, 79) (940922,) (104547,)\n",
      "finished writing: ../data/processed/train-02-15-2018-dos-goldeneye-slowloris.csv\n",
      "finished writing: ../data/processed/test-02-15-2018-dos-goldeneye-slowloris.csv\n",
      "reading: ../data/processed/02-16-2018-dos-slowhttp-hulk.csv\n",
      "(1048574, 79) (1048574,)\n",
      "(943716, 79) (104858, 79) (943716,) (104858,)\n",
      "finished writing: ../data/processed/train-02-16-2018-dos-slowhttp-hulk.csv\n",
      "finished writing: ../data/processed/test-02-16-2018-dos-slowhttp-hulk.csv\n",
      "reading: ../data/processed/02-21-2018-ddos-loic-udp.csv\n",
      "(1048575, 79) (1048575,)\n",
      "(943717, 79) (104858, 79) (943717,) (104858,)\n",
      "finished writing: ../data/processed/train-02-21-2018-ddos-loic-udp.csv\n",
      "finished writing: ../data/processed/test-02-21-2018-ddos-loic-udp.csv\n",
      "reading: ../data/processed/02-22-2018-bruteforce-webxss.csv\n",
      "(1046534, 79) (1046534,)\n",
      "(941880, 79) (104654, 79) (941880,) (104654,)\n",
      "finished writing: ../data/processed/train-02-22-2018-bruteforce-webxss.csv\n",
      "finished writing: ../data/processed/test-02-22-2018-bruteforce-webxss.csv\n",
      "reading: ../data/processed/02-23-2018-bruteforce-webxss-sql.csv\n",
      "(1046621, 79) (1046621,)\n",
      "(941958, 79) (104663, 79) (941958,) (104663,)\n",
      "finished writing: ../data/processed/train-02-23-2018-bruteforce-webxss-sql.csv\n",
      "finished writing: ../data/processed/test-02-23-2018-bruteforce-webxss-sql.csv\n",
      "reading: ../data/processed/02-28-2018-infiltration.csv\n",
      "(610943, 79) (610943,)\n",
      "(549848, 79) (61095, 79) (549848,) (61095,)\n",
      "finished writing: ../data/processed/train-02-28-2018-infiltration.csv\n",
      "finished writing: ../data/processed/test-02-28-2018-infiltration.csv\n",
      "reading: ../data/processed/03-01-2018-botnet.csv\n",
      "(330015, 79) (330015,)\n",
      "(297013, 79) (33002, 79) (297013,) (33002,)\n",
      "finished writing: ../data/processed/train-03-01-2018-botnet.csv\n",
      "finished writing: ../data/processed/test-03-01-2018-botnet.csv\n"
     ]
    }
   ],
   "source": [
    "# Read the first file from the list to be processed\n",
    "for name in cleaned_csv_files[:]:\n",
    "    fname = os.path.join(processed_path, name)\n",
    "    print('reading:', fname)\n",
    "    df = pd.read_csv(fname)\n",
    "\n",
    "    y = df.pop('label')\n",
    "    X = df\n",
    "    print(X.shape, y.shape)\n",
    "\n",
    "    # split into train test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, shuffle=True, random_state=1)\n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    dftrain = X_train.join(y_train)\n",
    "    dftest = X_test.join(y_test)\n",
    "\n",
    "    outTrainFile = os.path.join(processed_path, train_prefix + name)\n",
    "    dftrain.to_csv(outTrainFile, index=False)\n",
    "    print('finished writing:', outTrainFile)\n",
    "\n",
    "    outTestFile = os.path.join(processed_path, test_prefix + name)\n",
    "    dftest.to_csv(outTestFile, index=False)\n",
    "    print('finished writing:', outTestFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f3d81c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign    684802\n",
       "Bot       257572\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a sample file and check label counts\n",
    "# CONFIG NEEDED: Change file name to the file you want to check\n",
    "df = pd.read_csv(\"../data/processed/train-03-02-2018-infiltration.csv\")\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b1d0db39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign    76090\n",
       "Bot       28619\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a sample file and check label counts\n",
    "# CONFIG NEEDED: Change file name to the file you want to check\n",
    "df = pd.read_csv(\"../data/processed/test-03-02-2018-infiltration.csv\")\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c490206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
