{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:38</td>\n",
       "      <td>141385</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>553</td>\n",
       "      <td>3773.0</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49684</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:38</td>\n",
       "      <td>281</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:40</td>\n",
       "      <td>279824</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>1086</td>\n",
       "      <td>10527.0</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:40</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:41</td>\n",
       "      <td>274016</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>1285</td>\n",
       "      <td>6141.0</td>\n",
       "      <td>517</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dst Port  Protocol            Timestamp  Flow Duration  Tot Fwd Pkts  \\\n",
       "0       443         6  02/03/2018 08:47:38         141385             9   \n",
       "1     49684         6  02/03/2018 08:47:38            281             2   \n",
       "2       443         6  02/03/2018 08:47:40         279824            11   \n",
       "3       443         6  02/03/2018 08:47:40            132             2   \n",
       "4       443         6  02/03/2018 08:47:41         274016             9   \n",
       "\n",
       "   Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  \\\n",
       "0             7              553           3773.0              202   \n",
       "1             1               38              0.0               38   \n",
       "2            15             1086          10527.0              385   \n",
       "3             0                0              0.0                0   \n",
       "4            13             1285           6141.0              517   \n",
       "\n",
       "   Fwd Pkt Len Min  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
       "0                0  ...                20          0.0         0.0   \n",
       "1                0  ...                20          0.0         0.0   \n",
       "2                0  ...                20          0.0         0.0   \n",
       "3                0  ...                20          0.0         0.0   \n",
       "4                0  ...                20          0.0         0.0   \n",
       "\n",
       "   Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min   Label  \n",
       "0         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
       "1         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
       "2         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
       "3         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
       "4         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDS_df = pd.read_csv(\"data/03-02-2018.csv\")\n",
    "\n",
    "# To display the top 5 rows\n",
    "IDS_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048575, 80)\n"
     ]
    }
   ],
   "source": [
    "# print shape before dropping NaN rows\n",
    "print(IDS_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8100\n"
     ]
    }
   ],
   "source": [
    "# Finding the null values.\n",
    "print(IDS_df.isin([np.nan, np.inf, -np.inf]).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  first replace infs to NaN:\n",
    "IDS_df = IDS_df.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044525, 80)\n"
     ]
    }
   ],
   "source": [
    "# print shape after dropping NaN rows\n",
    "IDS_df = IDS_df.dropna()\n",
    "print(IDS_df.shape)\n",
    "IDS_df = IDS_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Finding the null values.\n",
    "print(IDS_df.isin([np.nan, np.inf, -np.inf]).sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the proportion of types of traffic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Benign', 758334), ('Bot', 286191)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = IDS_df[\"Label\"].values\n",
    "from collections import Counter\n",
    "\n",
    "Counter(y).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all non-normal observations into a single class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_anomalous(text):\n",
    "    \"\"\"Binarize target labels into normal or anomalous.\"\"\"\n",
    "    if text == \"Benign\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "IDS_df[\"Label\"] = IDS_df[\"Label\"].apply(label_anomalous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 758334), (1, 286191)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = IDS_df[\"Label\"].values\n",
    "Counter(y).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all categorical features into numerical form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encodings_dictionary = dict()\n",
    "for c in IDS_df.columns:\n",
    "    if IDS_df[c].dtype == \"object\":\n",
    "        encodings_dictionary[c] = LabelEncoder()\n",
    "        IDS_df[c] = encodings_dictionary[c].fit_transform(IDS_df[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into normal and abnormal observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IDS_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d44b82fea092>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# X_anomaly = IDS_df_abnormal.values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIDS_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIDS_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IDS_df' is not defined"
     ]
    }
   ],
   "source": [
    "IDS_df_normal = IDS_df[IDS_df[\"Label\"] == 0]\n",
    "IDS_df_abnormal = IDS_df[IDS_df[\"Label\"] == 1]\n",
    "y_normal = IDS_df_normal.pop(\"Label\").values\n",
    "X_normal = IDS_df_normal.values\n",
    "y_anomaly = IDS_df_abnormal.pop(\"Label\").values\n",
    "X_anomaly = IDS_df_abnormal.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test split the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_normal_train, X_normal_test, y_normal_train, y_normal_test = train_test_split(\n",
    "    X_normal, y_normal, test_size=0.3, random_state=11\n",
    ")\n",
    "X_anomaly_train, X_anomaly_test, y_anomaly_train, y_anomaly_test = train_test_split(\n",
    "    X_anomaly, y_anomaly, test_size=0.3, random_state=11\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# X_train = np.concatenate((X_normal_train, X_anomaly_train))\n",
    "# y_train = np.concatenate((y_normal_train, y_anomaly_train))\n",
    "# X_test = np.concatenate((X_normal_test, X_anomaly_test))\n",
    "# y_test = np.concatenate((y_normal_test, y_anomaly_test))\n",
    "\n",
    "X_train = np.concatenate((X_normal_train[:10000], X_anomaly_train[:10000]))\n",
    "y_train = np.concatenate((y_normal_train[:10000], y_anomaly_train[:10000]))\n",
    "X_test = np.concatenate((X_normal_test[:1000], X_anomaly_test[:1000]))\n",
    "y_test = np.concatenate((y_normal_test[:1000], y_anomaly_test[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 79)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed loading data\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# Pytorch\n",
    "X_train  = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train)\n",
    "\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "valid = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "print('Completed loading data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20000, 79])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (layer1): Linear(in_features=79, out_features=256, bias=True)\n",
      "  (activ1): ReLU()\n",
      "  (layer2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (activ2): ReLU()\n",
      "  (layer3): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "        \n",
    "# Defining the DNN model\n",
    "input_size = train_loader.dataset.tensors[0].shape[1]\n",
    "hidden_layers = [256,256]\n",
    "output_size = 2\n",
    "\n",
    "# model = nn.Sequential(\n",
    "#     nn.Linear(input_size, hidden_layers[0]),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(hidden_layers[0], hidden_layers[1]),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(hidden_layers[1], output_size),\n",
    "#     nn.Sigmoid()\n",
    "# )\n",
    "\n",
    "\n",
    "# model definition\n",
    "class MLP(nn.Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_inputs, hidden_layers[0])\n",
    "        self.activ1 = nn.ReLU()\n",
    "        \n",
    "        self.layer2 = nn.Linear(hidden_layers[0], hidden_layers[1])\n",
    "        self.activ2 = nn.ReLU()\n",
    "        \n",
    "        self.layer3 = nn.Linear(hidden_layers[1], output_size)\n",
    "                \n",
    "    # forward propagate input\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.activ1(x)\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "        x = self.activ2(x)\n",
    "        \n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = MLP(input_size)\n",
    "print(model)\n",
    "model.to(device)\n",
    "\n",
    " # Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss().to(device)\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.001\n",
    "# TODO: Try SGD\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Epoch: 1 Iteration: 0  Loss: 23.320106506347656  Accuracy: 50 %\n",
      "Epoch: 1 Iteration: 100  Loss: 7099.6474609375  Accuracy: 50 %\n",
      "Epoch: 2 Iteration: 0  Loss: 11885061.0  Accuracy: 50 %\n",
      "Epoch: 2 Iteration: 100  Loss: 3347.555908203125  Accuracy: 50 %\n",
      "Epoch: 3 Iteration: 0  Loss: 9878019.0  Accuracy: 50 %\n",
      "Epoch: 3 Iteration: 100  Loss: 1730.6136474609375  Accuracy: 50 %\n",
      "Epoch: 4 Iteration: 0  Loss: 328680.6875  Accuracy: 79 %\n",
      "Epoch: 4 Iteration: 100  Loss: 9.142168998718262  Accuracy: 94 %\n",
      "Epoch: 5 Iteration: 0  Loss: 2.5265231132507324  Accuracy: 99 %\n",
      "Epoch: 5 Iteration: 100  Loss: 0.10745707154273987  Accuracy: 98 %\n",
      "Epoch: 6 Iteration: 0  Loss: 0.0  Accuracy: 98 %\n",
      "Epoch: 6 Iteration: 100  Loss: 0.12235981225967407  Accuracy: 97 %\n",
      "Epoch: 7 Iteration: 0  Loss: 0.06597274541854858  Accuracy: 99 %\n",
      "Epoch: 7 Iteration: 100  Loss: 1.7721558809280396  Accuracy: 89 %\n",
      "Epoch: 8 Iteration: 0  Loss: 0.0  Accuracy: 99 %\n",
      "Epoch: 8 Iteration: 100  Loss: 0.0004635810910258442  Accuracy: 99 %\n",
      "Epoch: 9 Iteration: 0  Loss: 0.0  Accuracy: 99 %\n",
      "Epoch: 9 Iteration: 100  Loss: 9.53674295089968e-09  Accuracy: 99 %\n",
      "Epoch: 10 Iteration: 0  Loss: 0.0  Accuracy: 99 %\n",
      "Epoch: 10 Iteration: 100  Loss: 0.0  Accuracy: 99 %\n",
      "Epoch: 11 Iteration: 0  Loss: 0.0  Accuracy: 99 %\n",
      "Epoch: 11 Iteration: 100  Loss: 0.07914771884679794  Accuracy: 98 %\n",
      "Epoch: 12 Iteration: 0  Loss: 0.0  Accuracy: 99 %\n",
      "Epoch: 12 Iteration: 100  Loss: 1.4305114426349519e-08  Accuracy: 99 %\n",
      "Epoch: 13 Iteration: 0  Loss: 0.0  Accuracy: 99 %\n",
      "Epoch: 13 Iteration: 100  Loss: 0.0  Accuracy: 100 %\n",
      "Epoch: 14 Iteration: 0  Loss: 0.0  Accuracy: 100 %\n",
      "Epoch: 14 Iteration: 100  Loss: 0.0  Accuracy: 100 %\n",
      "Epoch: 15 Iteration: 0  Loss: 0.0  Accuracy: 99 %\n",
      "Epoch: 15 Iteration: 100  Loss: 0.0  Accuracy: 100 %\n",
      "Epoch: 16 Iteration: 0  Loss: 0.0  Accuracy: 99 %\n",
      "Epoch: 16 Iteration: 100  Loss: 0.0  Accuracy: 100 %\n",
      "Epoch: 17 Iteration: 0  Loss: 0.0  Accuracy: 99 %\n",
      "Epoch: 17 Iteration: 100  Loss: 12.653402328491211  Accuracy: 98 %\n",
      "Epoch: 18 Iteration: 0  Loss: 0.0  Accuracy: 99 %\n",
      "Epoch: 18 Iteration: 100  Loss: 12.341391563415527  Accuracy: 88 %\n",
      "Epoch: 19 Iteration: 0  Loss: 7.693223476409912  Accuracy: 99 %\n",
      "Epoch: 19 Iteration: 100  Loss: 31.67449188232422  Accuracy: 87 %\n",
      "Epoch: 20 Iteration: 0  Loss: 8.258206367492676  Accuracy: 99 %\n",
      "Epoch: 20 Iteration: 100  Loss: 0.028408221900463104  Accuracy: 99 %\n",
      "Epochs completed. Time taken (seconds):  26.258206844329834\n"
     ]
    }
   ],
   "source": [
    "print('Start training...')\n",
    "start_time = time.time()\n",
    "    \n",
    "epochs = 20\n",
    "for e in range(epochs):\n",
    "    count = 0\n",
    "    loss_list = []\n",
    "    iteration_list = []\n",
    "    accuracy_list = []\n",
    "   \n",
    "    for i, (data, labels) in enumerate(train_loader):\n",
    "        train = data.to(device)\n",
    "        #print(labels)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for data, labels in valid_loader:\n",
    "                valid = data.to(device)\n",
    "                #print('Lables:', labels)\n",
    "                \n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward propagation\n",
    "                outputs = model(valid)\n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "\n",
    "                #print('Predicted: ', predicted)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / float(total)\n",
    "\n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "        if count % 100 == 0:\n",
    "            # Print Loss\n",
    "            print('Epoch: {} Iteration: {}  Loss: {}  Accuracy: {} %'.format(e + 1, count, loss.data, accuracy))\n",
    "\n",
    "        count += 1\n",
    "\n",
    "end_time = time.time()\n",
    "print('Epochs completed. Time taken (seconds): ', str(end_time - start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
